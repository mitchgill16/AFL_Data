{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Models to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "#import torch.nn as nn\n",
    "#import touch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "#from fdnn import feature_extractor as fex\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "#import torch.nn as nn\n",
    "#import touch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "#from fdnn import feature_extractor as fex\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Activation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get headers\n",
    "#feed this into a bigger function which specifies the amount of games to go through \n",
    "def get_headers(n_games):\n",
    "    headers = ['Round', 'Home_Team', 'Away_Team', 'Venue', 'H_PAV_Sum', 'A_PAV_Sum']\n",
    "    example_file = pd.read_csv('Data/Fremantle_clean_stats.csv')\n",
    "    cl_h = example_file.columns\n",
    "    cl_h = cl_h[:-5]\n",
    "    ladder_header = ['Ladder Pos_H', 'Form_H', 'Season Wins_H', 'Season Loss_H', 'Season Draw_H']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    j = 1\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'H_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    j = 1\n",
    "    ladder_header = ['Ladder Pos_A', 'Form_A', 'Season Wins_A', 'Season Loss_A', 'Season Draw_A']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'A_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headers(h):\n",
    "    headers = []\n",
    "    for x in h:\n",
    "        if '<' in x or '>' in x:\n",
    "            x = x.replace('<',\"lt_\")\n",
    "            x = x.replace('>', \"gt_\")\n",
    "            #print(x)\n",
    "        headers.append(str(x))\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_categorical_headers(h):\n",
    "    cat_var = ['Round', 'Home_Team', 'Away_Team']\n",
    "    skip = 0\n",
    "    for x in h:\n",
    "        if 'Round' in x:\n",
    "            if (skip == 0):\n",
    "                skip = 1\n",
    "                continue\n",
    "            cat_var.append(x)\n",
    "            #print(x)\n",
    "        elif 'Team_against_ID' in x:\n",
    "            #print(x)\n",
    "            cat_var.append(x)\n",
    "        elif 'Venue' in x:\n",
    "            cat_var.append(x)\n",
    "    return cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode data and transform the X_data\n",
    "#first redo, find the categorial variables\n",
    "def ohe_data(x_data, enc, flag,cat_var):\n",
    "    #data has not been previously one hot encoded\n",
    "    if (flag == 0):\n",
    "        #get columns with categorical data and drop from main DF\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        #define and fit new OHE. Use it on our categorical data by transforming\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        ohe = ohe.fit(categorical_data)\n",
    "        categorical_data = ohe.transform(categorical_data)\n",
    "        #get feature names for better labelling\n",
    "        fn = ohe.get_feature_names(cat_var)\n",
    "        #make a dataframe with new OHE data and feature names\n",
    "            #would have been good to have coded it like this for my Masters project...\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        #ensure that it won't get cranky about any different indexes(shouldn't be any but just a good check)\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        #concatenate along column axis\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1)\n",
    "    else:\n",
    "        #same as above except used already fitted ohe\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        categorical_data = enc.transform(categorical_data)\n",
    "        fn = enc.get_feature_names(cat_var)\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1, ignore_index=True)\n",
    "        ohe = enc\n",
    "    return x_data, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search parameters for best XGB classifier or best XGB regressor\n",
    "\n",
    "def param_search(x_data, y_label, class_reg):\n",
    "\n",
    "    def on_step(optim_result):\n",
    "        \"\"\"\n",
    "        Callback meant to view scores after\n",
    "        each iteration while performing Bayesian\n",
    "        Optimization in Skopt\"\"\"\n",
    "        score = xgb_bayes_search.best_score_\n",
    "        print(\"best score: %s\" % score)\n",
    "        if score >= 0.98:\n",
    "            print('Interrupting!')\n",
    "            return True\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_label, test_size=0.2, random_state=157732)\n",
    "    print(\"X_train shape: \" + str(X_train.shape))\n",
    "    print(\"X_test shape: \" + str(X_test.shape))\n",
    "  #  print(\"y_train shape: \" + str(y_train.shape))\n",
    "  #  print(\"y_test shape: \" + str(y_test.shape))\n",
    "    space ={'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'max_depth': Integer(0, 50),\n",
    "        'max_delta_step': Integer(0, 20),\n",
    "        'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': Real(0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': Real(1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 5),\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'scale_pos_weight': Real(1e-6, 500, 'log-uniform')}\n",
    "    if(class_reg == 0):\n",
    "        xgbclass = xgb.XGBClassifier(random_state=27022013)\n",
    "    else:\n",
    "        xgbclass = xgb.XGBRegressor(random_state=27022013)\n",
    "    xgb_bayes_search = BayesSearchCV(xgbclass, space, n_iter=60, # specify how many iterations\n",
    "                                    scoring=None, n_jobs=1, cv=10, verbose=1, random_state=42, n_points=12,\n",
    "                                 refit=True)\n",
    "  #  kk = np.isinf(X_train)\n",
    "  #  if True in kk:\n",
    "  #  \tprint(\"aaaaaaa\")\n",
    "  #  kk = np.isinf(y_train)\n",
    "  #  if True in kk:\n",
    "  #  \tprint(\"reeeeeee\")\n",
    "    try:\n",
    "        xgb_bayes_search.fit(X_train, y_train.values.ravel(), callback = on_step)\n",
    "    except:\n",
    "        xgb_bayes_search.fit(X_train, y_train.values.ravel(), callback = on_step)\n",
    "  #  print(\"BEST PARAMS ARE HERE\")\n",
    " #   print(xgb_bayes_search.best_params_)\n",
    "    model = xgb_bayes_search.best_estimator_\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = all data for classifier\n",
    "#y = label of whether home team or away team won\n",
    "#m = xgb classifier for winner prediction\n",
    "#mx = all data for regressor\n",
    "#my = labels of margins\n",
    "    #try absolute values\n",
    "#mm = xgb regressor for margin prediction\n",
    "def eval_xgb_games_margins(x, y, m, mx, my, mm):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    best_m = mm\n",
    "    high_m = 100\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "    print(x)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        margin_pred = mm.fit(mx.loc[train], my.loc[train])\n",
    "        print(\"variables for auroc curve done. Processing fold accuracy + checking best model\")\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        #print(y_pred)\n",
    "        m_pred = mm.predict(mx.loc[test])\n",
    "        print(m_pred)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        print(\"The accuracy of this model is\" + str(pcent))\n",
    "        rmse = sqrt(mean_squared_error(m_pred, my.loc[test]))\n",
    "        print(\"The rmse of this model is\" + str(rmse))\n",
    "        results.append(pcent)\n",
    "        error.append(rmse)\n",
    "        #change the best model to equal current model\n",
    "        if(pcent > high_w):\n",
    "            print(\"found new best classify\")\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "        if(rmse < high_m):\n",
    "            print(\"found best new margin\")\n",
    "            best_m = mm\n",
    "            high_m = rmse\n",
    "    print(\"Best win percentage split = \" +str(high_w))\n",
    "    print(\"Best margin rmse = \"+str(high_m))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    print(\"Training Testing Margins: %.2f%% (%.2f%%)\" % (np.mean(error), np.std(error)))\n",
    "    return best_w, best_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_threshold_cv(x, y, m):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "    mean_acc = (np.mean(results))\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(x_data, y_label, best_xgb_clas):\n",
    "    thresholds = sort(best_xgb_clas.feature_importances_)\n",
    "    threshold_array = []\n",
    "    threshold_accuracies = []\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(best_xgb_clas, threshold=thresh, prefit=True)\n",
    "        selection_x_data = selection.transform(x_data)\n",
    "        selection_x_data = pd.DataFrame(selection_x_data)\n",
    "        if(thresh > 0 ):\n",
    "            threshold_array.append(thresh)\n",
    "            selection_model = XGBClassifier()\n",
    "            acc = eval_threshold_cv(selection_x_data, y_label, selection_model)\n",
    "            threshold_accuracies.append(acc)\n",
    "            print(\"Thresh=%.10f, n=%d, Accuracy: %.2f%%\" % (thresh, selection_x_data.shape[1], acc))\n",
    "    i = 0\n",
    "    max_acc = 0\n",
    "    max_i = 0\n",
    "    max_thresh = 0\n",
    "    for x in threshold_array:\n",
    "        current_acc = threshold_accuracies[i]\n",
    "        if(current_acc > max_acc):\n",
    "            max_acc = current_acc\n",
    "            max_thresh = x\n",
    "            max_i = i\n",
    "        i = i + 1\n",
    "    print(\"max accuracy is: \" + str(max_acc) + \"for threshold: \" + str(max_thresh))\n",
    "    return max_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this a method param later\n",
    "#n_games = 5\n",
    "def run_all_models(n_games):\n",
    "    #load headers and then subsequently categorical headers\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "    \n",
    "    #filter post 2021-ish\n",
    "    x_data = x_data[1400:].reset_index(drop=True)\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "    filename = 'Models/ohe_'+str(n_games)+'_no_2021_games.dat'\n",
    "    pickle.dump(ohe, open(filename, \"wb\"))\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "    y_label = y_label[1400:].reset_index(drop=True)\n",
    "\n",
    "    #loads margin as the y_label\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "    margin_label = margin_label[1400:].reset_index(drop=True)\n",
    "\n",
    "    print(margin_label.shape)\n",
    "    print(y_label.shape)\n",
    "    print(x_data.shape)\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    #optimise XGBoost model\n",
    "\n",
    "    #for predicting win\n",
    "    model = param_search(x_data, y_label, 0)\n",
    "    #for predicting margin\n",
    "    #margin_label = abs(margin_label)\n",
    "    margin_model = param_search(x_data, margin_label, 1)\n",
    "    #margin_model = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "\n",
    "   # margin_label = abs(margin_label)\n",
    "    print(margin_label)\n",
    "    best_xgb_clas, best_xgb_reg = eval_xgb_games_margins(x_data, y_label, model, x_data, margin_label, margin_model)\n",
    "\n",
    "    #save\n",
    "    pickle.dump(best_xgb_clas, open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))\n",
    "    pickle.dump(best_xgb_reg, open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))\n",
    "    \n",
    "    best_threshold = threshold_search(x_data, y_label, best_xgb_clas)\n",
    "    selection = SelectFromModel(best_xgb_clas, threshold=best_threshold, prefit=True)\n",
    "    print(selection)\n",
    "    selection_x_data = selection.transform(x_data)\n",
    "    selection_x_data = pd.DataFrame(selection_x_data)\n",
    "\n",
    "    fs_filename = 'Models/fs_criteria_'+str(n_games)+'.dat'\n",
    "    pickle.dump(selection, open(fs_filename, \"wb\"))\n",
    "\n",
    "    fs_model = param_search(selection_x_data, y_label, 0)\n",
    "\n",
    "    best_xgb_fs_clas, best_xgb_reg = eval_xgb_games_margins(selection_x_data, y_label, fs_model, x_data, margin_label, margin_model)\n",
    "\n",
    "    pickle.dump(best_xgb_fs_clas, open(\"Models/best_xgb_clas_FS_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     H/A Win?\n",
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         1.0\n",
      "4         0.0\n",
      "..        ...\n",
      "655       0.0\n",
      "656       0.0\n",
      "657       1.0\n",
      "658       0.0\n",
      "659       0.0\n",
      "\n",
      "[660 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(2)+'_games.csv')\n",
    "y_label\n",
    "y_label = y_label[1400:].reset_index(drop=True)\n",
    "print(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660, 1)\n",
      "(660, 2)\n",
      "(660, 721)\n",
      "X_train shape: (528, 721)\n",
      "X_test shape: (132, 721)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [528, 1056]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 47\u001b[0m, in \u001b[0;36mparam_search\u001b[0;34m(x_data, y_label, class_reg)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mxgb_bayes_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skopt/searchcv.py:692\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    690\u001b[0m n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 692\u001b[0m optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skopt/searchcv.py:579\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit \u001b[38;5;241m=\u001b[39m refit\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skopt/searchcv.py:398\u001b[0m, in \u001b[0;36mBayesSearchCV._fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer_ \u001b[38;5;241m=\u001b[39m check_scoring(\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring)\n\u001b[0;32m--> 398\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, groups)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:248\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    247\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 248\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:211\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths])\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [528, 1056]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#n_games = [4,5,6]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m n_games:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mrun_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [24], line 48\u001b[0m, in \u001b[0;36mrun_all_models\u001b[0;34m(n_games)\u001b[0m\n\u001b[1;32m     43\u001b[0m x_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [regex\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, col) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(col) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m))) \u001b[38;5;28;01melse\u001b[39;00m col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m x_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#optimise XGBoost model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#for predicting win\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mparam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#for predicting margin\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#margin_label = abs(margin_label)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m margin_model \u001b[38;5;241m=\u001b[39m param_search(x_data, margin_label, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn [13], line 49\u001b[0m, in \u001b[0;36mparam_search\u001b[0;34m(x_data, y_label, class_reg)\u001b[0m\n\u001b[1;32m     47\u001b[0m        xgb_bayes_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel(), callback \u001b[38;5;241m=\u001b[39m on_step)\n\u001b[1;32m     48\u001b[0m    \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m        \u001b[43mxgb_bayes_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m  \u001b[38;5;66;03m#  print(\"BEST PARAMS ARE HERE\")\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#   print(xgb_bayes_search.best_params_)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m    model \u001b[38;5;241m=\u001b[39m xgb_bayes_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skopt/searchcv.py:692\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 692\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skopt/searchcv.py:579\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    577\u001b[0m refit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit \u001b[38;5;241m=\u001b[39m refit\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# merge existing and new cv_results_\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skopt/searchcv.py:398\u001b[0m, in \u001b[0;36mBayesSearchCV._fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    393\u001b[0m cv \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmodel_selection\u001b[38;5;241m.\u001b[39m_validation\u001b[38;5;241m.\u001b[39mcheck_cv(\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer_ \u001b[38;5;241m=\u001b[39m check_scoring(\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring)\n\u001b[0;32m--> 398\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m n_splits \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parameter_iterable, Sized):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:248\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    List of objects to ensure sliceability.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 248\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:211\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    209\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths])\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [528, 1056]"
     ]
    }
   ],
   "source": [
    "#as one big script to go through n_games\n",
    "n_games = [2,3,10]\n",
    "#n_games = [4,5,6]\n",
    "for n in n_games:\n",
    "    run_all_models(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best of 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_test(n_games,ohe):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "    #manual update cbf automating this part as this is just a rough check to see how well best of 3 does\n",
    "    x_data = x_data.tail(1817)\n",
    "    \n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, ohe, 1, cv)\n",
    "    \n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_models(n):\n",
    "    clf = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    #clf = pickle.load(open(\"Models/best_xgb_clas_FS_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    ohe = pickle.load(open(\"Models/ohe_\"+str(n)+\"_no_2021_games.dat\", \"rb\"))\n",
    "    fs_filename = 'Models/fs_criteria_'+str(n)+'.dat'\n",
    "    selector = pickle.load(open(fs_filename, \"rb\"))\n",
    "    return clf, ohe, selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no202010_games.csv')\n",
    "\n",
    "model_2, ohe, selector = load_test_models(2)\n",
    "x_2 = prep_data_test(2,ohe)\n",
    "#x_2 = selector.transform(x_2)\n",
    "#x_2 = pd.DataFrame(x_2)\n",
    "\n",
    "model_3, ohe, selector = load_test_models(3)\n",
    "x_3 = prep_data_test(3, ohe)\n",
    "#x_3 = selector.transform(x_3)\n",
    "#x_3 = pd.DataFrame(x_3)\n",
    "\n",
    "model_4, ohe, selector = load_test_models(4)\n",
    "x_4 = prep_data_test(4, ohe)\n",
    "#x_4 = selector.transform(x_4)\n",
    "#x_4 = pd.DataFrame(x_4)\n",
    "\n",
    "model_5, ohe, selector = load_test_models(5)\n",
    "x_5 = prep_data_test(5, ohe)\n",
    "#x_5 = selector.transform(x_5)\n",
    "#x_5 = pd.DataFrame(x_5)\n",
    "\n",
    "model_6, ohe, selector = load_test_models(6)\n",
    "x_6 = prep_data_test(6, ohe)\n",
    "#x_6 = selector.transform(x_6)\n",
    "#x_6 = pd.DataFrame(x_6)\n",
    "\n",
    "model_10, ohe, selector = load_test_models(10)\n",
    "x_10 = prep_data_test(10, ohe)\n",
    "#x_10 = selector.transform(x_10)\n",
    "#x_10 = pd.DataFrame(x_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       1.0       1.0  0.666667\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          1.0       1.0       1.0  1.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       1.0  0.333333\n",
      "..         ...       ...       ...       ...\n",
      "177        1.0       1.0       1.0  1.000000\n",
      "178        0.0       1.0       0.0  0.333333\n",
      "179        0.0       1.0       1.0  0.666667\n",
      "180        1.0       1.0       0.0  0.666667\n",
      "181        0.0       1.0       0.0  0.333333\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "[0.6666666666666666, 0.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333]\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "The accuracy of this model is72.52747252747253\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3  average\n",
      "0          1.0       1.0       1.0      1.0\n",
      "1          0.0       0.0       0.0      0.0\n",
      "2          1.0       1.0       1.0      1.0\n",
      "3          0.0       0.0       0.0      0.0\n",
      "4          0.0       0.0       0.0      0.0\n",
      "..         ...       ...       ...      ...\n",
      "177        0.0       0.0       0.0      0.0\n",
      "178        1.0       1.0       1.0      1.0\n",
      "179        0.0       0.0       0.0      0.0\n",
      "180        0.0       0.0       0.0      0.0\n",
      "181        0.0       0.0       0.0      0.0\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "[1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "The accuracy of this model is69.78021978021978\n",
      "Split: 3\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          0.0       1.0       1.0  0.666667\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "177        0.0       0.0       0.0  0.000000\n",
      "178        0.0       1.0       1.0  0.666667\n",
      "179        1.0       1.0       1.0  1.000000\n",
      "180        0.0       1.0       0.0  0.333333\n",
      "181        1.0       1.0       1.0  1.000000\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "[1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "The accuracy of this model is70.87912087912088\n",
      "Split: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          1.0       1.0       1.0  1.000000\n",
      "2          1.0       1.0       1.0  1.000000\n",
      "3          0.0       1.0       1.0  0.666667\n",
      "4          1.0       1.0       1.0  1.000000\n",
      "..         ...       ...       ...       ...\n",
      "177        0.0       1.0       1.0  0.666667\n",
      "178        0.0       0.0       0.0  0.000000\n",
      "179        0.0       1.0       0.0  0.333333\n",
      "180        0.0       0.0       0.0  0.000000\n",
      "181        1.0       1.0       0.0  0.666667\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "[1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666]\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "The accuracy of this model is65.93406593406593\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       0.0       0.0  0.000000\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          0.0       1.0       0.0  0.333333\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "177        0.0       0.0       0.0  0.000000\n",
      "178        0.0       0.0       0.0  0.000000\n",
      "179        0.0       0.0       0.0  0.000000\n",
      "180        0.0       1.0       0.0  0.333333\n",
      "181        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "[0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "The accuracy of this model is66.48351648351648\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "177        0.0       0.0       0.0  0.000000\n",
      "178        0.0       1.0       1.0  0.666667\n",
      "179        0.0       0.0       0.0  0.000000\n",
      "180        0.0       0.0       0.0  0.000000\n",
      "181        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0]\n",
      "[1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "The accuracy of this model is59.34065934065934\n",
      "Split: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       1.0       1.0  0.666667\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          0.0       1.0       0.0  0.333333\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "177        0.0       0.0       0.0  0.000000\n",
      "178        0.0       0.0       0.0  0.000000\n",
      "179        1.0       1.0       1.0  1.000000\n",
      "180        1.0       1.0       0.0  0.666667\n",
      "181        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[182 rows x 4 columns]\n",
      "[0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "The accuracy of this model is68.13186813186813\n",
      "Split: 8\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "176        0.0       1.0       0.0  0.333333\n",
      "177        0.0       0.0       0.0  0.000000\n",
      "178        0.0       0.0       0.0  0.000000\n",
      "179        0.0       0.0       0.0  0.000000\n",
      "180        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[181 rows x 4 columns]\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "The accuracy of this model is70.1657458563536\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       0.0       0.0  0.000000\n",
      "1          1.0       1.0       1.0  1.000000\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       1.0       1.0  0.666667\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "176        1.0       1.0       1.0  1.000000\n",
      "177        0.0       0.0       0.0  0.000000\n",
      "178        0.0       0.0       0.0  0.000000\n",
      "179        1.0       1.0       1.0  1.000000\n",
      "180        0.0       1.0       0.0  0.333333\n",
      "\n",
      "[181 rows x 4 columns]\n",
      "[0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333]\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "The accuracy of this model is64.64088397790056\n",
      "Split: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          0.0       1.0       0.0  0.333333\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "176        0.0       0.0       0.0  0.000000\n",
      "177        1.0       0.0       0.0  0.333333\n",
      "178        0.0       0.0       0.0  0.000000\n",
      "179        1.0       1.0       1.0  1.000000\n",
      "180        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[181 rows x 4 columns]\n",
      "[1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0]\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "The accuracy of this model is67.40331491712708\n",
      "Best win percentage split = 0\n",
      "Training Testing Accuracy: 67.53% (3.57%)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "count = 0\n",
    "high_w = 0\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "y = y_label\n",
    "for train,test in cv.split(x_2,y):\n",
    "    count = count + 1\n",
    "    print(\"Split: \" + str(count))\n",
    "    prediction = model_2.fit(x_2.loc[train],y.loc[train]).predict_proba(x_2.loc[test])\n",
    "    prediction = model_3.fit(x_3.loc[train],y.loc[train]).predict_proba(x_3.loc[test])\n",
    "    #prediction = model_4.fit(x_4.loc[train],y.loc[train]).predict_proba(x_4.loc[test])\n",
    "    #prediction = model_5.fit(x_5.loc[train],y.loc[train]).predict_proba(x_5.loc[test])\n",
    "    #prediction = model_6.fit(x_6.loc[train],y.loc[train]).predict_proba(x_6.loc[test])\n",
    "    prediction = model_10.fit(x_10.loc[train],y.loc[train]).predict_proba(x_10.loc[test])\n",
    "    print(\"variables for auroc curve done. Processing fold accuracy + checking best model\")\n",
    "    d = {'y_pred_10':model_10.predict(x_10.loc[test]),\n",
    "         'y_pred_2':model_2.predict(x_2.loc[test]), 'y_pred_3':model_3.predict(x_3.loc[test])}\n",
    "    pred_df = pd.DataFrame(data=d)\n",
    "    summary_ave_data = pred_df.copy()\n",
    "    summary_ave_data['average'] = summary_ave_data.mean(numeric_only=True, axis=1)\n",
    "    print(summary_ave_data)\n",
    "    y_pred = summary_ave_data[\"average\"].tolist()\n",
    "    print(y_pred)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    print(predictions)\n",
    "    #sees how accurate the model was when testing the test set\n",
    "    accuracy = accuracy_score(y.loc[test], predictions)\n",
    "    pcent = accuracy * 100.0\n",
    "    print(\"The accuracy of this model is\" + str(pcent))\n",
    "    results.append(pcent)\n",
    "print(\"Best win percentage split = \" +str(high_w))\n",
    "print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced Multicollinearity Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "n_games = 2\n",
    "model = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "thresholds = sort(model.feature_importances_)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find multicollinearaity and then reduce it\n",
    "\n",
    "#def feature_select(x_data, clf):\n",
    "n_games = 2\n",
    "h = get_headers(n_games)\n",
    "h = clean_headers(h)\n",
    "cv = generate_categorical_headers(h)\n",
    "\n",
    "#to get names of teams from index\n",
    "g = gad()\n",
    "teams = g.createTeamDict()\n",
    "\n",
    "#load Data\n",
    "x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "#make empty OHE object\n",
    "na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#one hot encode data with new one hot encoder, saves ohe for later use\n",
    "x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "#filename = 'Models/ohe_'+str(n_games)+'_no_2021_games_fs.dat'\n",
    "#pickle.dump(ohe, open(filename, \"wb\"))\n",
    "#reset headers\n",
    "feature_names = x_data.columns\n",
    "\n",
    "#loads the ylabel matrix,\n",
    "y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "#loads margin as the y_label\n",
    "margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "print(margin_label.shape)\n",
    "print(y_label.shape)\n",
    "print(x_data.shape)\n",
    "\n",
    "#regex solution which is apparently necessary??\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "model = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "margin_model = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "\n",
    "# margin_label = abs(margin_label)\n",
    "print(margin_label)\n",
    "best_xgb_clas, best_xgb_reg = eval_xgb_games_margins(x_data, y_label, model, x_data, margin_label, margin_model)\n",
    "\n",
    "best_threshold = threshold_search(x_data, y_label, best_xgb_clas)\n",
    "selection = SelectFromModel(best_xgb_clas, threshold=best_threshold, prefit=True)\n",
    "print(selection)\n",
    "selection_x_data = selection.transform(x_data)\n",
    "selection_x_data = pd.DataFrame(selection_x_data)\n",
    "\n",
    "fs_filename = 'Models/fs_criteria_'+str(n_games)+'.dat'\n",
    "pickle.dump(selection, open(fs_filename, \"wb\"))\n",
    "\n",
    "fs_model = param_search(selection_x_data, y_label, 0)\n",
    "\n",
    "best_xgb_fs_clas, best_xgb_reg = eval_xgb_games_margins(selection_x_data, y_label, fs_model, x_data, margin_label, margin_model)\n",
    "\n",
    "pickle.dump(best_xgb_fs_clas, open(\"Models/best_xgb_clas_FS_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))\n",
    "    #return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_threshold_cv(x, y, m):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "    mean_acc = (np.mean(results))\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(x_data, y_label, best_xgb_clas):\n",
    "    thresholds = sort(best_xgb_clas.feature_importances_)\n",
    "    threshold_array = []\n",
    "    threshold_accuracies = []\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(best_xgb_clas, threshold=thresh, prefit=True)\n",
    "        selection_x_data = selection.transform(x_data)\n",
    "        selection_x_data = pd.DataFrame(selection_x_data)\n",
    "        if(thresh > 0 ):\n",
    "            threshold_array.append(thresh)\n",
    "            selection_model = XGBClassifier()\n",
    "            acc = eval_threshold_cv(selection_x_data, y_label, selection_model)\n",
    "            threshold_accuracies.append(acc)\n",
    "            print(\"Thresh=%.10f, n=%d, Accuracy: %.2f%%\" % (thresh, selection_x_data.shape[1], acc))\n",
    "    i = 0\n",
    "    max_acc = 0\n",
    "    max_i = 0\n",
    "    max_thresh = 0\n",
    "    for x in threshold_array:\n",
    "        current_acc = threshold_accuracies[i]\n",
    "        if(current_acc > max_acc):\n",
    "            max_acc = current_acc\n",
    "            max_thresh = x\n",
    "            max_i = i\n",
    "        i = i + 1\n",
    "    print(\"max accuracy is: \" + str(max_acc) + \"for threshold: \" + str(max_thresh))\n",
    "    return max_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_2_thresh = \n",
    "n_3_thresh =\n",
    "n_10_thresh = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this a method param later\n",
    "#n_games = 5\n",
    "def run_all_models(n_games):\n",
    "    #load headers and then subsequently categorical headers\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "    filename = 'Models/ohe_'+str(n_games)+'_no_2021_games_fs.dat'\n",
    "    pickle.dump(ohe, open(filename, \"wb\"))\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "    \n",
    "    #DO STUFF Here\n",
    "    x_data = reduce_MC(x_data)\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #loads margin as the y_label\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    print(margin_label.shape)\n",
    "    print(y_label.shape)\n",
    "    print(x_data.shape)\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    #optimise XGBoost model\n",
    "\n",
    "    #for predicting win\n",
    "    model = param_search(x_data, y_label, 0)\n",
    "    #for predicting margin\n",
    "    #margin_label = abs(margin_label)\n",
    "    margin_model = clf = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "\n",
    "   # margin_label = abs(margin_label)\n",
    "    print(margin_label)\n",
    "    best_xgb_clas, best_xgb_reg = eval_xgb_games_margins(x_data, y_label, model, margin_label, margin_model)\n",
    "\n",
    "    #save\n",
    "    pickle.dump(best_xgb_clas, open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games_fs.dat\", \"wb\"))\n",
    "    #pickle.dump(best_xgb_reg, open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data Testing Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_R_TeamDict():\n",
    "    teams = {\n",
    "    \"1\" : \"Adelaide Crows\",\n",
    "    \"2\" : \"Brisbane Lions\",\n",
    "    \"3\" : \"Carlton\",\n",
    "    \"4\" : \"Collingwood\",\n",
    "    \"5\" : \"Essendon\",\n",
    "    \"6\" : \"Fremantle\",\n",
    "    \"7\" : \"Geelong Cats\",\n",
    "    \"8\" : \"Gold Coast Suns\",\n",
    "    \"9\" : \"GWS Giants\",\n",
    "    \"10\": \"Hawthorn\",\n",
    "    \"11\": \"Melbourne\",\n",
    "    \"12\": \"North Melbourne\",\n",
    "    \"13\": \"Port Adelaide\",\n",
    "    \"14\": \"Richmond\",\n",
    "    \"15\": \"St Kilda\",\n",
    "    \"16\": \"Sydney Swans\",\n",
    "    \"17\": \"West Coast Eagles\",\n",
    "    \"18\": \"Western Bulldogs\"\n",
    "    }\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_int = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pavs = pd.read_csv(\"R_Code/all_team_pavs.csv\")\n",
    "team_pavs = pavs.loc[(pavs[\"Team_ID\"]==team_int)]\n",
    "team_pavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sum_pav(year, rnd, team_int):\n",
    "    #do calc\n",
    "    g = gad()\n",
    "    team_dict = g.createTeamDict()\n",
    "    r_dict = create_R_TeamDict()\n",
    "    current_team = (team_dict[str(team_int)])\n",
    "    df = pd.read_csv(\"Data/\"+current_team+'_clean_stats.csv')\n",
    "    current_r_team = (r_dict[str(team_int)])\n",
    "    lineups = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "    lineups = lineups[lineups.isin([current_r_team]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([year]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([rnd]).any(axis=1)]\n",
    "    lineups['team'] = team_int\n",
    "    if(rnd < 11):\n",
    "        lineups['year'] = (year-1)\n",
    "    lineups.columns = ['year', 'teamname', 'roundNumber', 'firstname', 'surname', 'team']\n",
    "    cols = ['team', 'year', 'firstname', 'surname']\n",
    "    lineups = lineups[cols]\n",
    "    all_pavs = pd.read_csv(\"R_Code/all_player_PAVs.csv\")\n",
    "    \n",
    "    lineups.firstname = lineups.firstname.str.split(' ').str[0]\n",
    "    all_pavs.firstname = all_pavs.firstname.str.replace(' ','')\n",
    "    \n",
    "    lineups = lineups.merge(all_pavs, how='inner', on=['team', 'year', 'firstname', 'surname'])\n",
    "    if(lineups.shape[0] > 0):\n",
    "        pav = lineups['PAV_total'].sum()\n",
    "    else:\n",
    "        pav = 999\n",
    "    print(pav)\n",
    "    pav_array = [year, rnd, team_int, pav]\n",
    "    return pav_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pav_array = []\n",
    "for team_id in range(1,19):\n",
    "    for year in range(2022, 2023):\n",
    "        for rnd in range(1,5):\n",
    "            print(str(team_id) + '_' + str(year)+'_'+str(rnd))\n",
    "            pa = calc_sum_pav(year, rnd, team_id)\n",
    "            if(pa[3] == 999):\n",
    "                continue\n",
    "            pav_array.append(pa)\n",
    "pav_df = pd.DataFrame(pav_array, columns=['Year', 'Round', 'Team_ID', 'Player_PAV_Total'])\n",
    "all_pav_df = pd.read_csv('R_Code/all_team_pavs.csv')\n",
    "all_pav_df = pd.concat([all_pav_df, pav_df], ignore_index=True)\n",
    "print(pav_df)\n",
    "print(all_pav_df)\n",
    "all_pav_df.to_csv(\"R_Code/all_team_pavs.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Based Dataset Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get assemble_df code from the clean_dataset csv\n",
    "#do the usual stuff appended at the front eg. venue, ladder, round, H_team_id, A_team_id\n",
    "#pick averageable statistics and get n_game average for home and away\n",
    "#function to workout from clean_dataset home_team wins against away team in last 5\n",
    "    #5-home_team_wins to get away team wins against oppo\n",
    "    #append to new X_data\n",
    "#save to new assemble_df.csv\n",
    "\n",
    "match_id = 10576\n",
    "team_id = 9\n",
    "oppo_id = 6\n",
    "g = gad()\n",
    "teams = g.createTeamDict()\n",
    "n_games = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_form(ct, ot, match_id):\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "    current_team = (teams[str(ct)])\n",
    "    team_string = current_team+\"_clean_stats.csv\"\n",
    "    df = pd.read_csv(\"Data/\"+team_string)\n",
    "    idx = df.index[df['Match_ID'] == match_id]\n",
    "    my_idx = idx[0]\n",
    "    df = df.loc[0:my_idx-1,:]\n",
    "    prev_games = df.loc[(df['Team_against_ID']==ot)]\n",
    "    #return last 5 games against each other and 8th column is whether the ct won against ot\n",
    "    l = 5\n",
    "    if(prev_games.shape[0] < 5):\n",
    "        l = prev_games.shape[0]\n",
    "    if(l==0):\n",
    "        wins = 0\n",
    "    else:\n",
    "        prev_games = prev_games.iloc[-l: , 8]\n",
    "        wins = prev_games.sum()\n",
    "    return wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prev_games(match_id, team_id, teams, n_games, oppo_id):\n",
    "    margin = None\n",
    "    ma = None\n",
    "    y_label = None\n",
    "    trend_cg = []\n",
    "    current_team = (teams[str(team_id)])\n",
    "    print(current_team)\n",
    "    print(match_id)\n",
    "    team_string = current_team+\"_clean_stats.csv\"\n",
    "    df = pd.read_csv(\"Data/\"+team_string)\n",
    "    #drops ladder stats\n",
    "    #finds where in the dataframe the current match is\n",
    "    idx = df.index[df['Match_ID'] == match_id]\n",
    "    #print(idx)\n",
    "    my_idx = idx[0]\n",
    "    #splits dataframe into game data and end of round ladder data\n",
    "    l_df = df.iloc[:,-5:]\n",
    "    t_df = df.iloc[: , :-5]\n",
    "    current_year = t_df.loc[my_idx][1]\n",
    "    if(current_year == 2020.0):\n",
    "        print('game in 2020')\n",
    "        margin = 8888\n",
    "    else:\n",
    "        #turns the WWWLL form column into # of W\n",
    "        n_form = []\n",
    "        for x in l_df['form']:\n",
    "            if(len(x)<n_games):\n",
    "                y=float(x.count(\"W\"))\n",
    "                n_form.append(y)\n",
    "            else:\n",
    "                x=x[-n_games:]\n",
    "                y=float(x.count(\"W\"))\n",
    "                n_form.append(y)\n",
    "        l_df['form'] = n_form\n",
    "        #checks to make sure there is enough games to go through\n",
    "        if(my_idx < (n_games)):\n",
    "            print('Num of Prev Games Exceeds previous games')\n",
    "            margin = 9999\n",
    "        else:\n",
    "            #start match array with the ladder values from end of previous round (as this would be current for predicting round)\n",
    "            ma = l_df.loc[my_idx-1].values\n",
    "            #finds both labels for models\n",
    "            y_label = t_df.loc[my_idx][\"H/A Win?\"]\n",
    "            margin = t_df.loc[my_idx][\"Margin\"]\n",
    "            #start from the previous game to current game\n",
    "            #i is to know how many games included\n",
    "            i = 1\n",
    "            #j finds the previous game and allows for 2020 exclusion\n",
    "            j = 1\n",
    "            while i <= n_games:\n",
    "                year = t_df.loc[my_idx-j][1]\n",
    "                if(year == 2020.0):\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                cg = t_df.loc[my_idx-j][2:].values\n",
    "                trend_cg.append(cg)\n",
    "                i = i + 1\n",
    "                j = j + 1\n",
    "            my_df = pd.DataFrame(trend_cg, columns = t_df.columns[2:])\n",
    "            my_df = my_df.iloc[:,3:-1]\n",
    "            cg = my_df.mean(axis=0)\n",
    "            ma = [*ma, *cg]\n",
    "            h_form = find_form(team_id, oppo_id, match_id)\n",
    "            o_form = find_form(oppo_id, team_id, match_id)\n",
    "            form_diff = h_form-o_form\n",
    "            ma.append(form_diff)\n",
    "    return ma, y_label, margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "home_array, y_label, margin = create_prev_games(5720, team_id, teams, 3, oppo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(home_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Round', 'Home_Team', 'Away_Team', 'Venue']\n",
    "example_file = pd.read_csv('Data/Fremantle_clean_stats.csv')\n",
    "cl_h = example_file.columns\n",
    "cl_h = cl_h[5:-6]\n",
    "ladder_header = ['Ladder Pos_H', 'Form_H', 'Season Wins_H', 'Season Loss_H', 'Season Draw_H']\n",
    "headers = [*headers, *ladder_header]\n",
    "for x in cl_h:\n",
    "    if 'Match_ID' in x or 'Year' in x:\n",
    "        continue\n",
    "    x = 'H_'+ x + ' avg'\n",
    "    headers.append(x)\n",
    "headers.append(\"H_Recent_Matchup_Diff\")\n",
    "ladder_header = ['Ladder Pos_A', 'Form_A', 'Season Wins_A', 'Season Loss_A', 'Season Draw_A']\n",
    "headers = [*headers, *ladder_header]\n",
    "for x in cl_h:\n",
    "    if 'Match_ID' in x or 'Year' in x:\n",
    "        continue\n",
    "    x = 'A_'+ x + ' avg'\n",
    "    headers.append(x)\n",
    "headers.append(\"A_Recent_Matchup_Diff\")\n",
    "len(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Specific Models\n",
    "## Averaged about 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_specific_dataset(n_games, tn):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "    #load in x_data and y_label for n = 1 (quicker)\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #finds team index\n",
    "    team_idx = x_data.index[(x_data['Home_Team']==tn) | (x_data['Away_Team']==tn)]\n",
    "    team_x_data = x_data.iloc[team_idx]\n",
    "    team_y_data = y_label.iloc[team_idx]\n",
    "    team_x_data.reset_index(drop=True, inplace=True)\n",
    "    team_y_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #quick shape check\n",
    "    print(team_x_data.shape)\n",
    "    print(team_y_data.shape)\n",
    "    l = team_x_data.shape[0]\n",
    "\n",
    "    #loop for new y_array\n",
    "    i = 0\n",
    "    new_team_y = []\n",
    "    while i < l:\n",
    "        x = team_x_data.iloc[i]\n",
    "        y = team_y_data.iloc[i]\n",
    "        #if our team for current model is the home team\n",
    "        if(x[\"Home_Team\"] == tn):\n",
    "            #and the home team has won\n",
    "            if(y[\"H/A Win?\"] == 0):\n",
    "                #set win val to 1\n",
    "                w_val = 1\n",
    "            #else they're the home team but the away team won\n",
    "            else:\n",
    "                #set win val to 0\n",
    "                w_val = 0\n",
    "        #else they're the away team\n",
    "        else:\n",
    "            #if the home team won, that means they lost\n",
    "            if(y[\"H/A Win?\"] == 0):\n",
    "                w_val = 0\n",
    "            #else they're the away team and they won\n",
    "            else:\n",
    "                w_val = 1\n",
    "        i = i + 1\n",
    "        new_team_y.append(w_val)\n",
    "    ny = pd.DataFrame(new_team_y, columns=['Team Won?'])\n",
    "    return team_x_data, ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_team_specific_dataset(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_team_xgb_games(x, y, m, n_games, tn):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "        #change the best model to equal current model\n",
    "        if(pcent > high_w):\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "    print(\"Training Testing Accuracy for n_games=\"+str(n_games)+\" team=\"+str(tn)+\" : %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_w, np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_team_models(n_games, tn):\n",
    "    #load headers and then subsequently categorical headers\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data, y_label = get_team_specific_dataset(n_games, tn)\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "    filename = 'Models/Team_OHE/ohe_'+str(n_games)+\"_team_specific_\"+str(tn)+'_no_2020_games.dat'\n",
    "    pickle.dump(ohe, open(filename, \"wb\"))\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    #optimise XGBoost model\n",
    "    #print(x_data)\n",
    "    #for predicting win\n",
    "    model = param_search(x_data, y_label, 0)\n",
    "    best_xgb_clas, model_av = eval_team_xgb_games(x_data, y_label, model, n_games, tn)\n",
    "\n",
    "    #save\n",
    "    pickle.dump(best_xgb_clas, open(\"Models/Team_Models/best_xgb_clas_no2020_\"+str(n_games)+\"_team_specific_\"+str(tn)+'_.dat', \"wb\"))\n",
    "    return model_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for n in range(1,11):\n",
    "    averages = []\n",
    "    for tn in range(1,19):\n",
    "        a = run_team_models(n, tn)\n",
    "        averages.append(a)\n",
    "    print(\"Accuracy for Team Models for n_games= \"+str(n)+\" : %.2f%% (%.2f%%)\" % (np.mean(averages), np.std(averages)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import re\n",
    "from numpy import arange\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(n_games):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #loads margin as the y_label\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    print(margin_label.shape)\n",
    "    print(y_label.shape)\n",
    "    print(x_data.shape)\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "    return x_data, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_NC(x_data, y_label):\n",
    "# define model\n",
    "    print(\"optimising hyperparameters\")\n",
    "    model = NearestCentroid()\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # define grid\n",
    "    grid = dict()\n",
    "    grid['shrink_threshold'] = arange(0, 1.01, 0.01)\n",
    "    grid['metric'] = ['euclidean', 'manhattan']\n",
    "    # define search\n",
    "    search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # perform the search\n",
    "    results = search.fit(x_data, y_label.values.ravel())\n",
    "    # summarize\n",
    "    print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "    print('Config: %s' % results.best_params_)\n",
    "    return results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_NC(x, y, m):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    results = []\n",
    "    print(x)\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    for train,test in cv.split(x,y):\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        x_train = x.loc[train]\n",
    "        y_train = y.loc[train].values.ravel()\n",
    "        x_test = x.loc[test]\n",
    "        y_test = y.loc[test]\n",
    "        m.fit(x_train,y_train)\n",
    "        y_pred = m.predict(x_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "        if(pcent > high_w):\n",
    "            print(\"found new best classify\")\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "    print(\"Best win percentage split = \" +str(high_w))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_all_NC(n):\n",
    "    x_data, y_label = load_data(n)\n",
    "    best_params = params_NC(x_data, y_label)\n",
    "    model = NearestCentroid(**best_params)\n",
    "    best_NC_clas = eval_NC(x_data, y_label, model)\n",
    "    pickle.dump(best_NC_clas, open(\"Models/best_NC_clas_no2020\"+str(n_games)+'_games.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games = [1,2,3,4,5,6,7,10]\n",
    "for n in n_games:\n",
    "    run_all_NC(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_BNB(x_data, y_label):\n",
    "# define model\n",
    "    print(\"optimising hyperparameters\")\n",
    "    model = BernoulliNB()\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # define grid\n",
    "    grid = dict()\n",
    "    grid['alpha'] = arange(0.01, 1.01, 0.01)\n",
    "    # define search\n",
    "    search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=1, verbose=1)\n",
    "    # perform the search\n",
    "    results = search.fit(x_data, y_label.values.ravel())\n",
    "    # summarize\n",
    "    print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "    print('Config: %s' % results.best_params_)\n",
    "    return results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_BNB(x, y, m):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    results = []\n",
    "    print(x)\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    for train,test in cv.split(x,y):\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        x_train = x.loc[train]\n",
    "        y_train = y.loc[train].values.ravel()\n",
    "        x_test = x.loc[test]\n",
    "        y_test = y.loc[test]\n",
    "        m.fit(x_train,y_train)\n",
    "        y_pred = m.predict(x_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "        if(pcent > high_w):\n",
    "            print(\"found new best classify\")\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "    print(\"Best win percentage split = \" +str(high_w))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_BNB(n):\n",
    "    x_data, y_label = load_data(n)\n",
    "    best_params = params_BNB(x_data, y_label)\n",
    "    model = BernoulliNB(**best_params)\n",
    "    best_BNB_clas = eval_BNB(x_data, y_label, model)\n",
    "    pickle.dump(best_BNB_clas, open(\"Models/best_BNB_clas_no2020\"+str(n_games)+'_games.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_games = [1,2,3,4,5,6,7,10]\n",
    "for n in n_games:\n",
    "    run_all_BNB(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAZY PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lazy_predict(x, y, my):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    all_clf_models = []\n",
    "    all_reg_models = []\n",
    "    count = 0\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        #classifier\n",
    "        X_train = x.loc[train]\n",
    "        X_test = x.loc[test]\n",
    "        y_train = y.loc[train]\n",
    "        y_test = y.loc[test]\n",
    "        my_train = my.loc[train]\n",
    "        my_test = my.loc[test]\n",
    "        clf = LazyClassifier(predictions=True)\n",
    "        reg = LazyRegressor(predictions=True)\n",
    "        if(count == 1):\n",
    "            all_clf_models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "          #  all_reg_models, reg_predictions = reg.fit(X_train, X_test, my_train, my_test)\n",
    "            all_clf_models.sort_index(inplace=True)\n",
    "           # all_reg_models.sort_index(inplace=True)\n",
    "            #print(all_models)\n",
    "        else:\n",
    "            new_clf_models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "           # new_reg_models, reg_predictions = reg.fit(X_train, X_test, my_train, my_test)\n",
    "            new_clf_models.sort_index(inplace=True)\n",
    "           # new_reg_models.sort_index(inplace=True)\n",
    "            #print(new_models)\n",
    "            all_clf_models = all_clf_models.add(new_clf_models)\n",
    "           # all_reg_models = all_reg_models.add(new_reg_models)\n",
    "    return all_clf_models#, all_reg_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_all_lp(n_games):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #do margins in a second when this works\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "    margin_label = abs(margin_label)\n",
    "\n",
    "    clf_lp = eval_lazy_predict(x_data, y_label, margin_label)\n",
    "\n",
    "    clf_lp.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "    #reg_lp.sort_values(by='RMSE', inplace=True)\n",
    "    pct_lp = clf_lp*10\n",
    "    print(pct_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#as one big script to go through n_games\n",
    "n_games = [1,2,3,4,5,6,7,10]\n",
    "for n in n_games:\n",
    "    run_all_lp(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learningggg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DNN_model(x_len):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(63, input_dim = x_len))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.03))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.02))\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('relu'))\n",
    "    #add output layer\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_model(x_len):\n",
    "    #del model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=14,\n",
    "                     input_shape=(x_len, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=16, kernel_size=10,\n",
    "                     input_shape=(32, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=10, kernel_size=8,\n",
    "                     input_shape=(16, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='linear'))\n",
    "    model.add(Dense(32, activation='linear'))\n",
    "    model.add(Dense(16, activation='linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
    "\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag = 0 (DNN)\n",
    "#flag = 1 (CNN)\n",
    "def eval_dl(x,y,k,flag):\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=True)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        if(flag == 0):\n",
    "            model = build_DNN_model(x[train].shape[1])\n",
    "        if(flag == 1):\n",
    "            x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "            model = build_CNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/20)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs = 50, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy * 100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        i = i + 1\n",
    "    print(\"highest accuracy is: \" + str(highest))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
