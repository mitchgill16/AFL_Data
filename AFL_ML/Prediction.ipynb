{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78df18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import xgboost as xgb\n",
    "#import torch.nn as nn\n",
    "#import touch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "#from fdnn import feature_extractor as fex\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import re\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d702dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get headers\n",
    "#feed this into a bigger function which specifies the amount of games to go through \n",
    "def get_headers(n_games):\n",
    "    headers = ['Round', 'Home_Team', 'Away_Team', 'Venue', 'H_PAV_Sum', 'A_PAV_Sum']\n",
    "    example_file = pd.read_csv('Data/Fremantle_clean_stats.csv')\n",
    "    cl_h = example_file.columns\n",
    "    cl_h = cl_h[:-5]\n",
    "    ladder_header = ['Ladder Pos_H', 'Form_H', 'Season Wins_H', 'Season Loss_H', 'Season Draw_H']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    j = 1\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'H_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    j = 1\n",
    "    ladder_header = ['Ladder Pos_A', 'Form_A', 'Season Wins_A', 'Season Loss_A', 'Season Draw_A']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'A_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e83d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headers(h):\n",
    "    headers = []\n",
    "    for x in h:\n",
    "        if '<' in x or '>' in x:\n",
    "            x = x.replace('<',\"lt_\")\n",
    "            x = x.replace('>', \"gt_\")\n",
    "            #print(x)\n",
    "        headers.append(str(x))\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f930a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_categorical_headers(h):\n",
    "    cat_var = ['Round', 'Home_Team', 'Away_Team']\n",
    "    skip = 0\n",
    "    for x in h:\n",
    "        if 'Round' in x:\n",
    "            if (skip == 0):\n",
    "                skip = 1\n",
    "                continue\n",
    "            cat_var.append(x)\n",
    "            #print(x)\n",
    "        elif 'Team_against_ID' in x:\n",
    "            #print(x)\n",
    "            cat_var.append(x)\n",
    "        elif 'Venue' in x:\n",
    "            cat_var.append(x)\n",
    "    return cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0537bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode data and transform the X_data\n",
    "#first redo, find the categorial variables\n",
    "def ohe_data(x_data, enc, flag,cat_var):\n",
    "    #data has not been previously one hot encoded\n",
    "    if (flag == 0):\n",
    "        #get columns with categorical data and drop from main DF\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        #define and fit new OHE. Use it on our categorical data by transforming\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        ohe = ohe.fit(categorical_data)\n",
    "        categorical_data = ohe.transform(categorical_data)\n",
    "        #get feature names for better labelling\n",
    "        fn = ohe.get_feature_names(cat_var)\n",
    "        #make a dataframe with new OHE data and feature names\n",
    "            #would have been good to have coded it like this for my Masters project...\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        #ensure that it won't get cranky about any different indexes(shouldn't be any but just a good check)\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        #concatenate along column axis\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1)\n",
    "    else:\n",
    "        #same as above except used already fitted ohe\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        categorical_data = enc.transform(categorical_data)\n",
    "        fn = enc.get_feature_names(cat_var)\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1)\n",
    "        ohe = enc\n",
    "    return x_data, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790399f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(n):\n",
    "    clf = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    reg = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    ohe = pickle.load(open(\"Models/ohe_\"+str(n)+\"_no_2021_games.dat\", \"rb\"))\n",
    "    return clf, reg, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5916b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prev_games(team_id, n_games, teams):\n",
    "    ma = None\n",
    "    current_team = (teams[str(team_id)])\n",
    "    team_string = current_team+\"_clean_stats.csv\"\n",
    "    df = pd.read_csv(\"Data/\"+team_string)\n",
    "    df = df.iloc[::-1]\n",
    "    df = df.head(n_games)\n",
    "    df = df.reset_index()\n",
    "    #print(df)\n",
    "    #drops ladder stats\n",
    "    #finds where in the dataframe the current match is\n",
    "    #splits dataframe into game data and end of round ladder data\n",
    "    l_df = df.iloc[:,-5:]\n",
    "    t_df = df.iloc[: , :-5]\n",
    "    #turns the WWWLL form column into # of W\n",
    "    n_form = []\n",
    "    for x in l_df['form']:\n",
    "        if(len(x)<n_games):\n",
    "            y=float(x.count(\"W\"))\n",
    "            n_form.append(y)\n",
    "        else:\n",
    "            x=x[-n_games:]\n",
    "            y=float(x.count(\"W\"))\n",
    "            n_form.append(y)\n",
    "    l_df['form'] = n_form\n",
    "\n",
    "    #checks to make sure there is enough games to go through\n",
    "    #start match array with the ladder values from end of previous round (as this would be current for predicting round)\n",
    "    ma = l_df.loc[0].values\n",
    "    #finds both labels for models\n",
    "    #start from the previous game to current game\n",
    "    #i is to know how many games included\n",
    "    i = 0\n",
    "    #j finds the previous game and allows for 2020 exclusion\n",
    "    while i < n_games:\n",
    "        cg = t_df.loc[i][3:].values\n",
    "        ma = [*ma, *cg]\n",
    "        i = i + 1\n",
    "    return ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1efe2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prev_games(home_id, away_id, round_num, venue, h_pav, a_pav, home_array, away_array):\n",
    "    current_example_array = [round_num, home_id, away_id, venue, h_pav, a_pav]\n",
    "    current_example_array.extend(home_array)\n",
    "    current_example_array.extend(away_array)\n",
    "    return current_example_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85cbc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(home_id, away_id, venue, round_num, h_pav, a_pav, n, teams):\n",
    "    \n",
    "    cea_df = []\n",
    "    home_array = create_prev_games(home_id, n, teams)\n",
    "    away_array = create_prev_games(away_id, n, teams)\n",
    "    cea = combine_prev_games(home_id, away_id, round_num, venue, h_pav, a_pav, home_array, away_array)\n",
    "    \n",
    "    cea_df.append(cea)\n",
    "    cea_df = pd.DataFrame(cea_df)\n",
    "    h = get_headers(n)\n",
    "    cea_df.columns = h\n",
    "    \n",
    "    clf, reg, ohe = load_models(n)\n",
    "    h = get_headers(n)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "    x_data, ohe = ohe_data(cea_df, ohe, 1, cv)\n",
    "    #I don't think this does anything, but I'm too scared to move it\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "    \n",
    "    \n",
    "    y = clf.predict(x_data)\n",
    "    yp = clf.predict_proba(x_data)\n",
    "    my = reg.predict(x_data)\n",
    "    my[0] = abs(my[0])\n",
    "    my[0] = round(my[0],0)\n",
    "    if(y < 0.5):\n",
    "        p = yp[:,0]*100\n",
    "        p = str(p)\n",
    "        #Could somehow make this print statement into a javascript thing for django?\n",
    "        #print(teams[str(home_id)] + \"(HOME) is predicted to win against \"+teams[str(away_id)]+\" with a \"+p[1:-1]+\"% chance by \" + str(my[0]) +\" points\")\n",
    "    elif(y > 0.5):\n",
    "        p = yp[:,1]*100\n",
    "        p = str(p)\n",
    "        #print(teams[str(away_id)] + \"(AWAY) is predicted to win against \"+teams[str(home_id)]+\"  with a \"+p[1:-1]+\"% chance by \" + str(my[0]) +\" points\")\n",
    "    else:\n",
    "        print(\"DRAW\")\n",
    "    return y, my[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d712a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sum_pav(year, rnd, team_int):\n",
    "    #do calc\n",
    "    g = gad()\n",
    "    team_dict = g.createTeamDict()\n",
    "    r_dict = create_R_TeamDict()\n",
    "    current_team = (team_dict[str(team_int)])\n",
    "    df = pd.read_csv(\"Data/\"+current_team+'_clean_stats.csv')\n",
    "    current_r_team = (r_dict[str(team_int)])\n",
    "    lineups = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "    #lower_case the line ups\n",
    "    lineups['player.playerName.givenName'] = lineups['player.playerName.givenName'].str.lower()\n",
    "    lineups['player.playerName.surname'] = lineups['player.playerName.surname'].str.lower()\n",
    "    #filter line ups to the current round year and team\n",
    "    lineups = lineups[lineups.isin([current_r_team]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([year]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([rnd]).any(axis=1)]\n",
    "    lineups['team'] = team_int\n",
    "    if(rnd < 6):\n",
    "        lineups['year'] = (year-1)\n",
    "    lineups.columns = ['year', 'teamname', 'roundNumber', 'firstname', 'surname', 'team']\n",
    "    cols = ['team', 'year', 'firstname', 'surname']\n",
    "    lineups = lineups[cols]\n",
    "    all_pavs = pd.read_csv(\"R_Code/all_player_PAVs.csv\")\n",
    "    #lowcase the all_pavs\n",
    "    all_pavs['firstname'] = all_pavs['firstname'].str.lower()\n",
    "    all_pavs['surname'] = all_pavs['surname'].str.lower()\n",
    "    \n",
    "    #name edits\n",
    "    lineups.firstname = lineups.firstname.str.split(' ').str[0]\n",
    "    all_pavs.firstname = all_pavs.firstname.str.replace(' ','')\n",
    "    \n",
    "    #funky code to get players that do not exist in the 2022 PAVs\n",
    "    xyz = lineups\n",
    "    xyz = (\n",
    "    xyz.merge(all_pavs, \n",
    "              on=['team', 'year', 'firstname', 'surname'], \n",
    "              how='outer', \n",
    "              indicator=True)\n",
    "    .query('_merge != \"both\"')\n",
    "    .drop(columns='_merge'))\n",
    "    xyz = xyz[xyz['PAV_total'].isna()]\n",
    "    \n",
    "    #drop the PAV_total column\n",
    "    xyz = xyz.drop(['PAV_total', 'team'], axis = 1)\n",
    "    xyz['year'] = xyz['year'] - 1\n",
    "    #merge with all_pavs but the year before incase they've previously had a PAV\n",
    "    xyz = xyz.merge(all_pavs, how='inner', on=['year', 'firstname', 'surname'])\n",
    "    \n",
    "    \n",
    "    lineups = lineups.merge(all_pavs, how='inner', on=['team', 'year', 'firstname', 'surname'])\n",
    "    #generate an old pav to add\n",
    "    old_pav = 0\n",
    "    if(xyz.shape[0] > 0):\n",
    "        old_pav = xyz['PAV_total'].sum()\n",
    "    print(\"pav from prev year = \"+str(old_pav))\n",
    "    ### if the line up exists\n",
    "    if(lineups.shape[0] > 0):\n",
    "        pav = lineups['PAV_total'].sum()\n",
    "    #doesn't exist and should be obvious to do soething here\n",
    "    else:\n",
    "        pav = 999\n",
    "    print(pav)\n",
    "    #round pav because it get weird about it\n",
    "    pav = round(pav,2)\n",
    "    old_pav = round(old_pav, 2)\n",
    "    pav = pav + old_pav\n",
    "    print(pav)\n",
    "    pav_array = [year, rnd, team_int, pav]\n",
    "    return pav_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6030b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_venue_dict():\n",
    "    vDict = {\n",
    "        \"1\" : \"MCG\",\n",
    "        \"2\" : \"Marvel Stadium\",\n",
    "        \"3\" : \"Optus Stadium\",\n",
    "        \"4\" : \"Adelaide Oval\",\n",
    "        \"5\" : \"SCG\",\n",
    "        \"6\" : \"Gabba\",\n",
    "        \"7\" : \"Metricon Stadium\",\n",
    "        \"8\" : \"GIANTS Stadium\",\n",
    "        \"9\" : \"GMHBA Stadium\",\n",
    "        \"10\" : \"Manuka Oval\",\n",
    "        \"11\" : \"Blundstone Arena\",\n",
    "        \"12\" : \"University of Tasmania Stadium\",\n",
    "        \"13\" : \"TIO Stadium\",\n",
    "        \"14\" : \"Accor Stadium Australia\",\n",
    "        \"15\" : \"Mars Stadium\",\n",
    "        \"16\" : \"Cazalys Stadium\"\n",
    "        }\n",
    "    return vDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1283e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_R_TeamDict():\n",
    "    teams = {\n",
    "    \"1\" : \"Adelaide Crows\",\n",
    "    \"2\" : \"Brisbane Lions\",\n",
    "    \"3\" : \"Carlton\",\n",
    "    \"4\" : \"Collingwood\",\n",
    "    \"5\" : \"Essendon\",\n",
    "    \"6\" : \"Fremantle\",\n",
    "    \"7\" : \"Geelong Cats\",\n",
    "    \"8\" : \"Gold Coast Suns\",\n",
    "    \"9\" : \"GWS Giants\",\n",
    "    \"10\": \"Hawthorn\",\n",
    "    \"11\": \"Melbourne\",\n",
    "    \"12\": \"North Melbourne\",\n",
    "    \"13\": \"Port Adelaide\",\n",
    "    \"14\": \"Richmond\",\n",
    "    \"15\": \"St Kilda\",\n",
    "    \"16\": \"Sydney Swans\",\n",
    "    \"17\": \"West Coast Eagles\",\n",
    "    \"18\": \"Western Bulldogs\"\n",
    "    }\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ab28921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the PAV for a team in round and year\n",
    "def get_pav(season, round_num, team_id):\n",
    "    p_df = pd.read_csv('R_Code/all_team_pavs.csv')\n",
    "    test_pav = p_df.loc[(p_df['Year'] == season) & (p_df['Round'] == round_num) & (p_df['Team_ID'] == team_id)]\n",
    "    x = test_pav['Player_PAV_Total'].values[0]\n",
    "    y = test_pav['Player_PAV_Total'].values\n",
    "    print(y)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3abbaf",
   "metadata": {},
   "source": [
    "# Start Prediction Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be506aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter here until you automate\n",
    "round_num = 25\n",
    "season = 2022\n",
    "home_teams = [11,4]\n",
    "away_teams = [2,6]\n",
    "v_ids = [1,1]\n",
    "\n",
    "#incremental running due to teams being announced incrementally\n",
    "start_match = 0\n",
    "end_match = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0beea2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89537, 5)\n",
      "(89449, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/home/chris/Documents/Mitch/AFL_Data/AFL_Data/django_AFL_ML\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ℹ Fetching match ids\n",
      "✔ Fetching match ids ... done\n",
      "\n",
      "ℹ Fetching lineups for \"2 matches\".\n",
      "✔ Fetching lineups for \"2 matches\". ... done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Adelaide Crows\"\n",
      "[1] \"Brisbane Lions\"\n",
      "[1] \"Carlton\"\n",
      "[1] \"Collingwood\"\n",
      "[1] \"Essendon\"\n",
      "[1] \"Fremantle\"\n",
      "[1] \"Geelong Cats\"\n",
      "[1] \"Gold Coast Suns\"\n",
      "[1] \"GWS Giants\"\n",
      "[1] \"Hawthorn\"\n",
      "[1] \"Melbourne\"\n",
      "[1] \"North Melbourne\"\n",
      "[1] \"Port Adelaide\"\n",
      "[1] \"Richmond\"\n",
      "[1] \"St Kilda\"\n",
      "[1] \"Sydney Swans\"\n",
      "[1] \"West Coast Eagles\"\n",
      "[1] \"Western Bulldogs\"\n",
      "(89537, 5)\n",
      "pav from prev year = 0\n",
      "272.96\n",
      "272.96\n",
      "pav from prev year = 0\n",
      "233.21\n",
      "233.21\n",
      "pav from prev year = 0\n",
      "259.44\n",
      "259.44\n",
      "pav from prev year = 0\n",
      "264.04\n",
      "264.04\n",
      "   Year  Round  Team_ID  Player_PAV_Total\n",
      "0  2022     25       11            272.96\n",
      "1  2022     25        2            233.21\n",
      "2  2022     25        4            259.44\n",
      "3  2022     25        6            264.04\n",
      "(4046, 4)\n",
      "(4042, 4)\n",
      "(4046, 4)\n",
      "(4046, 4)\n",
      "Mitchell's Crackhead Model Tips \n",
      "\n",
      "[272.96]\n",
      "[233.21]\n",
      "[259.44]\n",
      "[264.04]\n",
      "\n",
      "\n",
      "\n",
      "Rebeccas's Tips \n",
      "\n",
      "[272.96]\n",
      "[233.21]\n",
      "[259.44]\n",
      "[264.04]\n",
      "\n",
      "\n",
      "\n",
      "Tie Breaker Tips \n",
      "\n",
      "[272.96]\n",
      "[233.21]\n",
      "[259.44]\n",
      "[264.04]\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### RUN :) ######\n",
    "###################\n",
    "\n",
    "\n",
    "#load in dictionaries\n",
    "g = gad()\n",
    "teams = g.createTeamDict()\n",
    "vdict = create_venue_dict()\n",
    "\n",
    "#turn v_ids in venue names that are model\n",
    "venues = []\n",
    "for x in v_ids:\n",
    "    v = (vdict[str(x)])\n",
    "    venues.append(v)\n",
    "\n",
    "#check if the round and year data for lineups already exists and if so drop \n",
    "    #allows for multiple calls to update team lists as teams get announced\n",
    "\n",
    "df = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "print(df.shape)\n",
    "to_drop = df.index[(df['year'] == season) & (df['round.roundNumber'] == round_num) ]\n",
    "df = df.drop(to_drop)\n",
    "print(df.shape)\n",
    "df.to_csv(\"R_Code/all_lineups.csv\", header=True, index=False)\n",
    "    \n",
    "#update the all_lineups.csv\n",
    "subprocess.call([\"/usr/bin/Rscript\", \"R_Code/update_lineups.R\", str(season), str(round_num)])\n",
    "\n",
    "#check shape slightly reduces if lineup had previously existed\n",
    "df = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "#uses the now updated all_lineups.csv to calculate PAVs for the specified games\n",
    "#updates the all_team_pavs file for easier access below and if retraining models\n",
    "#maybe chuck a cheeky remove duplicates and sort by year round in here for error checks\n",
    "pa = []\n",
    "for x in range(start_match, end_match):\n",
    "    home_pav_array = calc_sum_pav(season, round_num, home_teams[x])\n",
    "    pa.append(home_pav_array)\n",
    "    away_pav_array = calc_sum_pav(season, round_num, away_teams[x])\n",
    "    pa.append(away_pav_array)\n",
    "pav_df = pd.DataFrame(pa, columns=['Year', 'Round', 'Team_ID', 'Player_PAV_Total'])\n",
    "print(pav_df)\n",
    "\n",
    "#drop previous entries to all_team_pavs in the round and year\n",
    "all_pav_df = pd.read_csv('R_Code/all_team_pavs.csv')\n",
    "print(all_pav_df.shape)\n",
    "pav_to_drop = all_pav_df.index[(all_pav_df['Year'] == season) & (all_pav_df['Round'] == round_num) ]\n",
    "all_pav_df = all_pav_df.drop(pav_to_drop)\n",
    "print(all_pav_df.shape)\n",
    "\n",
    "all_pav_df = pd.concat([all_pav_df, pav_df], ignore_index=True)\n",
    "\n",
    "\n",
    "#remove duplicates and sort by year then round incase of multiple runnings or stupidity\n",
    "print(all_pav_df.shape)\n",
    "all_pav_df = all_pav_df.drop_duplicates()\n",
    "print(all_pav_df.shape)\n",
    "all_pav_df = all_pav_df.sort_values([\"Year\", \"Round\"], ascending = (True, True))\n",
    "all_pav_df.to_csv(\"R_Code/all_team_pavs.csv\", header=True, index=False)\n",
    "\n",
    "tip_array = []\n",
    "margin_tip_array = []\n",
    "predict_round_num = round_num\n",
    "\n",
    "#Run the predictions\n",
    "# n is which n_games model\n",
    "n = 2\n",
    "print(\"Mitchell's Crackhead Model Tips \\n\")\n",
    "\n",
    "i=start_match\n",
    "while i<end_match:\n",
    "    home_id = home_teams[i]\n",
    "    away_id = away_teams[i]\n",
    "    \n",
    "    home_pav = get_pav(season, round_num, home_id)\n",
    "    away_pav = get_pav(season, round_num, away_id)\n",
    "    \n",
    "    venue = venues[i]\n",
    "    tip, margin_tip = predict(home_id, away_id, venue, predict_round_num, home_pav, away_pav, n, teams)\n",
    "    tip_array.append(tip[0])\n",
    "    margin_tip_array.append(margin_tip)\n",
    "    i = i + 1\n",
    "    \n",
    "i = start_match\n",
    "n = 10\n",
    "print(\"\\n\\n\\nRebeccas's Tips \\n\")\n",
    "while i<end_match:\n",
    "    home_id = home_teams[i]\n",
    "    away_id = away_teams[i]\n",
    "    \n",
    "    home_pav = get_pav(season, round_num, home_id)\n",
    "    away_pav = get_pav(season, round_num, away_id)\n",
    "    \n",
    "    venue = venues[i]\n",
    "    tip, margin_tip = predict(home_id, away_id, venue, predict_round_num, home_pav, away_pav, n, teams)\n",
    "    tip_array.append(tip[0])\n",
    "    margin_tip_array.append(margin_tip)\n",
    "    i = i + 1\n",
    "    \n",
    "i = start_match\n",
    "n = 3\n",
    "print(\"\\n\\n\\nTie Breaker Tips \\n\")\n",
    "while i<end_match:\n",
    "    home_id = home_teams[i]\n",
    "    away_id = away_teams[i]\n",
    "    \n",
    "    home_pav = get_pav(season, round_num, home_id)\n",
    "    away_pav = get_pav(season, round_num, away_id)\n",
    "    \n",
    "    venue = venues[i]\n",
    "    tip, margin_tip = predict(home_id, away_id, venue, predict_round_num, home_pav, away_pav, n, teams)\n",
    "    tip_array.append(tip[0])\n",
    "    margin_tip_array.append(margin_tip)\n",
    "    i = i + 1\n",
    "\n",
    "l = len(tip_array)\n",
    "tip_df = pd.DataFrame({'n=2': tip_array[0:l:3], 'n=3':tip_array[1:l:3], 'n=10':tip_array[2:l:3]})\n",
    "tip_df['mean'] = tip_df.mean(axis=1)\n",
    "margin_df = pd.DataFrame({'n=2': margin_tip_array[0:l:3], 'n=3':margin_tip_array[1:l:3], 'n=10':margin_tip_array[2:l:3]})\n",
    "margin_df['mean'] = margin_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a658cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne(HOME) is predicted to win against Brisbaneby 16.666666 points\n",
      "Collingwood(HOME) is predicted to win against Fremantleby 11.0 points\n"
     ]
    }
   ],
   "source": [
    "i=start_match\n",
    "while i<end_match:\n",
    "    home_id = home_teams[i]\n",
    "    away_id = away_teams[i]\n",
    "    winner = (tip_df['mean'][i])\n",
    "    winner_margin = margin_df['mean'][i]\n",
    "    i = i + 1\n",
    "    if(winner < 0.5):\n",
    "        print(teams[str(home_id)] + \"(HOME) is predicted to win against \"+teams[str(away_id)]+\"by \" + str(winner_margin) +\" points\")\n",
    "    elif(winner > 0.5):\n",
    "        print(teams[str(away_id)] + \"(AWAY) is predicted to win against \"+teams[str(home_id)]+\" by \" + str(winner_margin) +\" points\")\n",
    "    else:\n",
    "        print(\"DRAW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274006c",
   "metadata": {},
   "source": [
    "# Update Player PAV File (change year to 2023 for next year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910aca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pav_dict():\n",
    "    teams = {\n",
    "    \"1\" : \"AD\",\n",
    "    \"2\" : \"BL\",\n",
    "    \"3\" : \"CA\",\n",
    "    \"4\" : \"CW\",\n",
    "    \"5\" : \"ES\",\n",
    "    \"6\" : \"FR\",\n",
    "    \"7\" : \"GE\",\n",
    "    \"8\" : \"GC\",\n",
    "    \"9\" : \"GW\",\n",
    "    \"10\": \"HW\",\n",
    "    \"11\": \"ME\",\n",
    "    \"12\": \"NM\",\n",
    "    \"13\": \"PA\",\n",
    "    \"14\": \"RI\",\n",
    "    \"15\": \"SK\",\n",
    "    \"16\": \"SY\",\n",
    "    \"17\": \"WC\",\n",
    "    \"18\": \"WB\"\n",
    "    }\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4299786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pavs = pd.read_csv(\"R_Code/all_player_PAVs.csv\")\n",
    "new_pavs = pd.read_csv(\"R_Code/2022 – HPN.csv\")\n",
    "hpn = create_pav_dict()\n",
    "#reverse\n",
    "hpn = {y: x for x, y in hpn.items()}\n",
    "to_drop = all_pavs.index[(all_pavs['year'] == 2022)]\n",
    "all_pavs = all_pavs.drop(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbe9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pavs = new_pavs.drop(['GM', 'Off PAV', 'Def PAV', 'Mid PAV',\n",
    "                         'Off mPAV', 'Def mPAV', 'Mid mPAV', 'Total mPAV'], axis = 1)\n",
    "new_pavs['year'] = 2022\n",
    "new_pavs[['surname', 'firstname']] = new_pavs['Player'].str.split(',', 1, expand=True)\n",
    "new_pavs['team'] = new_pavs['TM'].map(hpn)\n",
    "new_pavs['PAV_total'] = new_pavs['Total PAV']\n",
    "new_pavs = new_pavs.drop(['Player', 'TM', 'Total PAV'], axis = 1)\n",
    "cols = ['team', 'year', 'firstname', 'surname', 'PAV_total']\n",
    "new_pavs = new_pavs[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689e1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pavs = pd.concat([all_pavs, new_pavs])\n",
    "all_pavs.to_csv(\"R_Code/all_player_PAVs.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
