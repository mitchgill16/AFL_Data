{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Models to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "#import torch.nn as nn\n",
    "#import touch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "#from fdnn import feature_extractor as fex\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import sort\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "#import torch.nn as nn\n",
    "#import touch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "#from fdnn import feature_extractor as fex\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Activation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get headers\n",
    "#feed this into a bigger function which specifies the amount of games to go through \n",
    "def get_headers(n_games):\n",
    "    headers = ['Round', 'Home_Team', 'Away_Team', 'Venue', 'H_PAV_Sum', 'A_PAV_Sum']\n",
    "    example_file = pd.read_csv('Data/Fremantle_clean_stats.csv')\n",
    "    cl_h = example_file.columns\n",
    "    cl_h = cl_h[:-5]\n",
    "    ladder_header = ['Ladder Pos_H', 'Form_H', 'Season Wins_H', 'Season Loss_H', 'Season Draw_H']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    j = 1\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'H_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    j = 1\n",
    "    ladder_header = ['Ladder Pos_A', 'Form_A', 'Season Wins_A', 'Season Loss_A', 'Season Draw_A']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'A_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headers(h):\n",
    "    headers = []\n",
    "    for x in h:\n",
    "        if '<' in x or '>' in x:\n",
    "            x = x.replace('<',\"lt_\")\n",
    "            x = x.replace('>', \"gt_\")\n",
    "            #print(x)\n",
    "        headers.append(str(x))\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_categorical_headers(h):\n",
    "    cat_var = ['Round', 'Home_Team', 'Away_Team']\n",
    "    skip = 0\n",
    "    for x in h:\n",
    "        if 'Round' in x:\n",
    "            if (skip == 0):\n",
    "                skip = 1\n",
    "                continue\n",
    "            cat_var.append(x)\n",
    "            #print(x)\n",
    "        elif 'Team_against_ID' in x:\n",
    "            #print(x)\n",
    "            cat_var.append(x)\n",
    "        elif 'Venue' in x:\n",
    "            cat_var.append(x)\n",
    "    return cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode data and transform the X_data\n",
    "#first redo, find the categorial variables\n",
    "def ohe_data(x_data, enc, flag,cat_var):\n",
    "    #data has not been previously one hot encoded\n",
    "    if (flag == 0):\n",
    "        #get columns with categorical data and drop from main DF\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        #define and fit new OHE. Use it on our categorical data by transforming\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        ohe = ohe.fit(categorical_data)\n",
    "        categorical_data = ohe.transform(categorical_data)\n",
    "        #get feature names for better labelling\n",
    "        fn = ohe.get_feature_names(cat_var)\n",
    "        #make a dataframe with new OHE data and feature names\n",
    "            #would have been good to have coded it like this for my Masters project...\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        #ensure that it won't get cranky about any different indexes(shouldn't be any but just a good check)\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        #concatenate along column axis\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1)\n",
    "    else:\n",
    "        #same as above except used already fitted ohe\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        categorical_data = enc.transform(categorical_data)\n",
    "        fn = enc.get_feature_names(cat_var)\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1, ignore_index=True)\n",
    "        ohe = enc\n",
    "    return x_data, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search parameters for best XGB classifier or best XGB regressor\n",
    "\n",
    "def param_search(x_data, y_label, class_reg):\n",
    "\n",
    "    def on_step(optim_result):\n",
    "        \"\"\"\n",
    "        Callback meant to view scores after\n",
    "        each iteration while performing Bayesian\n",
    "        Optimization in Skopt\"\"\"\n",
    "        score = xgb_bayes_search.best_score_\n",
    "        print(\"best score: %s\" % score)\n",
    "        if score >= 0.98:\n",
    "            print('Interrupting!')\n",
    "            return True\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_label, test_size=0.2, random_state=157732)\n",
    "    print(\"X_train shape: \" + str(X_train.shape))\n",
    "    print(\"X_test shape: \" + str(X_test.shape))\n",
    "  #  print(\"y_train shape: \" + str(y_train.shape))\n",
    "  #  print(\"y_test shape: \" + str(y_test.shape))\n",
    "    space ={'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 10),\n",
    "        'max_depth': Integer(0, 50),\n",
    "        'max_delta_step': Integer(0, 20),\n",
    "        'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': Real(0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': Real(1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': Real(1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': Real(1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': Integer(0, 5),\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'scale_pos_weight': Real(1e-6, 500, 'log-uniform')}\n",
    "    if(class_reg == 0):\n",
    "        xgbclass = xgb.XGBClassifier(random_state=27022013)\n",
    "    else:\n",
    "        xgbclass = xgb.XGBRegressor(random_state=27022013)\n",
    "    xgb_bayes_search = BayesSearchCV(xgbclass, space, n_iter=60, # specify how many iterations\n",
    "                                    scoring=None, n_jobs=1, cv=10, verbose=1, random_state=42, n_points=12,\n",
    "                                 refit=True)\n",
    "  #  kk = np.isinf(X_train)\n",
    "  #  if True in kk:\n",
    "  #  \tprint(\"aaaaaaa\")\n",
    "  #  kk = np.isinf(y_train)\n",
    "  #  if True in kk:\n",
    "  #  \tprint(\"reeeeeee\")\n",
    "    try:\n",
    "        xgb_bayes_search.fit(X_train, y_train.values.ravel(), callback = on_step)\n",
    "    except:\n",
    "        xgb_bayes_search.fit(X_train, y_train.values.ravel(), callback = on_step)\n",
    "  #  print(\"BEST PARAMS ARE HERE\")\n",
    " #   print(xgb_bayes_search.best_params_)\n",
    "    model = xgb_bayes_search.best_estimator_\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = all data for classifier\n",
    "#y = label of whether home team or away team won\n",
    "#m = xgb classifier for winner prediction\n",
    "#mx = all data for regressor\n",
    "#my = labels of margins\n",
    "    #try absolute values\n",
    "#mm = xgb regressor for margin prediction\n",
    "def eval_xgb_games_margins(x, y, m, mx, my, mm):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    best_m = mm\n",
    "    high_m = 100\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "    print(x)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        margin_pred = mm.fit(mx.loc[train], my.loc[train])\n",
    "        print(\"variables for auroc curve done. Processing fold accuracy + checking best model\")\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        #print(y_pred)\n",
    "        m_pred = mm.predict(mx.loc[test])\n",
    "        print(m_pred)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        print(\"The accuracy of this model is\" + str(pcent))\n",
    "        rmse = sqrt(mean_squared_error(m_pred, my.loc[test]))\n",
    "        print(\"The rmse of this model is\" + str(rmse))\n",
    "        results.append(pcent)\n",
    "        error.append(rmse)\n",
    "        #change the best model to equal current model\n",
    "        if(pcent > high_w):\n",
    "            print(\"found new best classify\")\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "        if(rmse < high_m):\n",
    "            print(\"found best new margin\")\n",
    "            best_m = mm\n",
    "            high_m = rmse\n",
    "    print(\"Best win percentage split = \" +str(high_w))\n",
    "    print(\"Best margin rmse = \"+str(high_m))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    print(\"Training Testing Margins: %.2f%% (%.2f%%)\" % (np.mean(error), np.std(error)))\n",
    "    return best_w, best_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_threshold_cv(x, y, m):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "    mean_acc = (np.mean(results))\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(x_data, y_label, best_xgb_clas):\n",
    "    thresholds = sort(best_xgb_clas.feature_importances_)\n",
    "    threshold_array = []\n",
    "    threshold_accuracies = []\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(best_xgb_clas, threshold=thresh, prefit=True)\n",
    "        selection_x_data = selection.transform(x_data)\n",
    "        selection_x_data = pd.DataFrame(selection_x_data)\n",
    "        if(thresh > 0 ):\n",
    "            threshold_array.append(thresh)\n",
    "            selection_model = XGBClassifier()\n",
    "            acc = eval_threshold_cv(selection_x_data, y_label, selection_model)\n",
    "            threshold_accuracies.append(acc)\n",
    "            print(\"Thresh=%.10f, n=%d, Accuracy: %.2f%%\" % (thresh, selection_x_data.shape[1], acc))\n",
    "    i = 0\n",
    "    max_acc = 0\n",
    "    max_i = 0\n",
    "    max_thresh = 0\n",
    "    for x in threshold_array:\n",
    "        current_acc = threshold_accuracies[i]\n",
    "        if(current_acc > max_acc):\n",
    "            max_acc = current_acc\n",
    "            max_thresh = x\n",
    "            max_i = i\n",
    "        i = i + 1\n",
    "    print(\"max accuracy is: \" + str(max_acc) + \"for threshold: \" + str(max_thresh))\n",
    "    return max_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this a method param later\n",
    "#n_games = 5\n",
    "def run_all_models(n_games):\n",
    "    #load headers and then subsequently categorical headers\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "    \n",
    "    #filter post 2021-ish\n",
    "    x_data = x_data[1400:].reset_index(drop=True)\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "    filename = 'Models/ohe_'+str(n_games)+'_no_2021_games.dat'\n",
    "    pickle.dump(ohe, open(filename, \"wb\"))\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "    y_label = y_label[1400:].reset_index(drop=True)\n",
    "\n",
    "    #loads margin as the y_label\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "    margin_label = margin_label[1400:].reset_index(drop=True)\n",
    "\n",
    "    print(margin_label.shape)\n",
    "    print(y_label.shape)\n",
    "    print(x_data.shape)\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    #optimise XGBoost model\n",
    "\n",
    "    #for predicting win\n",
    "    model = param_search(x_data, y_label, 0)\n",
    "    #for predicting margin\n",
    "    #margin_label = abs(margin_label)\n",
    "    margin_model = param_search(x_data, margin_label, 1)\n",
    "    #margin_model = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "\n",
    "   # margin_label = abs(margin_label)\n",
    "    print(margin_label)\n",
    "    best_xgb_clas, best_xgb_reg = eval_xgb_games_margins(x_data, y_label, model, x_data, margin_label, margin_model)\n",
    "\n",
    "    #save\n",
    "    pickle.dump(best_xgb_clas, open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))\n",
    "    pickle.dump(best_xgb_reg, open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))\n",
    "    \n",
    "    best_threshold = threshold_search(x_data, y_label, best_xgb_clas)\n",
    "    selection = SelectFromModel(best_xgb_clas, threshold=best_threshold, prefit=True)\n",
    "    print(selection)\n",
    "    selection_x_data = selection.transform(x_data)\n",
    "    selection_x_data = pd.DataFrame(selection_x_data)\n",
    "\n",
    "    fs_filename = 'Models/fs_criteria_'+str(n_games)+'.dat'\n",
    "    pickle.dump(selection, open(fs_filename, \"wb\"))\n",
    "\n",
    "    fs_model = param_search(selection_x_data, y_label, 0)\n",
    "\n",
    "    best_xgb_fs_clas, best_xgb_reg = eval_xgb_games_margins(selection_x_data, y_label, fs_model, x_data, margin_label, margin_model)\n",
    "\n",
    "    pickle.dump(best_xgb_fs_clas, open(\"Models/best_xgb_clas_FS_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660, 1)\n",
      "(660, 1)\n",
      "(660, 720)\n",
      "X_train shape: (528, 720)\n",
      "X_test shape: (132, 720)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6761363636363636\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   18.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6761363636363636\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   27.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6761363636363636\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6875\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6875\n",
      "X_train shape: (528, 720)\n",
      "X_test shape: (132, 720)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   37.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.13280701316455648\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.13280701316455648\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   37.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.17799981397938913\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.18318678545331749\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   55.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.18318678545331749\n",
      "     Margin\n",
      "0       3.0\n",
      "1      28.0\n",
      "2      10.0\n",
      "3     -53.0\n",
      "4      10.0\n",
      "..      ...\n",
      "655     4.0\n",
      "656    22.0\n",
      "657    -1.0\n",
      "658    39.0\n",
      "659    32.0\n",
      "\n",
      "[660 rows x 1 columns]\n",
      "     H_PAV_Sum  A_PAV_Sum  Ladder Pos_H  Form_H  Season Wins_H  Season Loss_H  \\\n",
      "0       222.71     217.59          14.0     1.0            8.0           11.0   \n",
      "1       245.34     237.08           4.0     2.0           13.0            6.0   \n",
      "2       275.45     228.91           2.0     2.0           14.0            5.0   \n",
      "3       208.62     235.57          17.0     0.0            5.0           15.0   \n",
      "4       231.86     228.64          16.0     0.0            6.0           14.0   \n",
      "..         ...        ...           ...     ...            ...            ...   \n",
      "655     282.15     288.68           1.0     1.0           18.0            5.0   \n",
      "656     251.19     230.00           8.0     1.0           12.0           10.0   \n",
      "657     285.06     226.11           2.0     2.0           17.0            6.0   \n",
      "658     999.00     201.61          15.0     0.0            9.0           14.0   \n",
      "659     999.00     264.81           7.0     2.0           13.0           10.0   \n",
      "\n",
      "     Season Draw_H  H_H/A? n-1  H_H/A Win? n-1  H_Points For n-1  ...  \\\n",
      "0              0.0         1.0             0.0              70.0  ...   \n",
      "1              0.0         1.0             1.0              93.0  ...   \n",
      "2              0.0         1.0             1.0              99.0  ...   \n",
      "3              0.0         0.0             1.0              53.0  ...   \n",
      "4              0.0         1.0             0.0              45.0  ...   \n",
      "..             ...         ...             ...               ...  ...   \n",
      "655            0.0         0.0             0.0              58.0  ...   \n",
      "656            1.0         1.0             0.0              68.0  ...   \n",
      "657            0.0         1.0             0.0              86.0  ...   \n",
      "658            0.0         1.0             0.0              97.0  ...   \n",
      "659            0.0         1.0             0.0              57.0  ...   \n",
      "\n",
      "     A_Venue n-2_Mars Stadium  A_Venue n-2_Marvel Stadium  \\\n",
      "0                         0.0                         1.0   \n",
      "1                         0.0                         0.0   \n",
      "2                         0.0                         0.0   \n",
      "3                         0.0                         0.0   \n",
      "4                         0.0                         0.0   \n",
      "..                        ...                         ...   \n",
      "655                       0.0                         0.0   \n",
      "656                       0.0                         0.0   \n",
      "657                       0.0                         0.0   \n",
      "658                       0.0                         0.0   \n",
      "659                       0.0                         0.0   \n",
      "\n",
      "     A_Venue n-2_Metricon Stadium  A_Venue n-2_Norwood Oval  \\\n",
      "0                             0.0                       0.0   \n",
      "1                             0.0                       0.0   \n",
      "2                             0.0                       0.0   \n",
      "3                             0.0                       0.0   \n",
      "4                             0.0                       0.0   \n",
      "..                            ...                       ...   \n",
      "655                           0.0                       0.0   \n",
      "656                           0.0                       0.0   \n",
      "657                           0.0                       0.0   \n",
      "658                           0.0                       0.0   \n",
      "659                           0.0                       0.0   \n",
      "\n",
      "     A_Venue n-2_Optus Stadium  A_Venue n-2_SCG  A_Venue n-2_TIO Stadium  \\\n",
      "0                          0.0              0.0                      0.0   \n",
      "1                          0.0              0.0                      0.0   \n",
      "2                          0.0              0.0                      0.0   \n",
      "3                          0.0              0.0                      0.0   \n",
      "4                          0.0              0.0                      0.0   \n",
      "..                         ...              ...                      ...   \n",
      "655                        0.0              0.0                      0.0   \n",
      "656                        0.0              0.0                      0.0   \n",
      "657                        0.0              0.0                      0.0   \n",
      "658                        0.0              0.0                      0.0   \n",
      "659                        0.0              0.0                      0.0   \n",
      "\n",
      "     A_Venue n-2_TIO Traeger Park  A_Venue n-2_University of Tasmania Stadium  \\\n",
      "0                             0.0                                         0.0   \n",
      "1                             0.0                                         0.0   \n",
      "2                             0.0                                         0.0   \n",
      "3                             0.0                                         0.0   \n",
      "4                             0.0                                         0.0   \n",
      "..                            ...                                         ...   \n",
      "655                           0.0                                         0.0   \n",
      "656                           0.0                                         0.0   \n",
      "657                           0.0                                         0.0   \n",
      "658                           0.0                                         0.0   \n",
      "659                           0.0                                         0.0   \n",
      "\n",
      "     A_Venue n-2_University of Tasmania Statium  \n",
      "0                                           0.0  \n",
      "1                                           0.0  \n",
      "2                                           0.0  \n",
      "3                                           0.0  \n",
      "4                                           0.0  \n",
      "..                                          ...  \n",
      "655                                         0.0  \n",
      "656                                         0.0  \n",
      "657                                         0.0  \n",
      "658                                         0.0  \n",
      "659                                         0.0  \n",
      "\n",
      "[660 rows x 720 columns]\n",
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  5.133963    13.348584    26.14274     10.514645     9.147062\n",
      "   9.812756    -1.6460526    4.3849683  -27.32562     21.059736\n",
      "   8.196142    12.959004    -6.894992     5.953702    26.002186\n",
      " -15.173335     6.4756174   22.011204    -0.22973609  19.27392\n",
      "  -4.8155646  -13.323689     2.1312618   -7.422513   -12.058205\n",
      "   5.685994     8.708313     4.235073    19.841856     7.784524\n",
      "  13.652854   -19.661688     6.4995403  -30.401741     5.1051884\n",
      "  -0.13086653  14.735239   -22.400167   -29.662926    16.74654\n",
      "  33.621822     0.5269585   20.487186     6.739492    17.747234\n",
      " -12.105105    -2.624958    11.866557    14.49064     14.222986\n",
      "  18.487545    32.696545     7.232642    14.521629    26.36003\n",
      "  -6.7791114   24.823952    18.708576    13.52408      4.7216425\n",
      "  31.957153    14.163102   -14.913163    -5.314337     6.696272\n",
      "  10.789133  ]\n",
      "The accuracy of this model is66.66666666666666\n",
      "The rmse of this model is36.013202050741064\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  9.911693   -23.923895     8.664705    33.761524    19.078165\n",
      "  10.693943    15.96283     29.735092     0.04494458  -7.79093\n",
      "  11.304444    13.734134    16.38387      7.617369     4.604013\n",
      "   0.82804805   1.4002438   -5.968452    18.999659    -0.75164616\n",
      "   4.9695253    7.7059617   -3.1669836  -13.776304    23.952847\n",
      "   5.6175904   -2.4616098   -2.198245    19.881187     5.4190865\n",
      " -19.173672     9.291982    -0.6092088   17.87515      0.11183393\n",
      "  25.259771   -26.214773   -24.018135    33.23671     13.617849\n",
      "   8.395569    22.392847     4.521084    15.121693     5.8919044\n",
      "  17.42156     26.83563      0.2334758  -10.961915     6.7939286\n",
      "  -2.9258122    9.581262    32.398285    19.113276    10.630871\n",
      "   8.857092   -13.576938     5.8987064   14.784971     7.144647\n",
      "  23.834131   -17.345938   -12.155077    14.544478    22.578981\n",
      "  -5.6129546 ]\n",
      "The accuracy of this model is62.121212121212125\n",
      "The rmse of this model is31.029809002796814\n",
      "found best new margin\n",
      "Split: 3\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -0.20540118  14.330386   -20.996853    22.195227    38.30294\n",
      "  17.956833   -10.239067     1.1287603   -0.9437101   12.979745\n",
      "  11.367874    -4.225191     4.5110283    1.7573359   18.84753\n",
      "  34.00791     -0.37668908 -16.401451    -3.587594    22.511047\n",
      " -15.211496    22.211155    -4.83274     -8.418393     7.123876\n",
      "  26.761568    31.903421    21.931946    -6.8691564   18.30688\n",
      "  15.419184    -2.9419825   -5.6990547    2.1543705   -1.3525232\n",
      "  16.148613    29.571587     1.6188028    1.5625397    4.692062\n",
      "   5.0371256    2.2049422   15.766416    17.328615   -17.78204\n",
      " -10.695605   -12.499866    11.530435     7.5014563   -6.453791\n",
      "  12.1697035   22.504555     9.20547      5.2927256   14.437034\n",
      "  -4.449925   -11.348791     5.6465316   45.600975     6.519203\n",
      "  19.037512    -7.628746    -5.296447    15.408762    -6.147647\n",
      "  -2.493597  ]\n",
      "The accuracy of this model is63.63636363636363\n",
      "The rmse of this model is34.864624741767706\n",
      "Split: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 10.61188     31.344603    27.610071    -7.8841677  -17.568226\n",
      "  17.046055    -4.660841    18.916958    -2.3744056    7.8815913\n",
      "  11.876466   -23.777866    12.983935     3.5815349   19.004515\n",
      "   3.9418073   11.58022      4.716772    29.996195    24.618471\n",
      "  18.834852    -4.237246    13.942529     1.914858     0.5001443\n",
      " -11.927036    -3.384655     8.662058     2.9322274    7.077849\n",
      "  20.720766   -34.801506    12.465049     7.527835   -31.179401\n",
      "  -2.2823157   19.917097   -13.744858    -2.02769     -1.0384686\n",
      "  19.481474    12.382407    22.693722     7.116546     5.4530897\n",
      "  -3.5090823    0.6716629   42.25943     12.64008      7.543716\n",
      " -12.562004     8.788789     8.020807    23.638811    26.408543\n",
      "  -6.6398168    0.8727863  -33.922817     2.6127794    3.203855\n",
      "   2.5382814   -2.7749481    7.977039     3.0775084    1.2534215\n",
      "   0.21448717]\n",
      "The accuracy of this model is56.060606060606055\n",
      "The rmse of this model is30.099189094940076\n",
      "found best new margin\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -4.450321    12.810607    -1.7241771  -21.706657     9.551984\n",
      "   6.6436357   10.489235     2.898903    17.725786    -3.2674747\n",
      "  13.649783   -10.006919   -15.466317     5.3125553   17.168312\n",
      "  -2.1172845   -5.9851294   -9.671092   -11.756621    23.07398\n",
      "  23.439703   -12.228861     5.1142583  -13.712337   -14.668459\n",
      "  24.051556    11.211463     9.053673   -13.985065    16.50421\n",
      "  14.916239     2.9627633   14.062253   -17.067091    21.202023\n",
      "  19.554893    -0.86773205   1.5578836   10.187807    27.652033\n",
      "  -1.7140739    6.057389    18.37888      6.859358   -12.014672\n",
      "  10.0009775    7.831161    -6.85408    -27.846458     5.4886465\n",
      "  -5.956685    18.07691     20.191391     2.6998847  -17.311583\n",
      " -11.010974    32.592346    13.226086    34.758476    -3.9739652\n",
      "  -5.1670165   23.713236     5.021298     0.5339539   -1.0746492\n",
      "   1.56862   ]\n",
      "The accuracy of this model is66.66666666666666\n",
      "The rmse of this model is37.115040155369634\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 10.793447    16.952581     0.20502806  17.905735    20.305422\n",
      "  -3.0882502   14.528597   -11.218543    12.934085    -2.5471432\n",
      " -35.61665     22.345112     1.1445898  -10.501193     7.498878\n",
      "  28.182886    -5.3869705   -5.58749     20.436184     4.5275073\n",
      "  -9.556701    25.517054    21.597263    14.657128    20.879845\n",
      "  -5.953935    24.298653     8.093008     4.8554373  -10.038217\n",
      " -28.573437     5.077544    14.522919     6.5552106   18.107964\n",
      "  10.915685     1.6973106   13.081096    27.674885    -4.9650164\n",
      "  -1.482233    -8.314369    35.385563    38.684277    -8.899125\n",
      "  -2.903445     9.972027    -2.0512555    7.763382    15.010755\n",
      " -12.519971     0.3408137   -2.0122912   22.205986   -11.30836\n",
      " -17.063702     7.234088    -2.0316625   17.832409    -7.584922\n",
      "  27.79796     26.290953    20.200752    24.110846   -17.830822\n",
      "   8.126369  ]\n",
      "The accuracy of this model is68.18181818181817\n",
      "The rmse of this model is36.6847870289066\n",
      "found new best classify\n",
      "Split: 7\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -3.697061     3.0364182   30.9896       2.9867473   19.815914\n",
      "  18.19554    -17.810589    -9.074398    16.916004     5.5537567\n",
      "  13.721506    17.040432    -8.804242    11.749148    28.704025\n",
      "  15.14388     -7.905514     5.013382     7.39944      6.2527905\n",
      "  11.992644    -2.1939695   23.169718   -18.608368    -7.8931713\n",
      "  -6.8158803   -2.2681918    3.1936476   17.220903   -14.361569\n",
      "  15.619292   -39.43375      7.0970426   24.827671    17.390205\n",
      "  24.828016    11.793307     6.4847317   27.264477    44.6627\n",
      " -35.754536     5.926913     0.7910116   21.917774    13.965193\n",
      "   6.1362863   31.329813    18.763079    -4.4474497  -23.066727\n",
      " -39.458015    25.768429   -24.816607    13.077983    -0.20469242\n",
      "  25.212557   -13.864985   -14.326545     5.393809     4.300542\n",
      "  11.214937     5.304125     0.51108456  12.596753    19.099678\n",
      "  16.070637  ]\n",
      "The accuracy of this model is68.18181818181817\n",
      "The rmse of this model is35.57734845177661\n",
      "Split: 8\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-10.928657    11.23934     28.51888    -11.731056    13.389902\n",
      "  -1.4735712   -8.823604    -1.6672933  -16.521065    -9.486523\n",
      "  -7.4098177    1.2181151    3.059391    17.59464    -10.224794\n",
      "  15.855391     7.129393    11.834742    14.344623    13.274035\n",
      "  -6.481411    -6.742496    17.732395    27.026808    -0.99453926\n",
      "   9.6487665   22.615019   -28.888441     6.381711     8.683287\n",
      "  26.876472   -11.278797    45.699486    17.377468    -5.5141325\n",
      "  -3.7023149    1.7067276   16.550846     7.1438355   -1.7020123\n",
      " -13.367399    11.550267     8.735429   -22.299194    -4.9594765\n",
      "  -5.429134   -11.173451    25.818033    20.86586     20.75774\n",
      "   6.2714286   25.008429    -0.86892486   2.4076462   15.386433\n",
      "   8.973665     2.5850148    3.854424     2.6273136   14.291194\n",
      "  17.93627    -12.201752    21.849953    17.976685    13.84486\n",
      "  25.08032   ]\n",
      "The accuracy of this model is68.18181818181817\n",
      "The rmse of this model is34.13398119248058\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 11.219442    24.183203   -18.897552    -3.262117   -19.849522\n",
      "  -2.7162743   13.785368    20.08814     -0.49028033  -5.259481\n",
      "   9.6408415    7.3886237   -2.321374    -7.170259    24.755188\n",
      " -24.199259    15.908651    -3.3746881   -2.6269145    6.8743944\n",
      "  -0.3565333    6.3491306   -4.5322046    5.858295    19.689444\n",
      "  11.012439    10.7789345   14.181452    -3.4418688   15.780431\n",
      "  14.400484   -11.715587     5.241352     8.57976      0.5155378\n",
      "  -7.9584618   -0.24160635  -6.6365285    1.8724463   12.231545\n",
      "  -3.7808256  -10.305229    -4.7932854   -5.061651    22.57443\n",
      "  -1.9141965   25.011261     1.3929551   36.090687     6.078452\n",
      "  25.54904     46.043728     4.050124    41.815815    12.091205\n",
      " -30.733501     5.7024255  -15.852259    20.336353    13.95095\n",
      "  24.983114    -0.42443526  19.967232    16.474962     3.0157945\n",
      "  -5.703087  ]\n",
      "The accuracy of this model is60.60606060606061\n",
      "The rmse of this model is35.15694584189429\n",
      "Split: 10\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 11.711408    6.8877587  -3.2578197   7.9720516  -3.7314777  15.060977\n",
      "  14.782671  -32.800556    1.8030797  -9.925755    7.8444033  20.242138\n",
      " -17.214453   11.133551    1.109385  -21.638891    7.8367786  18.218742\n",
      "  18.878452  -10.098855   -6.989177   20.519941   18.810772   13.951934\n",
      "   2.4325466  25.872366   21.233414   -6.1843257  -1.0884564  -4.1636186\n",
      "  25.356443    8.441508   24.687733   18.083878   -4.695211  -46.64309\n",
      "  -2.3993776   1.2258451  19.459883   -3.8088698  11.646967    0.7297937\n",
      "  -5.185724   -1.711025   12.752013   15.301805   -4.6767507  -9.148903\n",
      "   5.804755  -11.02171    -4.354877   22.078577  -25.18165    -8.722613\n",
      "  22.988588   21.049385   22.979357  -51.639668   23.180403   -3.9442177\n",
      "   8.046595   23.227612  -12.8932705 -20.78313   -10.247819   13.253336 ]\n",
      "The accuracy of this model is63.63636363636363\n",
      "The rmse of this model is36.87046613233784\n",
      "Best win percentage split = 68.18181818181817\n",
      "Best margin rmse = 30.099189094940076\n",
      "Training Testing Accuracy: 64.39% (3.79%)\n",
      "Training Testing Margins: 34.75% (2.28%)\n",
      "Thresh=0.0001425519, n=351, Accuracy: 65.45%\n",
      "Thresh=0.0001624958, n=350, Accuracy: 64.85%\n",
      "Thresh=0.0001717761, n=349, Accuracy: 64.39%\n",
      "Thresh=0.0003656859, n=348, Accuracy: 63.94%\n",
      "Thresh=0.0004220563, n=347, Accuracy: 63.94%\n",
      "Thresh=0.0004379478, n=346, Accuracy: 63.94%\n",
      "Thresh=0.0004491457, n=345, Accuracy: 64.85%\n",
      "Thresh=0.0005340860, n=344, Accuracy: 65.00%\n",
      "Thresh=0.0005551066, n=343, Accuracy: 65.00%\n",
      "Thresh=0.0005598171, n=342, Accuracy: 64.70%\n",
      "Thresh=0.0006010468, n=341, Accuracy: 65.45%\n",
      "Thresh=0.0006030005, n=340, Accuracy: 65.76%\n",
      "Thresh=0.0006276913, n=339, Accuracy: 66.36%\n",
      "Thresh=0.0006545486, n=338, Accuracy: 65.76%\n",
      "Thresh=0.0006568308, n=337, Accuracy: 66.67%\n",
      "Thresh=0.0006572969, n=336, Accuracy: 66.06%\n",
      "Thresh=0.0006612152, n=335, Accuracy: 67.27%\n",
      "Thresh=0.0006643335, n=334, Accuracy: 65.00%\n",
      "Thresh=0.0006683236, n=333, Accuracy: 65.91%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0006857848, n=332, Accuracy: 63.94%\n",
      "Thresh=0.0007231224, n=331, Accuracy: 64.09%\n",
      "Thresh=0.0007376908, n=330, Accuracy: 63.79%\n",
      "Thresh=0.0007722980, n=329, Accuracy: 65.00%\n",
      "Thresh=0.0007755113, n=328, Accuracy: 64.85%\n",
      "Thresh=0.0007757818, n=327, Accuracy: 64.39%\n",
      "Thresh=0.0007804304, n=326, Accuracy: 63.94%\n",
      "Thresh=0.0007872950, n=325, Accuracy: 66.06%\n",
      "Thresh=0.0008279781, n=324, Accuracy: 64.85%\n",
      "Thresh=0.0008285872, n=323, Accuracy: 65.91%\n",
      "Thresh=0.0008477963, n=322, Accuracy: 67.12%\n",
      "Thresh=0.0008530575, n=321, Accuracy: 65.91%\n",
      "Thresh=0.0008590181, n=320, Accuracy: 64.85%\n",
      "Thresh=0.0008606636, n=319, Accuracy: 64.85%\n",
      "Thresh=0.0008637055, n=318, Accuracy: 66.82%\n",
      "Thresh=0.0008677241, n=317, Accuracy: 67.12%\n",
      "Thresh=0.0008717728, n=316, Accuracy: 65.45%\n",
      "Thresh=0.0008861260, n=315, Accuracy: 65.45%\n",
      "Thresh=0.0009034635, n=314, Accuracy: 65.76%\n",
      "Thresh=0.0009136510, n=313, Accuracy: 65.76%\n",
      "Thresh=0.0009159127, n=312, Accuracy: 66.06%\n",
      "Thresh=0.0009186797, n=311, Accuracy: 66.06%\n",
      "Thresh=0.0009390885, n=310, Accuracy: 65.76%\n",
      "Thresh=0.0009563687, n=309, Accuracy: 65.91%\n",
      "Thresh=0.0009563804, n=308, Accuracy: 65.45%\n",
      "Thresh=0.0009775602, n=307, Accuracy: 64.55%\n",
      "Thresh=0.0009985162, n=306, Accuracy: 65.00%\n",
      "Thresh=0.0009988624, n=305, Accuracy: 64.09%\n",
      "Thresh=0.0010177270, n=304, Accuracy: 65.30%\n",
      "Thresh=0.0010234064, n=303, Accuracy: 65.30%\n",
      "Thresh=0.0010383679, n=302, Accuracy: 65.76%\n",
      "Thresh=0.0010477351, n=301, Accuracy: 64.70%\n",
      "Thresh=0.0010616195, n=300, Accuracy: 65.15%\n",
      "Thresh=0.0010700010, n=299, Accuracy: 64.85%\n",
      "Thresh=0.0010829162, n=298, Accuracy: 66.36%\n",
      "Thresh=0.0010921237, n=297, Accuracy: 65.30%\n",
      "Thresh=0.0011015103, n=296, Accuracy: 65.76%\n",
      "Thresh=0.0011052575, n=295, Accuracy: 67.27%\n",
      "Thresh=0.0011112903, n=294, Accuracy: 65.91%\n",
      "Thresh=0.0011131123, n=293, Accuracy: 64.09%\n",
      "Thresh=0.0011595305, n=292, Accuracy: 66.82%\n",
      "Thresh=0.0012029517, n=291, Accuracy: 66.36%\n",
      "Thresh=0.0012371138, n=290, Accuracy: 65.30%\n",
      "Thresh=0.0012381523, n=289, Accuracy: 63.79%\n",
      "Thresh=0.0012413154, n=288, Accuracy: 63.94%\n",
      "Thresh=0.0012421749, n=287, Accuracy: 64.24%\n",
      "Thresh=0.0012428483, n=286, Accuracy: 65.61%\n",
      "Thresh=0.0012450534, n=285, Accuracy: 64.70%\n",
      "Thresh=0.0012528707, n=284, Accuracy: 66.06%\n",
      "Thresh=0.0012574532, n=283, Accuracy: 65.91%\n",
      "Thresh=0.0012580038, n=282, Accuracy: 65.15%\n",
      "Thresh=0.0012876424, n=281, Accuracy: 64.39%\n",
      "Thresh=0.0013034396, n=280, Accuracy: 63.94%\n",
      "Thresh=0.0013049869, n=279, Accuracy: 63.64%\n",
      "Thresh=0.0013344603, n=278, Accuracy: 65.91%\n",
      "Thresh=0.0013430899, n=277, Accuracy: 65.30%\n",
      "Thresh=0.0013440645, n=276, Accuracy: 63.33%\n",
      "Thresh=0.0013493976, n=275, Accuracy: 63.79%\n",
      "Thresh=0.0013546466, n=274, Accuracy: 66.21%\n",
      "Thresh=0.0013669542, n=273, Accuracy: 65.00%\n",
      "Thresh=0.0014012409, n=272, Accuracy: 67.88%\n",
      "Thresh=0.0014105017, n=271, Accuracy: 67.12%\n",
      "Thresh=0.0014146192, n=270, Accuracy: 64.70%\n",
      "Thresh=0.0014189683, n=269, Accuracy: 65.91%\n",
      "Thresh=0.0014329499, n=268, Accuracy: 65.15%\n",
      "Thresh=0.0014487582, n=267, Accuracy: 65.30%\n",
      "Thresh=0.0014541595, n=266, Accuracy: 66.06%\n",
      "Thresh=0.0014566741, n=265, Accuracy: 66.06%\n",
      "Thresh=0.0014609557, n=264, Accuracy: 64.70%\n",
      "Thresh=0.0014671850, n=263, Accuracy: 62.73%\n",
      "Thresh=0.0014825714, n=262, Accuracy: 63.18%\n",
      "Thresh=0.0014926273, n=261, Accuracy: 63.94%\n",
      "Thresh=0.0014949223, n=260, Accuracy: 64.55%\n",
      "Thresh=0.0015002836, n=259, Accuracy: 65.45%\n",
      "Thresh=0.0015035624, n=258, Accuracy: 65.61%\n",
      "Thresh=0.0015066521, n=257, Accuracy: 65.00%\n",
      "Thresh=0.0015157505, n=256, Accuracy: 63.64%\n",
      "Thresh=0.0015292711, n=255, Accuracy: 63.79%\n",
      "Thresh=0.0015303659, n=254, Accuracy: 63.64%\n",
      "Thresh=0.0015343974, n=253, Accuracy: 64.24%\n",
      "Thresh=0.0015626112, n=252, Accuracy: 64.55%\n",
      "Thresh=0.0015702221, n=251, Accuracy: 65.61%\n",
      "Thresh=0.0015765693, n=250, Accuracy: 65.45%\n",
      "Thresh=0.0015849159, n=249, Accuracy: 65.45%\n",
      "Thresh=0.0015967030, n=248, Accuracy: 65.91%\n",
      "Thresh=0.0016031311, n=247, Accuracy: 64.85%\n",
      "Thresh=0.0016167365, n=246, Accuracy: 65.76%\n",
      "Thresh=0.0016176989, n=245, Accuracy: 66.36%\n",
      "Thresh=0.0016215050, n=244, Accuracy: 65.45%\n",
      "Thresh=0.0016336744, n=243, Accuracy: 64.70%\n",
      "Thresh=0.0016351469, n=242, Accuracy: 65.45%\n",
      "Thresh=0.0016580892, n=241, Accuracy: 64.85%\n",
      "Thresh=0.0016594002, n=240, Accuracy: 65.45%\n",
      "Thresh=0.0016641479, n=239, Accuracy: 66.97%\n",
      "Thresh=0.0016894510, n=238, Accuracy: 65.76%\n",
      "Thresh=0.0016913640, n=237, Accuracy: 66.67%\n",
      "Thresh=0.0017074927, n=236, Accuracy: 66.82%\n",
      "Thresh=0.0017239605, n=235, Accuracy: 65.91%\n",
      "Thresh=0.0017297185, n=234, Accuracy: 65.30%\n",
      "Thresh=0.0017686507, n=233, Accuracy: 65.76%\n",
      "Thresh=0.0017818351, n=232, Accuracy: 64.70%\n",
      "Thresh=0.0017869881, n=231, Accuracy: 65.91%\n",
      "Thresh=0.0017916323, n=230, Accuracy: 66.52%\n",
      "Thresh=0.0017918609, n=229, Accuracy: 66.97%\n",
      "Thresh=0.0017930039, n=228, Accuracy: 65.76%\n",
      "Thresh=0.0018126380, n=227, Accuracy: 66.97%\n",
      "Thresh=0.0018226267, n=226, Accuracy: 67.27%\n",
      "Thresh=0.0018253223, n=225, Accuracy: 64.85%\n",
      "Thresh=0.0018354242, n=224, Accuracy: 64.70%\n",
      "Thresh=0.0018465258, n=223, Accuracy: 64.85%\n",
      "Thresh=0.0018505584, n=222, Accuracy: 65.15%\n",
      "Thresh=0.0018525459, n=221, Accuracy: 66.97%\n",
      "Thresh=0.0018603390, n=220, Accuracy: 66.67%\n",
      "Thresh=0.0018645164, n=219, Accuracy: 64.70%\n",
      "Thresh=0.0018662069, n=218, Accuracy: 65.61%\n",
      "Thresh=0.0018760745, n=217, Accuracy: 65.30%\n",
      "Thresh=0.0018843899, n=216, Accuracy: 64.39%\n",
      "Thresh=0.0018857254, n=215, Accuracy: 65.91%\n",
      "Thresh=0.0018993135, n=214, Accuracy: 66.82%\n",
      "Thresh=0.0019051629, n=213, Accuracy: 66.82%\n",
      "Thresh=0.0019295899, n=212, Accuracy: 65.76%\n",
      "Thresh=0.0019536549, n=211, Accuracy: 65.30%\n",
      "Thresh=0.0019591334, n=210, Accuracy: 65.00%\n",
      "Thresh=0.0019605446, n=209, Accuracy: 66.67%\n",
      "Thresh=0.0019713084, n=208, Accuracy: 66.82%\n",
      "Thresh=0.0020174414, n=207, Accuracy: 66.21%\n",
      "Thresh=0.0020190678, n=206, Accuracy: 63.94%\n",
      "Thresh=0.0020234999, n=205, Accuracy: 66.36%\n",
      "Thresh=0.0020236874, n=204, Accuracy: 66.21%\n",
      "Thresh=0.0020493043, n=203, Accuracy: 66.67%\n",
      "Thresh=0.0020536049, n=202, Accuracy: 66.06%\n",
      "Thresh=0.0020661769, n=201, Accuracy: 67.12%\n",
      "Thresh=0.0020804554, n=200, Accuracy: 67.42%\n",
      "Thresh=0.0020824778, n=199, Accuracy: 65.76%\n",
      "Thresh=0.0021064677, n=198, Accuracy: 66.36%\n",
      "Thresh=0.0021123434, n=197, Accuracy: 66.67%\n",
      "Thresh=0.0021171707, n=196, Accuracy: 65.91%\n",
      "Thresh=0.0021352184, n=195, Accuracy: 66.67%\n",
      "Thresh=0.0021399651, n=194, Accuracy: 66.36%\n",
      "Thresh=0.0021423814, n=193, Accuracy: 66.67%\n",
      "Thresh=0.0021749474, n=192, Accuracy: 65.76%\n",
      "Thresh=0.0021772704, n=191, Accuracy: 66.36%\n",
      "Thresh=0.0021816846, n=190, Accuracy: 66.67%\n",
      "Thresh=0.0021861177, n=189, Accuracy: 66.06%\n",
      "Thresh=0.0021869789, n=188, Accuracy: 68.03%\n",
      "Thresh=0.0021950512, n=187, Accuracy: 65.91%\n",
      "Thresh=0.0022606154, n=186, Accuracy: 67.73%\n",
      "Thresh=0.0022764052, n=185, Accuracy: 66.97%\n",
      "Thresh=0.0022844623, n=184, Accuracy: 65.00%\n",
      "Thresh=0.0022889883, n=183, Accuracy: 66.36%\n",
      "Thresh=0.0022917162, n=182, Accuracy: 64.70%\n",
      "Thresh=0.0022929851, n=181, Accuracy: 65.45%\n",
      "Thresh=0.0022980424, n=180, Accuracy: 65.15%\n",
      "Thresh=0.0023163024, n=179, Accuracy: 67.73%\n",
      "Thresh=0.0023374895, n=178, Accuracy: 66.06%\n",
      "Thresh=0.0023468435, n=177, Accuracy: 66.21%\n",
      "Thresh=0.0023672651, n=176, Accuracy: 67.73%\n",
      "Thresh=0.0023702220, n=175, Accuracy: 65.15%\n",
      "Thresh=0.0023830538, n=174, Accuracy: 65.45%\n",
      "Thresh=0.0023939493, n=173, Accuracy: 65.30%\n",
      "Thresh=0.0023969854, n=172, Accuracy: 66.06%\n",
      "Thresh=0.0024105986, n=171, Accuracy: 66.06%\n",
      "Thresh=0.0024210769, n=170, Accuracy: 66.97%\n",
      "Thresh=0.0024287584, n=169, Accuracy: 66.36%\n",
      "Thresh=0.0024331801, n=168, Accuracy: 66.82%\n",
      "Thresh=0.0024415846, n=167, Accuracy: 67.27%\n",
      "Thresh=0.0024449585, n=166, Accuracy: 65.15%\n",
      "Thresh=0.0024683627, n=165, Accuracy: 65.15%\n",
      "Thresh=0.0024751592, n=164, Accuracy: 65.91%\n",
      "Thresh=0.0024792640, n=163, Accuracy: 66.52%\n",
      "Thresh=0.0024967140, n=162, Accuracy: 66.67%\n",
      "Thresh=0.0025097439, n=161, Accuracy: 65.30%\n",
      "Thresh=0.0025239591, n=160, Accuracy: 66.06%\n",
      "Thresh=0.0025248544, n=159, Accuracy: 65.91%\n",
      "Thresh=0.0025582938, n=158, Accuracy: 64.09%\n",
      "Thresh=0.0025638978, n=157, Accuracy: 64.55%\n",
      "Thresh=0.0025672086, n=156, Accuracy: 65.76%\n",
      "Thresh=0.0025683618, n=155, Accuracy: 64.70%\n",
      "Thresh=0.0025684447, n=154, Accuracy: 65.61%\n",
      "Thresh=0.0025743206, n=153, Accuracy: 66.52%\n",
      "Thresh=0.0025940330, n=152, Accuracy: 67.73%\n",
      "Thresh=0.0025976636, n=151, Accuracy: 65.91%\n",
      "Thresh=0.0026081421, n=150, Accuracy: 66.82%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0026133198, n=149, Accuracy: 64.55%\n",
      "Thresh=0.0026206363, n=148, Accuracy: 65.30%\n",
      "Thresh=0.0026347071, n=147, Accuracy: 66.52%\n",
      "Thresh=0.0026449463, n=146, Accuracy: 65.30%\n",
      "Thresh=0.0026593029, n=145, Accuracy: 66.97%\n",
      "Thresh=0.0026881718, n=144, Accuracy: 67.58%\n",
      "Thresh=0.0027039568, n=143, Accuracy: 66.97%\n",
      "Thresh=0.0027217325, n=142, Accuracy: 66.67%\n",
      "Thresh=0.0027614173, n=141, Accuracy: 66.67%\n",
      "Thresh=0.0027952078, n=140, Accuracy: 64.70%\n",
      "Thresh=0.0028090924, n=139, Accuracy: 67.27%\n",
      "Thresh=0.0028176839, n=138, Accuracy: 64.39%\n",
      "Thresh=0.0028245216, n=137, Accuracy: 65.61%\n",
      "Thresh=0.0028376991, n=136, Accuracy: 65.15%\n",
      "Thresh=0.0028905729, n=135, Accuracy: 65.91%\n",
      "Thresh=0.0029592894, n=134, Accuracy: 64.85%\n",
      "Thresh=0.0029673723, n=133, Accuracy: 65.91%\n",
      "Thresh=0.0029694526, n=132, Accuracy: 65.00%\n",
      "Thresh=0.0030110702, n=131, Accuracy: 67.42%\n",
      "Thresh=0.0030200956, n=130, Accuracy: 65.76%\n",
      "Thresh=0.0030244058, n=129, Accuracy: 65.76%\n",
      "Thresh=0.0030311288, n=128, Accuracy: 65.61%\n",
      "Thresh=0.0030323139, n=127, Accuracy: 67.12%\n",
      "Thresh=0.0030607693, n=126, Accuracy: 66.82%\n",
      "Thresh=0.0030639768, n=125, Accuracy: 66.21%\n",
      "Thresh=0.0030864715, n=124, Accuracy: 66.67%\n",
      "Thresh=0.0030885322, n=123, Accuracy: 65.61%\n",
      "Thresh=0.0030974355, n=122, Accuracy: 66.82%\n",
      "Thresh=0.0030991668, n=121, Accuracy: 67.88%\n",
      "Thresh=0.0031059505, n=120, Accuracy: 67.88%\n",
      "Thresh=0.0031122770, n=119, Accuracy: 65.61%\n",
      "Thresh=0.0031299270, n=118, Accuracy: 65.00%\n",
      "Thresh=0.0031405338, n=117, Accuracy: 66.06%\n",
      "Thresh=0.0031539584, n=116, Accuracy: 65.45%\n",
      "Thresh=0.0031567824, n=115, Accuracy: 66.06%\n",
      "Thresh=0.0031619952, n=114, Accuracy: 67.12%\n",
      "Thresh=0.0031809343, n=113, Accuracy: 67.58%\n",
      "Thresh=0.0031926709, n=112, Accuracy: 68.18%\n",
      "Thresh=0.0032221740, n=111, Accuracy: 65.91%\n",
      "Thresh=0.0032424754, n=110, Accuracy: 65.61%\n",
      "Thresh=0.0032508972, n=109, Accuracy: 66.52%\n",
      "Thresh=0.0032540294, n=108, Accuracy: 67.12%\n",
      "Thresh=0.0032949999, n=107, Accuracy: 66.82%\n",
      "Thresh=0.0032961180, n=106, Accuracy: 68.03%\n",
      "Thresh=0.0033019676, n=105, Accuracy: 66.82%\n",
      "Thresh=0.0033319597, n=104, Accuracy: 65.76%\n",
      "Thresh=0.0033505680, n=103, Accuracy: 68.64%\n",
      "Thresh=0.0033668862, n=102, Accuracy: 68.94%\n",
      "Thresh=0.0034205022, n=101, Accuracy: 67.42%\n",
      "Thresh=0.0034227900, n=100, Accuracy: 66.52%\n",
      "Thresh=0.0034383105, n=99, Accuracy: 67.58%\n",
      "Thresh=0.0034981545, n=98, Accuracy: 66.67%\n",
      "Thresh=0.0035222431, n=97, Accuracy: 66.21%\n",
      "Thresh=0.0035245128, n=96, Accuracy: 65.76%\n",
      "Thresh=0.0035290534, n=95, Accuracy: 67.42%\n",
      "Thresh=0.0035347957, n=94, Accuracy: 65.00%\n",
      "Thresh=0.0035350460, n=93, Accuracy: 66.52%\n",
      "Thresh=0.0035768251, n=92, Accuracy: 68.18%\n",
      "Thresh=0.0035875414, n=91, Accuracy: 66.67%\n",
      "Thresh=0.0036064903, n=90, Accuracy: 66.06%\n",
      "Thresh=0.0036244199, n=89, Accuracy: 67.73%\n",
      "Thresh=0.0036260299, n=88, Accuracy: 67.73%\n",
      "Thresh=0.0036615597, n=87, Accuracy: 65.91%\n",
      "Thresh=0.0037353127, n=86, Accuracy: 67.42%\n",
      "Thresh=0.0037437035, n=85, Accuracy: 67.58%\n",
      "Thresh=0.0038105252, n=84, Accuracy: 68.33%\n",
      "Thresh=0.0038348399, n=83, Accuracy: 65.76%\n",
      "Thresh=0.0038727084, n=82, Accuracy: 66.06%\n",
      "Thresh=0.0038906441, n=81, Accuracy: 67.42%\n",
      "Thresh=0.0039331317, n=80, Accuracy: 66.52%\n",
      "Thresh=0.0039344272, n=79, Accuracy: 67.88%\n",
      "Thresh=0.0039661587, n=78, Accuracy: 65.15%\n",
      "Thresh=0.0039810524, n=77, Accuracy: 68.03%\n",
      "Thresh=0.0039984956, n=76, Accuracy: 68.18%\n",
      "Thresh=0.0040027560, n=75, Accuracy: 67.27%\n",
      "Thresh=0.0040341704, n=74, Accuracy: 67.58%\n",
      "Thresh=0.0040453183, n=73, Accuracy: 68.79%\n",
      "Thresh=0.0040490641, n=72, Accuracy: 68.79%\n",
      "Thresh=0.0040532937, n=71, Accuracy: 68.33%\n",
      "Thresh=0.0040993989, n=70, Accuracy: 65.76%\n",
      "Thresh=0.0041538952, n=69, Accuracy: 66.52%\n",
      "Thresh=0.0041732234, n=68, Accuracy: 67.27%\n",
      "Thresh=0.0041757007, n=67, Accuracy: 66.21%\n",
      "Thresh=0.0041985996, n=66, Accuracy: 67.27%\n",
      "Thresh=0.0042240061, n=65, Accuracy: 66.82%\n",
      "Thresh=0.0042620674, n=64, Accuracy: 65.91%\n",
      "Thresh=0.0042888378, n=63, Accuracy: 68.33%\n",
      "Thresh=0.0043015731, n=62, Accuracy: 66.36%\n",
      "Thresh=0.0043282239, n=61, Accuracy: 68.48%\n",
      "Thresh=0.0043549319, n=60, Accuracy: 67.42%\n",
      "Thresh=0.0044326042, n=59, Accuracy: 69.70%\n",
      "Thresh=0.0044409488, n=58, Accuracy: 68.03%\n",
      "Thresh=0.0044415877, n=57, Accuracy: 68.79%\n",
      "Thresh=0.0044439710, n=56, Accuracy: 66.97%\n",
      "Thresh=0.0044727232, n=55, Accuracy: 67.58%\n",
      "Thresh=0.0044791484, n=54, Accuracy: 69.85%\n",
      "Thresh=0.0045605921, n=53, Accuracy: 67.42%\n",
      "Thresh=0.0045669293, n=52, Accuracy: 67.27%\n",
      "Thresh=0.0045760241, n=51, Accuracy: 66.67%\n",
      "Thresh=0.0046084421, n=50, Accuracy: 66.36%\n",
      "Thresh=0.0046288469, n=49, Accuracy: 67.12%\n",
      "Thresh=0.0046566087, n=48, Accuracy: 66.52%\n",
      "Thresh=0.0046808040, n=47, Accuracy: 65.45%\n",
      "Thresh=0.0047422987, n=46, Accuracy: 66.36%\n",
      "Thresh=0.0047432510, n=45, Accuracy: 67.12%\n",
      "Thresh=0.0047640144, n=44, Accuracy: 64.85%\n",
      "Thresh=0.0048095072, n=43, Accuracy: 65.15%\n",
      "Thresh=0.0048286454, n=42, Accuracy: 65.00%\n",
      "Thresh=0.0049376376, n=41, Accuracy: 67.73%\n",
      "Thresh=0.0050261631, n=40, Accuracy: 65.91%\n",
      "Thresh=0.0050270958, n=39, Accuracy: 65.91%\n",
      "Thresh=0.0051535871, n=38, Accuracy: 65.30%\n",
      "Thresh=0.0051902384, n=37, Accuracy: 65.45%\n",
      "Thresh=0.0053092437, n=36, Accuracy: 64.39%\n",
      "Thresh=0.0054041520, n=35, Accuracy: 66.67%\n",
      "Thresh=0.0054816795, n=34, Accuracy: 64.85%\n",
      "Thresh=0.0055371495, n=33, Accuracy: 66.21%\n",
      "Thresh=0.0055689509, n=32, Accuracy: 65.91%\n",
      "Thresh=0.0056431210, n=31, Accuracy: 64.85%\n",
      "Thresh=0.0056653004, n=30, Accuracy: 67.12%\n",
      "Thresh=0.0057207202, n=29, Accuracy: 65.30%\n",
      "Thresh=0.0057778335, n=28, Accuracy: 66.06%\n",
      "Thresh=0.0058076801, n=27, Accuracy: 66.36%\n",
      "Thresh=0.0058112973, n=26, Accuracy: 65.15%\n",
      "Thresh=0.0059228060, n=25, Accuracy: 66.21%\n",
      "Thresh=0.0060511995, n=24, Accuracy: 66.21%\n",
      "Thresh=0.0060665761, n=23, Accuracy: 68.03%\n",
      "Thresh=0.0062204958, n=22, Accuracy: 67.27%\n",
      "Thresh=0.0064711631, n=21, Accuracy: 65.76%\n",
      "Thresh=0.0065355706, n=20, Accuracy: 59.70%\n",
      "Thresh=0.0067141922, n=19, Accuracy: 61.52%\n",
      "Thresh=0.0068609221, n=18, Accuracy: 60.45%\n",
      "Thresh=0.0070341919, n=17, Accuracy: 61.52%\n",
      "Thresh=0.0076609100, n=16, Accuracy: 58.79%\n",
      "Thresh=0.0076880483, n=15, Accuracy: 57.27%\n",
      "Thresh=0.0078816246, n=14, Accuracy: 58.48%\n",
      "Thresh=0.0080702398, n=13, Accuracy: 56.67%\n",
      "Thresh=0.0081384210, n=12, Accuracy: 56.52%\n",
      "Thresh=0.0081555266, n=11, Accuracy: 57.88%\n",
      "Thresh=0.0084049487, n=10, Accuracy: 56.21%\n",
      "Thresh=0.0084127393, n=9, Accuracy: 60.00%\n",
      "Thresh=0.0089003760, n=8, Accuracy: 59.39%\n",
      "Thresh=0.0089499131, n=7, Accuracy: 57.12%\n",
      "Thresh=0.0093364744, n=6, Accuracy: 57.42%\n",
      "Thresh=0.0099911150, n=5, Accuracy: 56.06%\n",
      "Thresh=0.0100945840, n=4, Accuracy: 56.97%\n",
      "Thresh=0.0104079712, n=3, Accuracy: 55.00%\n",
      "Thresh=0.0132496702, n=2, Accuracy: 54.24%\n",
      "Thresh=0.0139869135, n=1, Accuracy: 56.21%\n",
      "max accuracy is: 69.84848484848484for threshold: 0.0044791484\n",
      "SelectFromModel(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                        colsample_bylevel=0.717224780391087,\n",
      "                                        colsample_bynode=1,\n",
      "                                        colsample_bytree=0.5653280874220074,\n",
      "                                        gamma=0.00041911157722534966, gpu_id=-1,\n",
      "                                        importance_type='gain',\n",
      "                                        interaction_constraints='',\n",
      "                                        learning_rate=0.1300511568564498,\n",
      "                                        max_delta_step=11, max_depth=22,\n",
      "                                        min_child_weight=1, missing=nan,\n",
      "                                        mon...constraints='()',\n",
      "                                        n_estimators=81, n_jobs=0,\n",
      "                                        num_parallel_tree=1,\n",
      "                                        objective='binary:logistic',\n",
      "                                        random_state=27022013,\n",
      "                                        reg_alpha=1.2514503049485467e-09,\n",
      "                                        reg_lambda=0.47540667716857976,\n",
      "                                        scale_pos_weight=0.2964610511403682,\n",
      "                                        subsample=1.0, tree_method='exact',\n",
      "                                        validate_parameters=1, verbosity=None),\n",
      "                max_features=None, norm_order=1, prefit=True,\n",
      "                threshold=0.0044791484)\n",
      "X_train shape: (528, 54)\n",
      "X_test shape: (132, 54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6704545454545454\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6704545454545454\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6742424242424242\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   13.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7064393939393939\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7102272727272727\n",
      "         0       1     2     3     4     5     6     7     8     9   ...  \\\n",
      "0    222.71  217.59  14.0  70.0  10.0   5.0  42.0  53.0  5.30  10.0  ...   \n",
      "1    245.34  237.08   4.0  93.0  13.0  10.0  33.0  70.0  5.38   7.0  ...   \n",
      "2    275.45  228.91   2.0  99.0  15.0  10.0  33.0  50.0  3.33   6.0  ...   \n",
      "3    208.62  235.57  17.0  53.0   7.0   5.0  36.0  43.0  6.14   6.0  ...   \n",
      "4    231.86  228.64  16.0  45.0   6.0   1.0  40.0  43.0  7.17   7.0  ...   \n",
      "..      ...     ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "655  282.15  288.68   1.0  58.0   8.0   6.0  44.0  52.0  6.50   2.0  ...   \n",
      "656  251.19  230.00   8.0  68.0   9.0   6.0  35.0  46.0  5.11   3.0  ...   \n",
      "657  285.06  226.11   2.0  86.0  13.0  10.0  44.0  43.0  3.31   3.0  ...   \n",
      "658  999.00  201.61  15.0  97.0  14.0   9.0  40.0  53.0  3.79   7.0  ...   \n",
      "659  999.00  264.81   7.0  57.0   8.0   7.0  26.0  48.0  6.00   6.0  ...   \n",
      "\n",
      "       44    45    46    47    48   49   50   51   52   53  \n",
      "0    16.0  33.0  48.5  1.79  3.69  0.0  0.0  0.0  0.0  0.0  \n",
      "1     9.0  15.0  60.0  3.07  5.11  0.0  0.0  0.0  0.0  0.0  \n",
      "2    13.0  22.0  59.1  2.09  3.54  0.0  0.0  0.0  0.0  0.0  \n",
      "3    12.0  23.0  52.2  2.43  4.67  0.0  0.0  0.0  0.0  0.0  \n",
      "4    14.0  22.0  63.6  2.09  3.29  0.0  0.0  0.0  0.0  0.0  \n",
      "..    ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  \n",
      "655  11.0  20.0  55.0  2.40  4.36  0.0  0.0  0.0  0.0  1.0  \n",
      "656   9.0  15.0  60.0  2.47  4.11  0.0  0.0  0.0  0.0  0.0  \n",
      "657   9.0  26.0  34.6  2.04  5.89  0.0  0.0  0.0  0.0  0.0  \n",
      "658  10.0  22.0  45.5  2.14  4.70  0.0  0.0  0.0  1.0  0.0  \n",
      "659   8.0  17.0  47.1  2.82  6.00  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[660 rows x 54 columns]\n",
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  5.133963    13.348584    26.14274     10.514645     9.147062\n",
      "   9.812756    -1.6460526    4.3849683  -27.32562     21.059736\n",
      "   8.196142    12.959004    -6.894992     5.953702    26.002186\n",
      " -15.173335     6.4756174   22.011204    -0.22973609  19.27392\n",
      "  -4.8155646  -13.323689     2.1312618   -7.422513   -12.058205\n",
      "   5.685994     8.708313     4.235073    19.841856     7.784524\n",
      "  13.652854   -19.661688     6.4995403  -30.401741     5.1051884\n",
      "  -0.13086653  14.735239   -22.400167   -29.662926    16.74654\n",
      "  33.621822     0.5269585   20.487186     6.739492    17.747234\n",
      " -12.105105    -2.624958    11.866557    14.49064     14.222986\n",
      "  18.487545    32.696545     7.232642    14.521629    26.36003\n",
      "  -6.7791114   24.823952    18.708576    13.52408      4.7216425\n",
      "  31.957153    14.163102   -14.913163    -5.314337     6.696272\n",
      "  10.789133  ]\n",
      "The accuracy of this model is65.15151515151516\n",
      "The rmse of this model is36.013202050741064\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  9.911693   -23.923895     8.664705    33.761524    19.078165\n",
      "  10.693943    15.96283     29.735092     0.04494458  -7.79093\n",
      "  11.304444    13.734134    16.38387      7.617369     4.604013\n",
      "   0.82804805   1.4002438   -5.968452    18.999659    -0.75164616\n",
      "   4.9695253    7.7059617   -3.1669836  -13.776304    23.952847\n",
      "   5.6175904   -2.4616098   -2.198245    19.881187     5.4190865\n",
      " -19.173672     9.291982    -0.6092088   17.87515      0.11183393\n",
      "  25.259771   -26.214773   -24.018135    33.23671     13.617849\n",
      "   8.395569    22.392847     4.521084    15.121693     5.8919044\n",
      "  17.42156     26.83563      0.2334758  -10.961915     6.7939286\n",
      "  -2.9258122    9.581262    32.398285    19.113276    10.630871\n",
      "   8.857092   -13.576938     5.8987064   14.784971     7.144647\n",
      "  23.834131   -17.345938   -12.155077    14.544478    22.578981\n",
      "  -5.6129546 ]\n",
      "The accuracy of this model is65.15151515151516\n",
      "The rmse of this model is31.029809002796814\n",
      "found best new margin\n",
      "Split: 3\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -0.20540118  14.330386   -20.996853    22.195227    38.30294\n",
      "  17.956833   -10.239067     1.1287603   -0.9437101   12.979745\n",
      "  11.367874    -4.225191     4.5110283    1.7573359   18.84753\n",
      "  34.00791     -0.37668908 -16.401451    -3.587594    22.511047\n",
      " -15.211496    22.211155    -4.83274     -8.418393     7.123876\n",
      "  26.761568    31.903421    21.931946    -6.8691564   18.30688\n",
      "  15.419184    -2.9419825   -5.6990547    2.1543705   -1.3525232\n",
      "  16.148613    29.571587     1.6188028    1.5625397    4.692062\n",
      "   5.0371256    2.2049422   15.766416    17.328615   -17.78204\n",
      " -10.695605   -12.499866    11.530435     7.5014563   -6.453791\n",
      "  12.1697035   22.504555     9.20547      5.2927256   14.437034\n",
      "  -4.449925   -11.348791     5.6465316   45.600975     6.519203\n",
      "  19.037512    -7.628746    -5.296447    15.408762    -6.147647\n",
      "  -2.493597  ]\n",
      "The accuracy of this model is65.15151515151516\n",
      "The rmse of this model is34.864624741767706\n",
      "Split: 4\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 10.61188     31.344603    27.610071    -7.8841677  -17.568226\n",
      "  17.046055    -4.660841    18.916958    -2.3744056    7.8815913\n",
      "  11.876466   -23.777866    12.983935     3.5815349   19.004515\n",
      "   3.9418073   11.58022      4.716772    29.996195    24.618471\n",
      "  18.834852    -4.237246    13.942529     1.914858     0.5001443\n",
      " -11.927036    -3.384655     8.662058     2.9322274    7.077849\n",
      "  20.720766   -34.801506    12.465049     7.527835   -31.179401\n",
      "  -2.2823157   19.917097   -13.744858    -2.02769     -1.0384686\n",
      "  19.481474    12.382407    22.693722     7.116546     5.4530897\n",
      "  -3.5090823    0.6716629   42.25943     12.64008      7.543716\n",
      " -12.562004     8.788789     8.020807    23.638811    26.408543\n",
      "  -6.6398168    0.8727863  -33.922817     2.6127794    3.203855\n",
      "   2.5382814   -2.7749481    7.977039     3.0775084    1.2534215\n",
      "   0.21448717]\n",
      "The accuracy of this model is68.18181818181817\n",
      "The rmse of this model is30.099189094940076\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -4.450321    12.810607    -1.7241771  -21.706657     9.551984\n",
      "   6.6436357   10.489235     2.898903    17.725786    -3.2674747\n",
      "  13.649783   -10.006919   -15.466317     5.3125553   17.168312\n",
      "  -2.1172845   -5.9851294   -9.671092   -11.756621    23.07398\n",
      "  23.439703   -12.228861     5.1142583  -13.712337   -14.668459\n",
      "  24.051556    11.211463     9.053673   -13.985065    16.50421\n",
      "  14.916239     2.9627633   14.062253   -17.067091    21.202023\n",
      "  19.554893    -0.86773205   1.5578836   10.187807    27.652033\n",
      "  -1.7140739    6.057389    18.37888      6.859358   -12.014672\n",
      "  10.0009775    7.831161    -6.85408    -27.846458     5.4886465\n",
      "  -5.956685    18.07691     20.191391     2.6998847  -17.311583\n",
      " -11.010974    32.592346    13.226086    34.758476    -3.9739652\n",
      "  -5.1670165   23.713236     5.021298     0.5339539   -1.0746492\n",
      "   1.56862   ]\n",
      "The accuracy of this model is69.6969696969697\n",
      "The rmse of this model is37.115040155369634\n",
      "found new best classify\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 10.793447    16.952581     0.20502806  17.905735    20.305422\n",
      "  -3.0882502   14.528597   -11.218543    12.934085    -2.5471432\n",
      " -35.61665     22.345112     1.1445898  -10.501193     7.498878\n",
      "  28.182886    -5.3869705   -5.58749     20.436184     4.5275073\n",
      "  -9.556701    25.517054    21.597263    14.657128    20.879845\n",
      "  -5.953935    24.298653     8.093008     4.8554373  -10.038217\n",
      " -28.573437     5.077544    14.522919     6.5552106   18.107964\n",
      "  10.915685     1.6973106   13.081096    27.674885    -4.9650164\n",
      "  -1.482233    -8.314369    35.385563    38.684277    -8.899125\n",
      "  -2.903445     9.972027    -2.0512555    7.763382    15.010755\n",
      " -12.519971     0.3408137   -2.0122912   22.205986   -11.30836\n",
      " -17.063702     7.234088    -2.0316625   17.832409    -7.584922\n",
      "  27.79796     26.290953    20.200752    24.110846   -17.830822\n",
      "   8.126369  ]\n",
      "The accuracy of this model is69.6969696969697\n",
      "The rmse of this model is36.6847870289066\n",
      "Split: 7\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -3.697061     3.0364182   30.9896       2.9867473   19.815914\n",
      "  18.19554    -17.810589    -9.074398    16.916004     5.5537567\n",
      "  13.721506    17.040432    -8.804242    11.749148    28.704025\n",
      "  15.14388     -7.905514     5.013382     7.39944      6.2527905\n",
      "  11.992644    -2.1939695   23.169718   -18.608368    -7.8931713\n",
      "  -6.8158803   -2.2681918    3.1936476   17.220903   -14.361569\n",
      "  15.619292   -39.43375      7.0970426   24.827671    17.390205\n",
      "  24.828016    11.793307     6.4847317   27.264477    44.6627\n",
      " -35.754536     5.926913     0.7910116   21.917774    13.965193\n",
      "   6.1362863   31.329813    18.763079    -4.4474497  -23.066727\n",
      " -39.458015    25.768429   -24.816607    13.077983    -0.20469242\n",
      "  25.212557   -13.864985   -14.326545     5.393809     4.300542\n",
      "  11.214937     5.304125     0.51108456  12.596753    19.099678\n",
      "  16.070637  ]\n",
      "The accuracy of this model is68.18181818181817\n",
      "The rmse of this model is35.57734845177661\n",
      "Split: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-10.928657    11.23934     28.51888    -11.731056    13.389902\n",
      "  -1.4735712   -8.823604    -1.6672933  -16.521065    -9.486523\n",
      "  -7.4098177    1.2181151    3.059391    17.59464    -10.224794\n",
      "  15.855391     7.129393    11.834742    14.344623    13.274035\n",
      "  -6.481411    -6.742496    17.732395    27.026808    -0.99453926\n",
      "   9.6487665   22.615019   -28.888441     6.381711     8.683287\n",
      "  26.876472   -11.278797    45.699486    17.377468    -5.5141325\n",
      "  -3.7023149    1.7067276   16.550846     7.1438355   -1.7020123\n",
      " -13.367399    11.550267     8.735429   -22.299194    -4.9594765\n",
      "  -5.429134   -11.173451    25.818033    20.86586     20.75774\n",
      "   6.2714286   25.008429    -0.86892486   2.4076462   15.386433\n",
      "   8.973665     2.5850148    3.854424     2.6273136   14.291194\n",
      "  17.93627    -12.201752    21.849953    17.976685    13.84486\n",
      "  25.08032   ]\n",
      "The accuracy of this model is68.18181818181817\n",
      "The rmse of this model is34.13398119248058\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 11.219442    24.183203   -18.897552    -3.262117   -19.849522\n",
      "  -2.7162743   13.785368    20.08814     -0.49028033  -5.259481\n",
      "   9.6408415    7.3886237   -2.321374    -7.170259    24.755188\n",
      " -24.199259    15.908651    -3.3746881   -2.6269145    6.8743944\n",
      "  -0.3565333    6.3491306   -4.5322046    5.858295    19.689444\n",
      "  11.012439    10.7789345   14.181452    -3.4418688   15.780431\n",
      "  14.400484   -11.715587     5.241352     8.57976      0.5155378\n",
      "  -7.9584618   -0.24160635  -6.6365285    1.8724463   12.231545\n",
      "  -3.7808256  -10.305229    -4.7932854   -5.061651    22.57443\n",
      "  -1.9141965   25.011261     1.3929551   36.090687     6.078452\n",
      "  25.54904     46.043728     4.050124    41.815815    12.091205\n",
      " -30.733501     5.7024255  -15.852259    20.336353    13.95095\n",
      "  24.983114    -0.42443526  19.967232    16.474962     3.0157945\n",
      "  -5.703087  ]\n",
      "The accuracy of this model is63.63636363636363\n",
      "The rmse of this model is35.15694584189429\n",
      "Split: 10\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 11.711408    6.8877587  -3.2578197   7.9720516  -3.7314777  15.060977\n",
      "  14.782671  -32.800556    1.8030797  -9.925755    7.8444033  20.242138\n",
      " -17.214453   11.133551    1.109385  -21.638891    7.8367786  18.218742\n",
      "  18.878452  -10.098855   -6.989177   20.519941   18.810772   13.951934\n",
      "   2.4325466  25.872366   21.233414   -6.1843257  -1.0884564  -4.1636186\n",
      "  25.356443    8.441508   24.687733   18.083878   -4.695211  -46.64309\n",
      "  -2.3993776   1.2258451  19.459883   -3.8088698  11.646967    0.7297937\n",
      "  -5.185724   -1.711025   12.752013   15.301805   -4.6767507  -9.148903\n",
      "   5.804755  -11.02171    -4.354877   22.078577  -25.18165    -8.722613\n",
      "  22.988588   21.049385   22.979357  -51.639668   23.180403   -3.9442177\n",
      "   8.046595   23.227612  -12.8932705 -20.78313   -10.247819   13.253336 ]\n",
      "The accuracy of this model is69.6969696969697\n",
      "The rmse of this model is36.87046613233784\n",
      "Best win percentage split = 69.6969696969697\n",
      "Best margin rmse = 30.099189094940076\n",
      "Training Testing Accuracy: 67.27% (2.16%)\n",
      "Training Testing Margins: 34.75% (2.28%)\n",
      "(651, 1)\n",
      "(651, 1)\n",
      "(651, 1030)\n",
      "X_train shape: (520, 1030)\n",
      "X_test shape: (131, 1030)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   41.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6346153846153846\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   45.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6346153846153846\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   41.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6634615384615384\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   35.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6634615384615384\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   22.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6634615384615384\n",
      "X_train shape: (520, 1030)\n",
      "X_test shape: (131, 1030)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   52.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.17498970683604428\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.17498970683604428\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   32.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.17498970683604428\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   42.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.19192438854436522\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.1940741202959829\n",
      "     Margin\n",
      "0       6.0\n",
      "1     -61.0\n",
      "2      70.0\n",
      "3       5.0\n",
      "4      27.0\n",
      "..      ...\n",
      "646     4.0\n",
      "647    22.0\n",
      "648    -1.0\n",
      "649    39.0\n",
      "650    32.0\n",
      "\n",
      "[651 rows x 1 columns]\n",
      "     H_PAV_Sum  A_PAV_Sum  Ladder Pos_H  Form_H  Season Wins_H  Season Loss_H  \\\n",
      "0       260.46     271.77           4.0     3.0           14.0            6.0   \n",
      "1       201.60     233.95           6.0     2.0           12.0            8.0   \n",
      "2       230.59     167.95          11.0     1.0            9.0           11.0   \n",
      "3       261.39     220.95          12.0     2.0            9.0           12.0   \n",
      "4       267.63     268.56           4.0     3.0           15.0            6.0   \n",
      "..         ...        ...           ...     ...            ...            ...   \n",
      "646     282.15     288.68           1.0     2.0           18.0            5.0   \n",
      "647     251.19     230.00           8.0     2.0           12.0           10.0   \n",
      "648     285.06     226.11           2.0     3.0           17.0            6.0   \n",
      "649     999.00     201.61          15.0     0.0            9.0           14.0   \n",
      "650     999.00     264.81           7.0     2.0           13.0           10.0   \n",
      "\n",
      "     Season Draw_H  H_H/A? n-1  H_H/A Win? n-1  H_Points For n-1  ...  \\\n",
      "0              0.0         0.0             0.0              73.0  ...   \n",
      "1              0.0         0.0             1.0              29.0  ...   \n",
      "2              0.0         1.0             1.0              85.0  ...   \n",
      "3              0.0         0.0             0.0             144.0  ...   \n",
      "4              0.0         0.0             0.0              88.0  ...   \n",
      "..             ...         ...             ...               ...  ...   \n",
      "646            0.0         0.0             0.0              58.0  ...   \n",
      "647            1.0         1.0             0.0              68.0  ...   \n",
      "648            0.0         1.0             0.0              86.0  ...   \n",
      "649            0.0         1.0             0.0              97.0  ...   \n",
      "650            0.0         1.0             0.0              57.0  ...   \n",
      "\n",
      "     A_Venue n-3_Manuka Oval  A_Venue n-3_Mars Stadium  \\\n",
      "0                        0.0                       0.0   \n",
      "1                        0.0                       0.0   \n",
      "2                        0.0                       0.0   \n",
      "3                        0.0                       0.0   \n",
      "4                        0.0                       0.0   \n",
      "..                       ...                       ...   \n",
      "646                      0.0                       0.0   \n",
      "647                      0.0                       0.0   \n",
      "648                      0.0                       0.0   \n",
      "649                      0.0                       0.0   \n",
      "650                      0.0                       0.0   \n",
      "\n",
      "     A_Venue n-3_Marvel Stadium  A_Venue n-3_Metricon Stadium  \\\n",
      "0                           0.0                           0.0   \n",
      "1                           1.0                           0.0   \n",
      "2                           0.0                           1.0   \n",
      "3                           0.0                           0.0   \n",
      "4                           0.0                           0.0   \n",
      "..                          ...                           ...   \n",
      "646                         0.0                           0.0   \n",
      "647                         0.0                           0.0   \n",
      "648                         0.0                           0.0   \n",
      "649                         1.0                           0.0   \n",
      "650                         0.0                           0.0   \n",
      "\n",
      "     A_Venue n-3_Norwood Oval  A_Venue n-3_Optus Stadium  A_Venue n-3_SCG  \\\n",
      "0                         0.0                        1.0              0.0   \n",
      "1                         0.0                        0.0              0.0   \n",
      "2                         0.0                        0.0              0.0   \n",
      "3                         0.0                        0.0              0.0   \n",
      "4                         0.0                        0.0              0.0   \n",
      "..                        ...                        ...              ...   \n",
      "646                       0.0                        0.0              0.0   \n",
      "647                       0.0                        0.0              1.0   \n",
      "648                       0.0                        0.0              0.0   \n",
      "649                       0.0                        0.0              0.0   \n",
      "650                       0.0                        0.0              0.0   \n",
      "\n",
      "     A_Venue n-3_TIO Stadium  A_Venue n-3_University of Tasmania Stadium  \\\n",
      "0                        0.0                                         0.0   \n",
      "1                        0.0                                         0.0   \n",
      "2                        0.0                                         0.0   \n",
      "3                        0.0                                         0.0   \n",
      "4                        0.0                                         0.0   \n",
      "..                       ...                                         ...   \n",
      "646                      0.0                                         0.0   \n",
      "647                      0.0                                         0.0   \n",
      "648                      0.0                                         0.0   \n",
      "649                      0.0                                         0.0   \n",
      "650                      0.0                                         0.0   \n",
      "\n",
      "     A_Venue n-3_University of Tasmania Statium  \n",
      "0                                           0.0  \n",
      "1                                           0.0  \n",
      "2                                           0.0  \n",
      "3                                           0.0  \n",
      "4                                           0.0  \n",
      "..                                          ...  \n",
      "646                                         0.0  \n",
      "647                                         0.0  \n",
      "648                                         0.0  \n",
      "649                                         0.0  \n",
      "650                                         0.0  \n",
      "\n",
      "[651 rows x 1030 columns]\n",
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 2.44900646e+01  3.78534546e+01  2.16680698e+01  3.47574120e+01\n",
      " -1.19661465e+01 -1.84032307e+01  2.07257004e+01  1.18281574e+01\n",
      "  2.00418472e+01  3.42906418e+01 -1.30679293e+01 -1.57300510e+01\n",
      "  2.51535473e+01  1.43486118e+01  1.40278015e+01 -4.76110601e+00\n",
      " -2.67474594e+01  1.54590902e+01 -6.16249943e+00 -7.28525543e+00\n",
      "  1.15553942e+01  3.45898724e+00  2.28579826e+01  1.70356369e+01\n",
      " -2.31373291e+01  5.20965614e+01  5.26279640e+00 -1.05381937e+01\n",
      "  2.29005356e+01  3.36262016e+01 -2.84169495e-01  2.59665728e+00\n",
      "  6.89112568e+00  1.26824541e+01  3.50402308e+00  1.18097887e+01\n",
      "  9.24523163e+00  1.70971146e+01 -9.61097050e+00  1.18377018e+01\n",
      "  6.37787938e-01 -5.93810987e+00  3.08367157e+00  1.73412800e+01\n",
      " -3.50812674e+00 -6.14947081e+00  2.24076767e+01 -4.13489342e-02\n",
      "  2.26198997e+01  7.94532728e+00  7.80463791e+00  2.28914394e+01\n",
      "  2.98110819e+00  4.98816538e+00  1.30605965e+01  1.10447769e+01\n",
      " -2.21166935e+01 -2.62075500e+01  2.75760975e+01  2.22049561e+01\n",
      " -2.34871063e+01 -5.08578181e-01  1.13705578e+01 -3.49861240e+00\n",
      " -1.51578703e+01  8.52119160e+00]\n",
      "The accuracy of this model is62.121212121212125\n",
      "The rmse of this model is32.9236458497558\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 2.0657744e+00 -7.7791214e+00 -1.9145807e+01 -1.0161592e+01\n",
      "  2.5893566e+01  1.5805673e+01  2.4677515e+00 -3.4288657e+00\n",
      "  2.1846386e+01  1.8415749e+01  1.2039811e+01 -8.1433535e+00\n",
      "  3.3421621e+00  2.8335421e+01  6.0089297e+00 -5.8376808e+00\n",
      " -8.6440504e-01  2.5176771e+01  7.7210174e+00 -5.3547630e+00\n",
      "  1.4334699e+01  2.3953419e+01  3.5191269e+01 -6.9642053e+00\n",
      "  2.3880999e+01  3.2092358e+01 -3.3897972e-01 -2.2452188e+01\n",
      "  5.2952026e+01  1.8869062e+01 -1.5686274e-02  2.5526974e+01\n",
      " -2.7368446e+01  3.8552759e+00 -2.4221087e+00  2.4707233e+01\n",
      "  3.0449755e+01  3.3846466e+01  3.3553753e+01 -3.3471386e+01\n",
      "  2.6679262e+01  1.8022724e+01  4.6127949e+00  6.1045580e+00\n",
      "  9.6623354e+00 -2.2465906e+01  2.5042171e+01 -1.4642250e+01\n",
      "  7.5215645e+00  1.2680727e+01  1.9652313e+01  5.8618612e+00\n",
      "  2.8746037e+01  1.7189802e+01 -7.6645784e+00 -3.5310044e+00\n",
      " -5.3970383e+01 -2.4240849e+00 -1.1768442e+01 -1.0340492e+00\n",
      "  2.5774796e+01 -9.3643131e+00  3.8396697e+00  2.7235651e+01\n",
      "  8.2164741e-01]\n",
      "The accuracy of this model is69.23076923076923\n",
      "The rmse of this model is29.544746996063047\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  2.4684005    5.778695    17.051294   -11.801649    -3.7746053\n",
      "  -0.28846186   6.6071725   15.770054     2.4824882  -12.502081\n",
      "   0.73017204  12.551137   -14.599402    13.116338     0.6277029\n",
      "   4.2831774   16.318712    -0.67765653  -3.7584434    8.990565\n",
      "  21.104273     6.325841    -2.1007247  -16.330818    24.44756\n",
      "  18.299488    42.21576     26.398981   -14.445832    -7.618434\n",
      "  14.565536    -5.0826364   11.802211     1.133039    10.905283\n",
      "  -5.98442    -21.98624     16.301899    24.123436    -7.9526644\n",
      "  35.967514     9.375867    25.234907     9.86929     -2.420899\n",
      "   5.866368    -8.142332   -19.466082    -3.5953698   -0.49082893\n",
      "   9.170064     2.4225533   20.804737    15.464734     1.4130235\n",
      "  21.50985      9.820292    -7.6377544   44.87647     -2.45248\n",
      "  -1.6244395   -7.082927    -4.8223515   17.669437    -4.284083  ]\n",
      "The accuracy of this model is53.84615384615385\n",
      "The rmse of this model is35.01343873886414\n",
      "Split: 4\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 16.659948    21.8093      17.816872    11.143543    16.47258\n",
      "  16.339174    23.412071    10.573542    29.880043    13.208446\n",
      " -10.395757    27.783264    -4.9830093   -2.3007479   -7.031808\n",
      "  34.21234      0.07432994  25.651194    -2.686612     1.9236366\n",
      " -11.125763    15.874319    15.046119    12.429863    -1.0186719\n",
      "   4.1482244  -14.998699    -3.5109825   26.369707     9.201926\n",
      "   3.6483083   14.037655   -11.999864    -1.8447633    2.5699096\n",
      "  25.501524    14.478829    16.98032     15.641934    15.863966\n",
      "   6.1718884   -7.694785    33.878548    14.161621     6.411984\n",
      "   9.941453    -5.954314    -4.396812    -7.255223   -11.220752\n",
      "  13.915588    17.832876    14.180954    31.225191     4.6810493\n",
      "   4.6614456  -47.551186     9.091416     5.994862   -10.744687\n",
      " -10.268211     6.6519556    7.4627423    3.9962952   10.992931  ]\n",
      "The accuracy of this model is60.0\n",
      "The rmse of this model is31.96651276594667\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 11.325153    26.205248   -15.61772      9.612969   -18.345428\n",
      "   6.2439137  -35.01828      5.474585     6.0085287    3.7844381\n",
      "  -0.9226445    1.1713927  -12.115405   -13.108315    13.539923\n",
      "  28.562532     6.2272716   17.069063    -6.8063884   -0.6243808\n",
      "   2.4394274  -16.538319    30.149273    13.073123    -5.4630637\n",
      "  45.152668    25.963604   -10.415575    11.899907     1.2785704\n",
      "  -5.3376513   25.942852    -1.7282557  -32.588684    -6.208363\n",
      "  21.939722   -27.119122    -2.447417     9.203946    19.217432\n",
      "  23.776634     7.7352734   14.953471     8.98384     -3.2080271\n",
      "  16.963276    24.177547     2.3250084  -11.679441    12.78133\n",
      " -15.295747    -5.27755    -10.952096    -0.37693888  13.776384\n",
      "   0.53188235  -1.9137037   29.394579     0.5571319  -24.77024\n",
      "  26.253569   -12.015392    15.595192     6.585997     0.06375101]\n",
      "The accuracy of this model is69.23076923076923\n",
      "The rmse of this model is36.94812173258633\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-17.123405    29.804413    18.291473    11.964662     6.0463576\n",
      "  18.094315     6.8675346  -12.15233     38.177345     3.7727592\n",
      "   4.165722     2.1970534   -1.3137543  -17.87009      7.0798388\n",
      "   0.4470223    7.553104    -7.8681164   15.336528     5.6655283\n",
      "  24.92262     32.270523     0.19527853   5.246774   -10.336013\n",
      "  -8.252174     8.278522     2.3163633  -21.42931    -18.899725\n",
      "  15.372328    25.374983   -34.56753    -14.935199    26.696669\n",
      " -10.968078    -3.5589175   23.393244    12.621994    13.145856\n",
      "  17.592882   -18.150661    16.751486    10.847169     1.8882489\n",
      "  -5.3425074   -6.333477    21.125177    46.91602     -5.0016026\n",
      "   7.164169    22.218596    18.143114   -18.766388     5.5090075\n",
      "   6.7616277   27.185326    24.274675    31.054464    24.345238\n",
      "  33.849       32.75177     -2.6549182   -5.5068593   20.406124  ]\n",
      "The accuracy of this model is66.15384615384615\n",
      "The rmse of this model is35.212563495497086\n",
      "Split: 7\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -2.2205274    6.7811337   38.879986    21.415245   -17.182156\n",
      " -20.015886    -3.1388772    5.1973166   15.464016     5.371651\n",
      "  10.936214    18.845543     2.2732265   10.356206    15.1229515\n",
      "  -2.1321425   18.598122    16.65929     -9.63477    -16.09064\n",
      "  26.25857      4.231594    -0.29708248   8.515607    21.192207\n",
      "   6.967454    28.663845     4.525843   -10.653405   -22.971596\n",
      "   3.7380989  -35.319653    12.993925    20.651009     7.319943\n",
      "  19.855371     9.0813875   23.53723     19.550573     2.2299542\n",
      "  -6.044688    20.779781    15.085762    -7.9517145    9.202307\n",
      "  -7.3332705   33.01469     30.82272     -2.1929288  -31.705791\n",
      "  21.952812     8.303496    -3.7115974   26.25004     26.323833\n",
      " -11.041036     1.1563277   -2.929244    17.00607    -14.789544\n",
      "  11.627619    -2.2754097    4.9184136   26.888422    46.064568  ]\n",
      "The accuracy of this model is61.53846153846154\n",
      "The rmse of this model is32.80169633501418\n",
      "Split: 8\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-19.434887    -0.41058558  19.421679     6.221416    -3.3903973\n",
      "  19.682623     0.23509446  12.060621    16.4633     -22.148666\n",
      " -15.939306    -4.4891787   14.059824     3.9004579   10.842321\n",
      " -13.74029     15.50456     -6.2927346   -1.9148872   -3.9538536\n",
      "  20.492636    21.601633    -2.664693    -0.22949445  -9.67502\n",
      "   4.0811586   -0.2915458  -20.520643    -6.905793    24.174566\n",
      " -11.967944     4.782307    14.259646    -9.585238   -31.891045\n",
      "  18.235819     8.05011      2.3381913   -0.3091792  -15.137719\n",
      "  -0.99013853  -2.6546478   45.84736      5.0497046    2.242379\n",
      "  24.14069     17.913893   -11.832741     6.581619    33.956333\n",
      "  20.00284     24.19975     29.460182     2.3043509    2.1828995\n",
      "  16.564133    14.059656     6.1153536    9.707788     0.5987087\n",
      " -10.065083    19.966822    -2.8780444   27.450407     7.453748  ]\n",
      "The accuracy of this model is67.6923076923077\n",
      "The rmse of this model is39.1848100159422\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  6.2126503   -0.9728409   19.282179     4.45821    -19.174852\n",
      "  42.745876   -10.976186    15.2907915   -7.4084783   12.388664\n",
      "   7.9613175   17.002401    -1.9609072   -6.9397473   14.377504\n",
      "  30.60404     -1.6718247   12.483828    16.94861      6.0167093\n",
      " -18.215904     8.1108265    1.1839299   31.556765    13.524452\n",
      " -13.101477    27.851585     5.9029326    7.948976    19.257227\n",
      "  15.683237   -28.418472    38.516476    29.179724     9.54327\n",
      "   9.268812    17.429047    45.67033     17.354166    -0.7968811\n",
      "  20.938091    -0.92358863  17.518787     2.6627026   24.103151\n",
      "  18.427633    18.12461     -0.7206038   37.92346      0.1173979\n",
      " -14.230394    42.092335    18.6456     -28.06783      8.464981\n",
      "  23.187445     7.947622    27.461048     6.0094433   -0.7765093\n",
      "   5.822788    18.358187    -1.5432639   19.762138   -10.98833   ]\n",
      "The accuracy of this model is64.61538461538461\n",
      "The rmse of this model is33.458640690199466\n",
      "Split: 10\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  8.619001   -13.604468    16.808361    -1.6667991   -2.820167\n",
      "  -8.952035    11.250835     7.076814    13.075838    -7.3257446\n",
      "   1.961829    43.011272     5.3810363   20.594673   -12.838958\n",
      "  -7.3576303   -8.360334    -8.791368    -9.131902    43.72354\n",
      "   3.054379     1.5639213   -1.0456148   19.808418     5.5194454\n",
      " -11.458126   -48.033184   -28.937963   -16.45071     12.135057\n",
      "  19.59666      0.1274826   27.574669   -14.950939     3.0497334\n",
      "  -5.1473713  -11.503023    24.424257    27.1448      19.47062\n",
      "  12.873092    -3.8866363    1.9506764   -1.5964754    2.9340863\n",
      "   7.0862145  -18.64905      3.9655905   21.943302   -34.906067\n",
      "   8.949414    20.535341    14.850526    28.120077     4.1071954\n",
      "  -2.726828     9.01867      4.239318    16.808844    20.15024\n",
      "  25.267166    -0.23273832  -4.963583     7.481017    27.035881  ]\n",
      "The accuracy of this model is66.15384615384615\n",
      "The rmse of this model is36.84150803477244\n",
      "Best win percentage split = 69.23076923076923\n",
      "Best margin rmse = 29.544746996063047\n",
      "Training Testing Accuracy: 64.06% (4.55%)\n",
      "Training Testing Margins: 34.39% (2.67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0004543221, n=356, Accuracy: 66.52%\n",
      "Thresh=0.0005354836, n=355, Accuracy: 66.83%\n",
      "Thresh=0.0006059573, n=354, Accuracy: 67.90%\n",
      "Thresh=0.0006311396, n=353, Accuracy: 67.13%\n",
      "Thresh=0.0006585732, n=352, Accuracy: 66.98%\n",
      "Thresh=0.0006637017, n=351, Accuracy: 66.68%\n",
      "Thresh=0.0006987379, n=350, Accuracy: 66.06%\n",
      "Thresh=0.0007831351, n=349, Accuracy: 66.22%\n",
      "Thresh=0.0007890332, n=348, Accuracy: 66.53%\n",
      "Thresh=0.0007918763, n=347, Accuracy: 66.69%\n",
      "Thresh=0.0007948950, n=346, Accuracy: 68.22%\n",
      "Thresh=0.0008117012, n=345, Accuracy: 67.90%\n",
      "Thresh=0.0008188041, n=344, Accuracy: 65.90%\n",
      "Thresh=0.0008246684, n=343, Accuracy: 66.21%\n",
      "Thresh=0.0008317719, n=342, Accuracy: 66.67%\n",
      "Thresh=0.0008603917, n=341, Accuracy: 65.60%\n",
      "Thresh=0.0008690546, n=340, Accuracy: 64.99%\n",
      "Thresh=0.0008707019, n=339, Accuracy: 66.52%\n",
      "Thresh=0.0008757831, n=338, Accuracy: 65.60%\n",
      "Thresh=0.0008796233, n=337, Accuracy: 65.60%\n",
      "Thresh=0.0008821049, n=336, Accuracy: 65.59%\n",
      "Thresh=0.0008832959, n=335, Accuracy: 67.13%\n",
      "Thresh=0.0008923421, n=334, Accuracy: 66.82%\n",
      "Thresh=0.0008944847, n=333, Accuracy: 65.29%\n",
      "Thresh=0.0008965433, n=332, Accuracy: 66.06%\n",
      "Thresh=0.0008984734, n=331, Accuracy: 68.05%\n",
      "Thresh=0.0009161199, n=330, Accuracy: 68.51%\n",
      "Thresh=0.0009253559, n=329, Accuracy: 69.28%\n",
      "Thresh=0.0009305628, n=328, Accuracy: 69.28%\n",
      "Thresh=0.0009309477, n=327, Accuracy: 67.59%\n",
      "Thresh=0.0009463069, n=326, Accuracy: 68.05%\n",
      "Thresh=0.0009789616, n=325, Accuracy: 66.97%\n",
      "Thresh=0.0009791367, n=324, Accuracy: 67.28%\n",
      "Thresh=0.0009834896, n=323, Accuracy: 67.90%\n",
      "Thresh=0.0009838950, n=322, Accuracy: 67.28%\n",
      "Thresh=0.0009861204, n=321, Accuracy: 67.13%\n",
      "Thresh=0.0009975124, n=320, Accuracy: 66.66%\n",
      "Thresh=0.0010005264, n=319, Accuracy: 66.66%\n",
      "Thresh=0.0010086837, n=318, Accuracy: 65.90%\n",
      "Thresh=0.0010201744, n=317, Accuracy: 64.97%\n",
      "Thresh=0.0010312281, n=316, Accuracy: 66.36%\n",
      "Thresh=0.0010346206, n=315, Accuracy: 65.74%\n",
      "Thresh=0.0010419113, n=314, Accuracy: 68.21%\n",
      "Thresh=0.0010438190, n=313, Accuracy: 66.98%\n",
      "Thresh=0.0010549724, n=312, Accuracy: 66.52%\n",
      "Thresh=0.0010572873, n=311, Accuracy: 67.13%\n",
      "Thresh=0.0010800428, n=310, Accuracy: 66.83%\n",
      "Thresh=0.0010895589, n=309, Accuracy: 66.21%\n",
      "Thresh=0.0010897869, n=308, Accuracy: 67.29%\n",
      "Thresh=0.0010987339, n=307, Accuracy: 67.44%\n",
      "Thresh=0.0011020937, n=306, Accuracy: 67.44%\n",
      "Thresh=0.0011107250, n=305, Accuracy: 67.59%\n",
      "Thresh=0.0011210524, n=304, Accuracy: 66.36%\n",
      "Thresh=0.0011246570, n=303, Accuracy: 66.52%\n",
      "Thresh=0.0011266670, n=302, Accuracy: 66.06%\n",
      "Thresh=0.0011267262, n=301, Accuracy: 66.98%\n",
      "Thresh=0.0011308914, n=300, Accuracy: 67.59%\n",
      "Thresh=0.0011324600, n=299, Accuracy: 68.21%\n",
      "Thresh=0.0011558364, n=298, Accuracy: 67.75%\n",
      "Thresh=0.0011609663, n=297, Accuracy: 65.60%\n",
      "Thresh=0.0011726017, n=296, Accuracy: 66.67%\n",
      "Thresh=0.0011764205, n=295, Accuracy: 68.52%\n",
      "Thresh=0.0011841556, n=294, Accuracy: 68.82%\n",
      "Thresh=0.0011890017, n=293, Accuracy: 68.21%\n",
      "Thresh=0.0011937266, n=292, Accuracy: 67.75%\n",
      "Thresh=0.0012006627, n=291, Accuracy: 68.52%\n",
      "Thresh=0.0012017953, n=290, Accuracy: 67.90%\n",
      "Thresh=0.0012153747, n=289, Accuracy: 68.67%\n",
      "Thresh=0.0012727750, n=288, Accuracy: 68.06%\n",
      "Thresh=0.0012925230, n=287, Accuracy: 67.29%\n",
      "Thresh=0.0013126512, n=286, Accuracy: 69.44%\n",
      "Thresh=0.0013273687, n=285, Accuracy: 66.52%\n",
      "Thresh=0.0013309750, n=284, Accuracy: 66.20%\n",
      "Thresh=0.0013461041, n=283, Accuracy: 66.06%\n",
      "Thresh=0.0013515903, n=282, Accuracy: 67.75%\n",
      "Thresh=0.0013647777, n=281, Accuracy: 66.06%\n",
      "Thresh=0.0013977677, n=280, Accuracy: 64.36%\n",
      "Thresh=0.0014085990, n=279, Accuracy: 67.75%\n",
      "Thresh=0.0014095790, n=278, Accuracy: 67.29%\n",
      "Thresh=0.0014096114, n=277, Accuracy: 67.43%\n",
      "Thresh=0.0014133983, n=276, Accuracy: 67.74%\n",
      "Thresh=0.0014314768, n=275, Accuracy: 66.67%\n",
      "Thresh=0.0014352958, n=274, Accuracy: 67.59%\n",
      "Thresh=0.0014373719, n=273, Accuracy: 67.43%\n",
      "Thresh=0.0014453134, n=272, Accuracy: 66.82%\n",
      "Thresh=0.0014485598, n=271, Accuracy: 66.97%\n",
      "Thresh=0.0014767817, n=270, Accuracy: 67.89%\n",
      "Thresh=0.0014837257, n=269, Accuracy: 66.51%\n",
      "Thresh=0.0014957330, n=268, Accuracy: 67.59%\n",
      "Thresh=0.0015100699, n=267, Accuracy: 65.90%\n",
      "Thresh=0.0015211983, n=266, Accuracy: 66.52%\n",
      "Thresh=0.0015334141, n=265, Accuracy: 68.05%\n",
      "Thresh=0.0015396868, n=264, Accuracy: 67.44%\n",
      "Thresh=0.0015512871, n=263, Accuracy: 65.28%\n",
      "Thresh=0.0015657984, n=262, Accuracy: 67.59%\n",
      "Thresh=0.0015682394, n=261, Accuracy: 67.75%\n",
      "Thresh=0.0015904558, n=260, Accuracy: 65.60%\n",
      "Thresh=0.0015954344, n=259, Accuracy: 66.82%\n",
      "Thresh=0.0015980123, n=258, Accuracy: 67.75%\n",
      "Thresh=0.0016050604, n=257, Accuracy: 68.37%\n",
      "Thresh=0.0016070474, n=256, Accuracy: 66.82%\n",
      "Thresh=0.0016249699, n=255, Accuracy: 67.13%\n",
      "Thresh=0.0016388098, n=254, Accuracy: 66.21%\n",
      "Thresh=0.0016419654, n=253, Accuracy: 69.13%\n",
      "Thresh=0.0016460537, n=252, Accuracy: 67.29%\n",
      "Thresh=0.0016546519, n=251, Accuracy: 68.05%\n",
      "Thresh=0.0016616057, n=250, Accuracy: 68.82%\n",
      "Thresh=0.0016628578, n=249, Accuracy: 68.83%\n",
      "Thresh=0.0016662530, n=248, Accuracy: 66.83%\n",
      "Thresh=0.0016688469, n=247, Accuracy: 68.36%\n",
      "Thresh=0.0016858425, n=246, Accuracy: 69.14%\n",
      "Thresh=0.0016904239, n=245, Accuracy: 69.13%\n",
      "Thresh=0.0016974167, n=244, Accuracy: 67.90%\n",
      "Thresh=0.0017040162, n=243, Accuracy: 67.90%\n",
      "Thresh=0.0017049557, n=242, Accuracy: 67.60%\n",
      "Thresh=0.0017121901, n=241, Accuracy: 67.60%\n",
      "Thresh=0.0017232216, n=240, Accuracy: 65.75%\n",
      "Thresh=0.0017232752, n=239, Accuracy: 67.60%\n",
      "Thresh=0.0017532371, n=238, Accuracy: 67.90%\n",
      "Thresh=0.0017597594, n=237, Accuracy: 66.67%\n",
      "Thresh=0.0017652061, n=236, Accuracy: 67.75%\n",
      "Thresh=0.0017765138, n=235, Accuracy: 66.83%\n",
      "Thresh=0.0017786367, n=234, Accuracy: 65.75%\n",
      "Thresh=0.0017903156, n=233, Accuracy: 65.60%\n",
      "Thresh=0.0018205704, n=232, Accuracy: 66.83%\n",
      "Thresh=0.0018430218, n=231, Accuracy: 68.82%\n",
      "Thresh=0.0018437238, n=230, Accuracy: 65.91%\n",
      "Thresh=0.0018440404, n=229, Accuracy: 67.75%\n",
      "Thresh=0.0018946313, n=228, Accuracy: 66.82%\n",
      "Thresh=0.0018979297, n=227, Accuracy: 65.75%\n",
      "Thresh=0.0019050039, n=226, Accuracy: 66.36%\n",
      "Thresh=0.0019052631, n=225, Accuracy: 67.59%\n",
      "Thresh=0.0019070460, n=224, Accuracy: 67.13%\n",
      "Thresh=0.0019128029, n=223, Accuracy: 67.28%\n",
      "Thresh=0.0019437025, n=222, Accuracy: 66.98%\n",
      "Thresh=0.0019484672, n=221, Accuracy: 68.05%\n",
      "Thresh=0.0019498750, n=220, Accuracy: 66.97%\n",
      "Thresh=0.0019518993, n=219, Accuracy: 68.51%\n",
      "Thresh=0.0019692504, n=218, Accuracy: 67.59%\n",
      "Thresh=0.0019705980, n=217, Accuracy: 67.75%\n",
      "Thresh=0.0019732963, n=216, Accuracy: 66.52%\n",
      "Thresh=0.0019776016, n=215, Accuracy: 66.67%\n",
      "Thresh=0.0019970608, n=214, Accuracy: 65.59%\n",
      "Thresh=0.0020077808, n=213, Accuracy: 66.21%\n",
      "Thresh=0.0020090370, n=212, Accuracy: 66.98%\n",
      "Thresh=0.0020128659, n=211, Accuracy: 68.21%\n",
      "Thresh=0.0020214485, n=210, Accuracy: 68.21%\n",
      "Thresh=0.0020711154, n=209, Accuracy: 69.13%\n",
      "Thresh=0.0020780677, n=208, Accuracy: 69.43%\n",
      "Thresh=0.0020879505, n=207, Accuracy: 67.28%\n",
      "Thresh=0.0020879551, n=206, Accuracy: 68.82%\n",
      "Thresh=0.0020971561, n=205, Accuracy: 66.67%\n",
      "Thresh=0.0020973615, n=204, Accuracy: 67.44%\n",
      "Thresh=0.0021260874, n=203, Accuracy: 68.97%\n",
      "Thresh=0.0021267319, n=202, Accuracy: 68.20%\n",
      "Thresh=0.0021284972, n=201, Accuracy: 68.20%\n",
      "Thresh=0.0021310719, n=200, Accuracy: 66.52%\n",
      "Thresh=0.0021334202, n=199, Accuracy: 65.75%\n",
      "Thresh=0.0021357473, n=198, Accuracy: 64.83%\n",
      "Thresh=0.0021390058, n=197, Accuracy: 67.75%\n",
      "Thresh=0.0021416363, n=196, Accuracy: 67.45%\n",
      "Thresh=0.0021492387, n=195, Accuracy: 68.52%\n",
      "Thresh=0.0021521370, n=194, Accuracy: 67.12%\n",
      "Thresh=0.0021985155, n=193, Accuracy: 65.59%\n",
      "Thresh=0.0022010047, n=192, Accuracy: 66.51%\n",
      "Thresh=0.0022177722, n=191, Accuracy: 65.44%\n",
      "Thresh=0.0022192711, n=190, Accuracy: 67.13%\n",
      "Thresh=0.0022284798, n=189, Accuracy: 67.14%\n",
      "Thresh=0.0022349211, n=188, Accuracy: 66.98%\n",
      "Thresh=0.0022359053, n=187, Accuracy: 66.36%\n",
      "Thresh=0.0022684068, n=186, Accuracy: 68.51%\n",
      "Thresh=0.0022737593, n=185, Accuracy: 66.83%\n",
      "Thresh=0.0022747202, n=184, Accuracy: 65.60%\n",
      "Thresh=0.0023089638, n=183, Accuracy: 66.98%\n",
      "Thresh=0.0023224852, n=182, Accuracy: 66.67%\n",
      "Thresh=0.0023260310, n=181, Accuracy: 66.36%\n",
      "Thresh=0.0023271693, n=180, Accuracy: 66.97%\n",
      "Thresh=0.0023391030, n=179, Accuracy: 66.35%\n",
      "Thresh=0.0023403384, n=178, Accuracy: 67.13%\n",
      "Thresh=0.0023434130, n=177, Accuracy: 68.52%\n",
      "Thresh=0.0023459629, n=176, Accuracy: 67.28%\n",
      "Thresh=0.0023542664, n=175, Accuracy: 66.66%\n",
      "Thresh=0.0023573225, n=174, Accuracy: 67.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0023616522, n=173, Accuracy: 67.59%\n",
      "Thresh=0.0023628229, n=172, Accuracy: 67.89%\n",
      "Thresh=0.0023869541, n=171, Accuracy: 68.36%\n",
      "Thresh=0.0023943994, n=170, Accuracy: 67.13%\n",
      "Thresh=0.0023972194, n=169, Accuracy: 68.05%\n",
      "Thresh=0.0024070400, n=168, Accuracy: 66.83%\n",
      "Thresh=0.0024218999, n=167, Accuracy: 67.14%\n",
      "Thresh=0.0024358116, n=166, Accuracy: 67.27%\n",
      "Thresh=0.0024653634, n=165, Accuracy: 66.51%\n",
      "Thresh=0.0025037276, n=164, Accuracy: 68.05%\n",
      "Thresh=0.0025134676, n=163, Accuracy: 67.12%\n",
      "Thresh=0.0025252616, n=162, Accuracy: 67.28%\n",
      "Thresh=0.0025542874, n=161, Accuracy: 67.28%\n",
      "Thresh=0.0025545920, n=160, Accuracy: 67.60%\n",
      "Thresh=0.0025621681, n=159, Accuracy: 69.13%\n",
      "Thresh=0.0025893711, n=158, Accuracy: 68.04%\n",
      "Thresh=0.0025929550, n=157, Accuracy: 67.74%\n",
      "Thresh=0.0026284235, n=156, Accuracy: 66.05%\n",
      "Thresh=0.0026441843, n=155, Accuracy: 67.59%\n",
      "Thresh=0.0026757440, n=154, Accuracy: 69.28%\n",
      "Thresh=0.0026776686, n=153, Accuracy: 67.74%\n",
      "Thresh=0.0026817478, n=152, Accuracy: 69.44%\n",
      "Thresh=0.0026961674, n=151, Accuracy: 67.90%\n",
      "Thresh=0.0027040702, n=150, Accuracy: 68.21%\n",
      "Thresh=0.0027104118, n=149, Accuracy: 67.28%\n",
      "Thresh=0.0027274759, n=148, Accuracy: 68.21%\n",
      "Thresh=0.0027304282, n=147, Accuracy: 68.82%\n",
      "Thresh=0.0027395184, n=146, Accuracy: 68.51%\n",
      "Thresh=0.0027817672, n=145, Accuracy: 67.13%\n",
      "Thresh=0.0027913633, n=144, Accuracy: 67.74%\n",
      "Thresh=0.0028146005, n=143, Accuracy: 68.20%\n",
      "Thresh=0.0028185067, n=142, Accuracy: 67.44%\n",
      "Thresh=0.0028231721, n=141, Accuracy: 67.13%\n",
      "Thresh=0.0028439381, n=140, Accuracy: 67.43%\n",
      "Thresh=0.0028550457, n=139, Accuracy: 68.20%\n",
      "Thresh=0.0028657177, n=138, Accuracy: 68.05%\n",
      "Thresh=0.0028917054, n=137, Accuracy: 68.82%\n",
      "Thresh=0.0029060596, n=136, Accuracy: 68.51%\n",
      "Thresh=0.0029195668, n=135, Accuracy: 69.13%\n",
      "Thresh=0.0029204350, n=134, Accuracy: 69.28%\n",
      "Thresh=0.0029209303, n=133, Accuracy: 67.29%\n",
      "Thresh=0.0029275012, n=132, Accuracy: 66.67%\n",
      "Thresh=0.0029372526, n=131, Accuracy: 67.60%\n",
      "Thresh=0.0029378454, n=130, Accuracy: 67.28%\n",
      "Thresh=0.0029462820, n=129, Accuracy: 66.52%\n",
      "Thresh=0.0029698689, n=128, Accuracy: 69.45%\n",
      "Thresh=0.0029879059, n=127, Accuracy: 68.21%\n",
      "Thresh=0.0030188470, n=126, Accuracy: 67.75%\n",
      "Thresh=0.0030303253, n=125, Accuracy: 68.52%\n",
      "Thresh=0.0030361549, n=124, Accuracy: 68.36%\n",
      "Thresh=0.0030430604, n=123, Accuracy: 67.59%\n",
      "Thresh=0.0030766453, n=122, Accuracy: 69.90%\n",
      "Thresh=0.0031082393, n=121, Accuracy: 69.59%\n",
      "Thresh=0.0031148782, n=120, Accuracy: 68.36%\n",
      "Thresh=0.0031236070, n=119, Accuracy: 69.12%\n",
      "Thresh=0.0031243816, n=118, Accuracy: 67.75%\n",
      "Thresh=0.0031441434, n=117, Accuracy: 69.59%\n",
      "Thresh=0.0031556911, n=116, Accuracy: 67.74%\n",
      "Thresh=0.0031624793, n=115, Accuracy: 68.51%\n",
      "Thresh=0.0032015643, n=114, Accuracy: 68.50%\n",
      "Thresh=0.0032255657, n=113, Accuracy: 67.43%\n",
      "Thresh=0.0032636432, n=112, Accuracy: 67.91%\n",
      "Thresh=0.0032911366, n=111, Accuracy: 66.06%\n",
      "Thresh=0.0033217603, n=110, Accuracy: 67.44%\n",
      "Thresh=0.0033242281, n=109, Accuracy: 69.45%\n",
      "Thresh=0.0033549427, n=108, Accuracy: 67.75%\n",
      "Thresh=0.0033880379, n=107, Accuracy: 69.14%\n",
      "Thresh=0.0033929821, n=106, Accuracy: 68.06%\n",
      "Thresh=0.0034130637, n=105, Accuracy: 68.21%\n",
      "Thresh=0.0034245402, n=104, Accuracy: 67.90%\n",
      "Thresh=0.0034358152, n=103, Accuracy: 67.90%\n",
      "Thresh=0.0034544982, n=102, Accuracy: 67.45%\n",
      "Thresh=0.0034689021, n=101, Accuracy: 68.52%\n",
      "Thresh=0.0035022367, n=100, Accuracy: 69.13%\n",
      "Thresh=0.0035155942, n=99, Accuracy: 68.67%\n",
      "Thresh=0.0035969336, n=98, Accuracy: 67.75%\n",
      "Thresh=0.0036135947, n=97, Accuracy: 68.52%\n",
      "Thresh=0.0036223033, n=96, Accuracy: 68.67%\n",
      "Thresh=0.0036366386, n=95, Accuracy: 69.44%\n",
      "Thresh=0.0036478972, n=94, Accuracy: 68.37%\n",
      "Thresh=0.0036663034, n=93, Accuracy: 68.82%\n",
      "Thresh=0.0036854751, n=92, Accuracy: 68.36%\n",
      "Thresh=0.0036898539, n=91, Accuracy: 66.98%\n",
      "Thresh=0.0037585993, n=90, Accuracy: 68.52%\n",
      "Thresh=0.0037620915, n=89, Accuracy: 68.68%\n",
      "Thresh=0.0037638245, n=88, Accuracy: 68.97%\n",
      "Thresh=0.0037778544, n=87, Accuracy: 68.22%\n",
      "Thresh=0.0037817045, n=86, Accuracy: 68.83%\n",
      "Thresh=0.0037862374, n=85, Accuracy: 68.98%\n",
      "Thresh=0.0037927392, n=84, Accuracy: 69.75%\n",
      "Thresh=0.0038053275, n=83, Accuracy: 67.75%\n",
      "Thresh=0.0039046048, n=82, Accuracy: 68.67%\n",
      "Thresh=0.0039493619, n=81, Accuracy: 70.67%\n",
      "Thresh=0.0039547463, n=80, Accuracy: 68.21%\n",
      "Thresh=0.0039619850, n=79, Accuracy: 69.59%\n",
      "Thresh=0.0039621578, n=78, Accuracy: 65.13%\n",
      "Thresh=0.0040289764, n=77, Accuracy: 67.13%\n",
      "Thresh=0.0040588854, n=76, Accuracy: 68.66%\n",
      "Thresh=0.0040638926, n=75, Accuracy: 68.82%\n",
      "Thresh=0.0040812488, n=74, Accuracy: 67.44%\n",
      "Thresh=0.0040821633, n=73, Accuracy: 66.35%\n",
      "Thresh=0.0040836195, n=72, Accuracy: 66.98%\n",
      "Thresh=0.0041422681, n=71, Accuracy: 67.74%\n",
      "Thresh=0.0041970746, n=70, Accuracy: 68.36%\n",
      "Thresh=0.0042295624, n=69, Accuracy: 69.59%\n",
      "Thresh=0.0042647882, n=68, Accuracy: 67.59%\n",
      "Thresh=0.0042750025, n=67, Accuracy: 68.66%\n",
      "Thresh=0.0042762975, n=66, Accuracy: 68.82%\n",
      "Thresh=0.0043085152, n=65, Accuracy: 67.43%\n",
      "Thresh=0.0043538040, n=64, Accuracy: 69.13%\n",
      "Thresh=0.0043699653, n=63, Accuracy: 67.74%\n",
      "Thresh=0.0043837638, n=62, Accuracy: 67.90%\n",
      "Thresh=0.0043888376, n=61, Accuracy: 67.75%\n",
      "Thresh=0.0043954765, n=60, Accuracy: 66.50%\n",
      "Thresh=0.0044079153, n=59, Accuracy: 65.44%\n",
      "Thresh=0.0044121412, n=58, Accuracy: 67.90%\n",
      "Thresh=0.0044193100, n=57, Accuracy: 68.21%\n",
      "Thresh=0.0045581269, n=56, Accuracy: 67.28%\n",
      "Thresh=0.0045844396, n=55, Accuracy: 67.59%\n",
      "Thresh=0.0046070814, n=54, Accuracy: 69.59%\n",
      "Thresh=0.0046085720, n=53, Accuracy: 68.67%\n",
      "Thresh=0.0046091927, n=52, Accuracy: 67.90%\n",
      "Thresh=0.0046117278, n=51, Accuracy: 66.82%\n",
      "Thresh=0.0046548382, n=50, Accuracy: 65.74%\n",
      "Thresh=0.0046723657, n=49, Accuracy: 68.81%\n",
      "Thresh=0.0046974369, n=48, Accuracy: 68.06%\n",
      "Thresh=0.0047048531, n=47, Accuracy: 68.82%\n",
      "Thresh=0.0047126338, n=46, Accuracy: 68.82%\n",
      "Thresh=0.0047485097, n=45, Accuracy: 67.28%\n",
      "Thresh=0.0047638090, n=44, Accuracy: 67.89%\n",
      "Thresh=0.0047862669, n=43, Accuracy: 66.52%\n",
      "Thresh=0.0047903992, n=42, Accuracy: 67.59%\n",
      "Thresh=0.0048736711, n=41, Accuracy: 68.67%\n",
      "Thresh=0.0049119070, n=40, Accuracy: 68.21%\n",
      "Thresh=0.0049176938, n=39, Accuracy: 69.29%\n",
      "Thresh=0.0049277279, n=38, Accuracy: 66.67%\n",
      "Thresh=0.0049600177, n=37, Accuracy: 66.52%\n",
      "Thresh=0.0050771488, n=36, Accuracy: 65.44%\n",
      "Thresh=0.0051277233, n=35, Accuracy: 66.67%\n",
      "Thresh=0.0051979544, n=34, Accuracy: 64.83%\n",
      "Thresh=0.0053421664, n=33, Accuracy: 64.69%\n",
      "Thresh=0.0053547588, n=32, Accuracy: 65.44%\n",
      "Thresh=0.0054044770, n=31, Accuracy: 67.59%\n",
      "Thresh=0.0054208934, n=30, Accuracy: 67.28%\n",
      "Thresh=0.0055374745, n=29, Accuracy: 65.74%\n",
      "Thresh=0.0055969860, n=28, Accuracy: 66.52%\n",
      "Thresh=0.0056192712, n=27, Accuracy: 64.98%\n",
      "Thresh=0.0056288997, n=26, Accuracy: 64.06%\n",
      "Thresh=0.0056561348, n=25, Accuracy: 66.06%\n",
      "Thresh=0.0057273312, n=24, Accuracy: 63.59%\n",
      "Thresh=0.0059592579, n=23, Accuracy: 65.43%\n",
      "Thresh=0.0060156765, n=22, Accuracy: 65.44%\n",
      "Thresh=0.0061924690, n=21, Accuracy: 66.05%\n",
      "Thresh=0.0062506562, n=20, Accuracy: 64.97%\n",
      "Thresh=0.0063745454, n=19, Accuracy: 63.12%\n",
      "Thresh=0.0066715195, n=18, Accuracy: 62.82%\n",
      "Thresh=0.0068101310, n=17, Accuracy: 64.98%\n",
      "Thresh=0.0068698097, n=16, Accuracy: 65.12%\n",
      "Thresh=0.0069578514, n=15, Accuracy: 63.89%\n",
      "Thresh=0.0072340784, n=14, Accuracy: 64.35%\n",
      "Thresh=0.0072568958, n=13, Accuracy: 63.73%\n",
      "Thresh=0.0072627221, n=12, Accuracy: 63.90%\n",
      "Thresh=0.0073656002, n=11, Accuracy: 62.98%\n",
      "Thresh=0.0075000105, n=10, Accuracy: 64.36%\n",
      "Thresh=0.0076203886, n=9, Accuracy: 64.36%\n",
      "Thresh=0.0076534706, n=8, Accuracy: 62.21%\n",
      "Thresh=0.0079743955, n=7, Accuracy: 60.97%\n",
      "Thresh=0.0081937369, n=6, Accuracy: 57.76%\n",
      "Thresh=0.0084583173, n=5, Accuracy: 57.30%\n",
      "Thresh=0.0085164290, n=4, Accuracy: 57.29%\n",
      "Thresh=0.0087669604, n=3, Accuracy: 55.14%\n",
      "Thresh=0.0087831477, n=2, Accuracy: 54.37%\n",
      "Thresh=0.0112056034, n=1, Accuracy: 59.75%\n",
      "max accuracy is: 70.66666666666666for threshold: 0.003949362\n",
      "SelectFromModel(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                        colsample_bylevel=1.0,\n",
      "                                        colsample_bynode=1,\n",
      "                                        colsample_bytree=0.1973246737612914,\n",
      "                                        gamma=0.49999999999999994, gpu_id=-1,\n",
      "                                        importance_type='gain',\n",
      "                                        interaction_constraints='',\n",
      "                                        learning_rate=0.18046021990651956,\n",
      "                                        max_delta_step=7, max_depth=5,\n",
      "                                        min_child_weight=5, missing=nan,\n",
      "                                        monotone_constraints='()',\n",
      "                                        n_estimators=119, n_jobs=0,\n",
      "                                        num_parallel_tree=1,\n",
      "                                        objective='binary:logistic',\n",
      "                                        random_state=27022013,\n",
      "                                        reg_alpha=1.0768826889534145e-08,\n",
      "                                        reg_lambda=1e-09,\n",
      "                                        scale_pos_weight=0.9718122674164041,\n",
      "                                        subsample=0.6412903886234694,\n",
      "                                        tree_method='exact',\n",
      "                                        validate_parameters=1, verbosity=None),\n",
      "                max_features=None, norm_order=1, prefit=True,\n",
      "                threshold=0.003949362)\n",
      "X_train shape: (520, 81)\n",
      "X_test shape: (131, 81)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6711538461538461\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6711538461538461\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6711538461538461\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6826923076923077\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6826923076923077\n",
      "         0       1     2     3      4     5     6      7     8     9   ...  \\\n",
      "0    260.46  271.77  40.0  11.0  20.89  59.0  18.6  151.0  53.0   7.0  ...   \n",
      "1    201.60  233.95  43.0   4.0  38.67  42.0   9.5  144.0  38.0   4.0  ...   \n",
      "2    230.59  167.95  38.0  13.0  19.85  65.0  20.0  157.0  43.0   4.0  ...   \n",
      "3    261.39  220.95  30.0  22.0  15.12  63.0  34.9  175.0  35.0   8.0  ...   \n",
      "4    267.63  268.56  50.0  13.0  15.43  62.0  21.0  155.0  36.0   4.0  ...   \n",
      "..      ...     ...   ...   ...    ...   ...   ...    ...   ...   ...  ...   \n",
      "646  282.15  288.68  45.0   8.0  19.78  52.0  15.4  140.0  28.0   7.0  ...   \n",
      "647  251.19  230.00  35.0   9.0  15.74  46.0  19.6  135.0  36.0   7.0  ...   \n",
      "648  285.06  226.11  32.0  13.0  14.67  43.0  30.2  122.0  50.0  13.0  ...   \n",
      "649  999.00  201.61  37.0  14.0  13.74  53.0  26.4  128.0  42.0   7.0  ...   \n",
      "650  999.00  264.81  28.0   8.0  22.18  48.0  16.7  154.0  45.0   9.0  ...   \n",
      "\n",
      "        71     72    73   74    75    76    77     78   79   80  \n",
      "0    216.0  160.0  33.0  8.0  10.0  46.0   2.0   60.0  0.0  0.0  \n",
      "1    248.0  169.0  48.0  7.0   9.0  44.0   3.0   66.7  0.0  0.0  \n",
      "2    203.0  134.0  45.0  8.0  16.0  55.0   7.0   62.5  0.0  1.0  \n",
      "3    213.0  153.0  67.0  7.0  13.0  70.0   9.0   76.9  1.0  0.0  \n",
      "4    220.0  101.0  47.0  7.0  11.0  59.0   4.0  100.0  0.0  0.0  \n",
      "..     ...    ...   ...  ...   ...   ...   ...    ...  ...  ...  \n",
      "646  220.0  120.0  50.0  5.0   9.0  38.0  10.0   55.6  0.0  0.0  \n",
      "647  214.0  143.0  46.0  7.0   7.0  51.0   2.0   71.4  0.0  0.0  \n",
      "648  231.0  140.0  62.0  4.0   9.0  46.0   4.0   66.7  0.0  0.0  \n",
      "649  203.0  153.0  56.0  5.0  14.0  58.0   8.0   78.6  0.0  0.0  \n",
      "650  212.0  107.0  72.0  1.0   7.0  69.0   2.0   57.1  0.0  0.0  \n",
      "\n",
      "[651 rows x 81 columns]\n",
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 2.44900646e+01  3.78534546e+01  2.16680698e+01  3.47574120e+01\n",
      " -1.19661465e+01 -1.84032307e+01  2.07257004e+01  1.18281574e+01\n",
      "  2.00418472e+01  3.42906418e+01 -1.30679293e+01 -1.57300510e+01\n",
      "  2.51535473e+01  1.43486118e+01  1.40278015e+01 -4.76110601e+00\n",
      " -2.67474594e+01  1.54590902e+01 -6.16249943e+00 -7.28525543e+00\n",
      "  1.15553942e+01  3.45898724e+00  2.28579826e+01  1.70356369e+01\n",
      " -2.31373291e+01  5.20965614e+01  5.26279640e+00 -1.05381937e+01\n",
      "  2.29005356e+01  3.36262016e+01 -2.84169495e-01  2.59665728e+00\n",
      "  6.89112568e+00  1.26824541e+01  3.50402308e+00  1.18097887e+01\n",
      "  9.24523163e+00  1.70971146e+01 -9.61097050e+00  1.18377018e+01\n",
      "  6.37787938e-01 -5.93810987e+00  3.08367157e+00  1.73412800e+01\n",
      " -3.50812674e+00 -6.14947081e+00  2.24076767e+01 -4.13489342e-02\n",
      "  2.26198997e+01  7.94532728e+00  7.80463791e+00  2.28914394e+01\n",
      "  2.98110819e+00  4.98816538e+00  1.30605965e+01  1.10447769e+01\n",
      " -2.21166935e+01 -2.62075500e+01  2.75760975e+01  2.22049561e+01\n",
      " -2.34871063e+01 -5.08578181e-01  1.13705578e+01 -3.49861240e+00\n",
      " -1.51578703e+01  8.52119160e+00]\n",
      "The accuracy of this model is60.60606060606061\n",
      "The rmse of this model is32.9236458497558\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 2.0657744e+00 -7.7791214e+00 -1.9145807e+01 -1.0161592e+01\n",
      "  2.5893566e+01  1.5805673e+01  2.4677515e+00 -3.4288657e+00\n",
      "  2.1846386e+01  1.8415749e+01  1.2039811e+01 -8.1433535e+00\n",
      "  3.3421621e+00  2.8335421e+01  6.0089297e+00 -5.8376808e+00\n",
      " -8.6440504e-01  2.5176771e+01  7.7210174e+00 -5.3547630e+00\n",
      "  1.4334699e+01  2.3953419e+01  3.5191269e+01 -6.9642053e+00\n",
      "  2.3880999e+01  3.2092358e+01 -3.3897972e-01 -2.2452188e+01\n",
      "  5.2952026e+01  1.8869062e+01 -1.5686274e-02  2.5526974e+01\n",
      " -2.7368446e+01  3.8552759e+00 -2.4221087e+00  2.4707233e+01\n",
      "  3.0449755e+01  3.3846466e+01  3.3553753e+01 -3.3471386e+01\n",
      "  2.6679262e+01  1.8022724e+01  4.6127949e+00  6.1045580e+00\n",
      "  9.6623354e+00 -2.2465906e+01  2.5042171e+01 -1.4642250e+01\n",
      "  7.5215645e+00  1.2680727e+01  1.9652313e+01  5.8618612e+00\n",
      "  2.8746037e+01  1.7189802e+01 -7.6645784e+00 -3.5310044e+00\n",
      " -5.3970383e+01 -2.4240849e+00 -1.1768442e+01 -1.0340492e+00\n",
      "  2.5774796e+01 -9.3643131e+00  3.8396697e+00  2.7235651e+01\n",
      "  8.2164741e-01]\n",
      "The accuracy of this model is70.76923076923077\n",
      "The rmse of this model is29.544746996063047\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 3\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  2.4684005    5.778695    17.051294   -11.801649    -3.7746053\n",
      "  -0.28846186   6.6071725   15.770054     2.4824882  -12.502081\n",
      "   0.73017204  12.551137   -14.599402    13.116338     0.6277029\n",
      "   4.2831774   16.318712    -0.67765653  -3.7584434    8.990565\n",
      "  21.104273     6.325841    -2.1007247  -16.330818    24.44756\n",
      "  18.299488    42.21576     26.398981   -14.445832    -7.618434\n",
      "  14.565536    -5.0826364   11.802211     1.133039    10.905283\n",
      "  -5.98442    -21.98624     16.301899    24.123436    -7.9526644\n",
      "  35.967514     9.375867    25.234907     9.86929     -2.420899\n",
      "   5.866368    -8.142332   -19.466082    -3.5953698   -0.49082893\n",
      "   9.170064     2.4225533   20.804737    15.464734     1.4130235\n",
      "  21.50985      9.820292    -7.6377544   44.87647     -2.45248\n",
      "  -1.6244395   -7.082927    -4.8223515   17.669437    -4.284083  ]\n",
      "The accuracy of this model is60.0\n",
      "The rmse of this model is35.01343873886414\n",
      "Split: 4\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 16.659948    21.8093      17.816872    11.143543    16.47258\n",
      "  16.339174    23.412071    10.573542    29.880043    13.208446\n",
      " -10.395757    27.783264    -4.9830093   -2.3007479   -7.031808\n",
      "  34.21234      0.07432994  25.651194    -2.686612     1.9236366\n",
      " -11.125763    15.874319    15.046119    12.429863    -1.0186719\n",
      "   4.1482244  -14.998699    -3.5109825   26.369707     9.201926\n",
      "   3.6483083   14.037655   -11.999864    -1.8447633    2.5699096\n",
      "  25.501524    14.478829    16.98032     15.641934    15.863966\n",
      "   6.1718884   -7.694785    33.878548    14.161621     6.411984\n",
      "   9.941453    -5.954314    -4.396812    -7.255223   -11.220752\n",
      "  13.915588    17.832876    14.180954    31.225191     4.6810493\n",
      "   4.6614456  -47.551186     9.091416     5.994862   -10.744687\n",
      " -10.268211     6.6519556    7.4627423    3.9962952   10.992931  ]\n",
      "The accuracy of this model is55.38461538461539\n",
      "The rmse of this model is31.96651276594667\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 11.325153    26.205248   -15.61772      9.612969   -18.345428\n",
      "   6.2439137  -35.01828      5.474585     6.0085287    3.7844381\n",
      "  -0.9226445    1.1713927  -12.115405   -13.108315    13.539923\n",
      "  28.562532     6.2272716   17.069063    -6.8063884   -0.6243808\n",
      "   2.4394274  -16.538319    30.149273    13.073123    -5.4630637\n",
      "  45.152668    25.963604   -10.415575    11.899907     1.2785704\n",
      "  -5.3376513   25.942852    -1.7282557  -32.588684    -6.208363\n",
      "  21.939722   -27.119122    -2.447417     9.203946    19.217432\n",
      "  23.776634     7.7352734   14.953471     8.98384     -3.2080271\n",
      "  16.963276    24.177547     2.3250084  -11.679441    12.78133\n",
      " -15.295747    -5.27755    -10.952096    -0.37693888  13.776384\n",
      "   0.53188235  -1.9137037   29.394579     0.5571319  -24.77024\n",
      "  26.253569   -12.015392    15.595192     6.585997     0.06375101]\n",
      "The accuracy of this model is70.76923076923077\n",
      "The rmse of this model is36.94812173258633\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-17.123405    29.804413    18.291473    11.964662     6.0463576\n",
      "  18.094315     6.8675346  -12.15233     38.177345     3.7727592\n",
      "   4.165722     2.1970534   -1.3137543  -17.87009      7.0798388\n",
      "   0.4470223    7.553104    -7.8681164   15.336528     5.6655283\n",
      "  24.92262     32.270523     0.19527853   5.246774   -10.336013\n",
      "  -8.252174     8.278522     2.3163633  -21.42931    -18.899725\n",
      "  15.372328    25.374983   -34.56753    -14.935199    26.696669\n",
      " -10.968078    -3.5589175   23.393244    12.621994    13.145856\n",
      "  17.592882   -18.150661    16.751486    10.847169     1.8882489\n",
      "  -5.3425074   -6.333477    21.125177    46.91602     -5.0016026\n",
      "   7.164169    22.218596    18.143114   -18.766388     5.5090075\n",
      "   6.7616277   27.185326    24.274675    31.054464    24.345238\n",
      "  33.849       32.75177     -2.6549182   -5.5068593   20.406124  ]\n",
      "The accuracy of this model is66.15384615384615\n",
      "The rmse of this model is35.212563495497086\n",
      "Split: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -2.2205274    6.7811337   38.879986    21.415245   -17.182156\n",
      " -20.015886    -3.1388772    5.1973166   15.464016     5.371651\n",
      "  10.936214    18.845543     2.2732265   10.356206    15.1229515\n",
      "  -2.1321425   18.598122    16.65929     -9.63477    -16.09064\n",
      "  26.25857      4.231594    -0.29708248   8.515607    21.192207\n",
      "   6.967454    28.663845     4.525843   -10.653405   -22.971596\n",
      "   3.7380989  -35.319653    12.993925    20.651009     7.319943\n",
      "  19.855371     9.0813875   23.53723     19.550573     2.2299542\n",
      "  -6.044688    20.779781    15.085762    -7.9517145    9.202307\n",
      "  -7.3332705   33.01469     30.82272     -2.1929288  -31.705791\n",
      "  21.952812     8.303496    -3.7115974   26.25004     26.323833\n",
      " -11.041036     1.1563277   -2.929244    17.00607    -14.789544\n",
      "  11.627619    -2.2754097    4.9184136   26.888422    46.064568  ]\n",
      "The accuracy of this model is70.76923076923077\n",
      "The rmse of this model is32.80169633501418\n",
      "Split: 8\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-19.434887    -0.41058558  19.421679     6.221416    -3.3903973\n",
      "  19.682623     0.23509446  12.060621    16.4633     -22.148666\n",
      " -15.939306    -4.4891787   14.059824     3.9004579   10.842321\n",
      " -13.74029     15.50456     -6.2927346   -1.9148872   -3.9538536\n",
      "  20.492636    21.601633    -2.664693    -0.22949445  -9.67502\n",
      "   4.0811586   -0.2915458  -20.520643    -6.905793    24.174566\n",
      " -11.967944     4.782307    14.259646    -9.585238   -31.891045\n",
      "  18.235819     8.05011      2.3381913   -0.3091792  -15.137719\n",
      "  -0.99013853  -2.6546478   45.84736      5.0497046    2.242379\n",
      "  24.14069     17.913893   -11.832741     6.581619    33.956333\n",
      "  20.00284     24.19975     29.460182     2.3043509    2.1828995\n",
      "  16.564133    14.059656     6.1153536    9.707788     0.5987087\n",
      " -10.065083    19.966822    -2.8780444   27.450407     7.453748  ]\n",
      "The accuracy of this model is69.23076923076923\n",
      "The rmse of this model is39.1848100159422\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  6.2126503   -0.9728409   19.282179     4.45821    -19.174852\n",
      "  42.745876   -10.976186    15.2907915   -7.4084783   12.388664\n",
      "   7.9613175   17.002401    -1.9609072   -6.9397473   14.377504\n",
      "  30.60404     -1.6718247   12.483828    16.94861      6.0167093\n",
      " -18.215904     8.1108265    1.1839299   31.556765    13.524452\n",
      " -13.101477    27.851585     5.9029326    7.948976    19.257227\n",
      "  15.683237   -28.418472    38.516476    29.179724     9.54327\n",
      "   9.268812    17.429047    45.67033     17.354166    -0.7968811\n",
      "  20.938091    -0.92358863  17.518787     2.6627026   24.103151\n",
      "  18.427633    18.12461     -0.7206038   37.92346      0.1173979\n",
      " -14.230394    42.092335    18.6456     -28.06783      8.464981\n",
      "  23.187445     7.947622    27.461048     6.0094433   -0.7765093\n",
      "   5.822788    18.358187    -1.5432639   19.762138   -10.98833   ]\n",
      "The accuracy of this model is72.3076923076923\n",
      "The rmse of this model is33.458640690199466\n",
      "found new best classify\n",
      "Split: 10\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  8.619001   -13.604468    16.808361    -1.6667991   -2.820167\n",
      "  -8.952035    11.250835     7.076814    13.075838    -7.3257446\n",
      "   1.961829    43.011272     5.3810363   20.594673   -12.838958\n",
      "  -7.3576303   -8.360334    -8.791368    -9.131902    43.72354\n",
      "   3.054379     1.5639213   -1.0456148   19.808418     5.5194454\n",
      " -11.458126   -48.033184   -28.937963   -16.45071     12.135057\n",
      "  19.59666      0.1274826   27.574669   -14.950939     3.0497334\n",
      "  -5.1473713  -11.503023    24.424257    27.1448      19.47062\n",
      "  12.873092    -3.8866363    1.9506764   -1.5964754    2.9340863\n",
      "   7.0862145  -18.64905      3.9655905   21.943302   -34.906067\n",
      "   8.949414    20.535341    14.850526    28.120077     4.1071954\n",
      "  -2.726828     9.01867      4.239318    16.808844    20.15024\n",
      "  25.267166    -0.23273832  -4.963583     7.481017    27.035881  ]\n",
      "The accuracy of this model is67.6923076923077\n",
      "The rmse of this model is36.84150803477244\n",
      "Best win percentage split = 72.3076923076923\n",
      "Best margin rmse = 29.544746996063047\n",
      "Training Testing Accuracy: 66.37% (5.46%)\n",
      "Training Testing Margins: 34.39% (2.67%)\n",
      "(588, 1)\n",
      "(588, 1)\n",
      "(588, 3197)\n",
      "X_train shape: (470, 3197)\n",
      "X_test shape: (118, 3197)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6680851063829787\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   45.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6680851063829787\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6680851063829787\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6680851063829787\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6787234042553192\n",
      "X_train shape: (470, 3197)\n",
      "X_test shape: (118, 3197)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.13129682098138024\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.1427213542254938\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.16885778395421389\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.16885778395421389\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.16885778395421389\n",
      "     Margin\n",
      "0     -50.0\n",
      "1      30.0\n",
      "2     -39.0\n",
      "3      97.0\n",
      "4      40.0\n",
      "..      ...\n",
      "583     4.0\n",
      "584    22.0\n",
      "585    -1.0\n",
      "586    39.0\n",
      "587    32.0\n",
      "\n",
      "[588 rows x 1 columns]\n",
      "     H_PAV_Sum  A_PAV_Sum  Ladder Pos_H  Form_H  Season Wins_H  Season Loss_H  \\\n",
      "0       153.18     220.73          17.0     1.0            1.0            3.0   \n",
      "1       271.70     111.92          10.0     2.0            2.0            2.0   \n",
      "2       165.38     221.03          12.0     2.0            2.0            3.0   \n",
      "3       243.72     222.30           8.0     3.0            3.0            2.0   \n",
      "4       225.93     202.16          15.0     1.0            1.0            4.0   \n",
      "..         ...        ...           ...     ...            ...            ...   \n",
      "583     282.15     288.68           1.0     7.0           18.0            5.0   \n",
      "584     251.19     230.00           8.0     7.0           12.0           10.0   \n",
      "585     285.06     226.11           2.0     8.0           17.0            6.0   \n",
      "586     999.00     201.61          15.0     3.0            9.0           14.0   \n",
      "587     999.00     264.81           7.0     8.0           13.0           10.0   \n",
      "\n",
      "     Season Draw_H  H_H/A? n-1  H_H/A Win? n-1  H_Points For n-1  ...  \\\n",
      "0              0.0         1.0             0.0              81.0  ...   \n",
      "1              0.0         1.0             0.0              60.0  ...   \n",
      "2              0.0         1.0             1.0              71.0  ...   \n",
      "3              0.0         0.0             0.0              77.0  ...   \n",
      "4              0.0         1.0             0.0              56.0  ...   \n",
      "..             ...         ...             ...               ...  ...   \n",
      "583            0.0         0.0             0.0              58.0  ...   \n",
      "584            1.0         1.0             0.0              68.0  ...   \n",
      "585            0.0         1.0             0.0              86.0  ...   \n",
      "586            0.0         1.0             0.0              97.0  ...   \n",
      "587            0.0         1.0             0.0              57.0  ...   \n",
      "\n",
      "     A_Venue n-10_Manuka Oval  A_Venue n-10_Mars Stadium  \\\n",
      "0                         0.0                        0.0   \n",
      "1                         0.0                        0.0   \n",
      "2                         0.0                        0.0   \n",
      "3                         0.0                        0.0   \n",
      "4                         0.0                        0.0   \n",
      "..                        ...                        ...   \n",
      "583                       0.0                        0.0   \n",
      "584                       0.0                        0.0   \n",
      "585                       0.0                        0.0   \n",
      "586                       0.0                        0.0   \n",
      "587                       0.0                        0.0   \n",
      "\n",
      "     A_Venue n-10_Marvel Stadium  A_Venue n-10_Metricon Stadium  \\\n",
      "0                            0.0                            0.0   \n",
      "1                            0.0                            0.0   \n",
      "2                            0.0                            0.0   \n",
      "3                            0.0                            0.0   \n",
      "4                            0.0                            0.0   \n",
      "..                           ...                            ...   \n",
      "583                          0.0                            0.0   \n",
      "584                          1.0                            0.0   \n",
      "585                          1.0                            0.0   \n",
      "586                          0.0                            0.0   \n",
      "587                          0.0                            0.0   \n",
      "\n",
      "     A_Venue n-10_Norwood Oval  A_Venue n-10_Optus Stadium  A_Venue n-10_SCG  \\\n",
      "0                          0.0                         0.0               0.0   \n",
      "1                          0.0                         0.0               0.0   \n",
      "2                          0.0                         0.0               0.0   \n",
      "3                          0.0                         1.0               0.0   \n",
      "4                          0.0                         0.0               1.0   \n",
      "..                         ...                         ...               ...   \n",
      "583                        0.0                         0.0               0.0   \n",
      "584                        0.0                         0.0               0.0   \n",
      "585                        0.0                         0.0               0.0   \n",
      "586                        0.0                         0.0               0.0   \n",
      "587                        0.0                         0.0               0.0   \n",
      "\n",
      "     A_Venue n-10_TIO Stadium  A_Venue n-10_TIO Traeger Park  \\\n",
      "0                         0.0                            1.0   \n",
      "1                         0.0                            0.0   \n",
      "2                         0.0                            0.0   \n",
      "3                         0.0                            0.0   \n",
      "4                         0.0                            0.0   \n",
      "..                        ...                            ...   \n",
      "583                       0.0                            0.0   \n",
      "584                       0.0                            0.0   \n",
      "585                       0.0                            0.0   \n",
      "586                       0.0                            0.0   \n",
      "587                       0.0                            0.0   \n",
      "\n",
      "     A_Venue n-10_University of Tasmania Stadium  \n",
      "0                                            0.0  \n",
      "1                                            0.0  \n",
      "2                                            0.0  \n",
      "3                                            0.0  \n",
      "4                                            0.0  \n",
      "..                                           ...  \n",
      "583                                          0.0  \n",
      "584                                          0.0  \n",
      "585                                          0.0  \n",
      "586                                          0.0  \n",
      "587                                          0.0  \n",
      "\n",
      "[588 rows x 3197 columns]\n",
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -0.21987736  20.250814   -19.073978    -0.919021    13.837525\n",
      "  35.68171     18.04242     -3.1485515   -7.2493677    7.021889\n",
      "  -5.7917767   14.896067    -2.5937061   14.604222    28.657246\n",
      " -12.939452    16.445583    -5.802227    25.397085    18.223167\n",
      "  20.556377   -14.210878    -1.8626618   -6.0442977   16.029823\n",
      " -29.039207    -9.354258     8.597378   -25.83505    -20.778858\n",
      "  12.729288    14.169562    20.19467      6.026655   -28.135572\n",
      "  11.253288    35.556095    40.3074      32.307922   -27.703648\n",
      " -17.398647   -19.013338    26.929255   -21.040787    15.61627\n",
      "  -8.804467    -2.565005    -3.0488746   14.23246      5.4308558\n",
      "   9.514693    19.083302    42.527164    16.133121   -16.81689\n",
      "  -5.041564    20.569706     2.2595706   41.31718   ]\n",
      "The accuracy of this model is59.32203389830508\n",
      "The rmse of this model is34.13846453826125\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  5.725937     8.25313     -7.10013      8.671521    24.459404\n",
      " -10.17421    -10.106241    14.312805    -4.474455    -8.181011\n",
      "  -9.915964    12.882906     5.896421   -14.858349    13.365591\n",
      "  -1.4823058   14.649452   -23.112425    -1.2580119    2.5311294\n",
      " -17.070377     3.2119925    8.223803    26.815475    22.956648\n",
      "  21.431332     9.51892     20.72569      3.0928297   25.75275\n",
      " -24.656605     8.251276    37.944317    47.678596   -10.87561\n",
      "   2.5429113    4.6013703   14.986763    19.929684     8.521501\n",
      "  33.582226    20.599062     6.3694186   29.474083    10.95358\n",
      "   2.0554004   13.963576    12.097475    16.398407     0.8684002\n",
      " -10.134967    -0.25273484  23.531065     1.5383445   21.82167\n",
      "  15.639459    -5.5379543   -4.7314787    9.333968  ]\n",
      "The accuracy of this model is61.016949152542374\n",
      "The rmse of this model is34.45531534805608\n",
      "found new best classify\n",
      "Split: 3\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -9.321343   30.270184    1.0539532   8.259073   10.152626    4.03022\n",
      "  28.494009   -3.4252892  -7.8551655  -9.331161   -9.699861   26.891146\n",
      "  13.11736    25.095352  -12.8031435 -27.827158   -7.389784   -5.2954307\n",
      " -10.109796  -13.776615  -25.785208   17.632385   31.541803    8.773183\n",
      " -11.530463   28.12512   -22.193926  -10.249711   37.703335   12.303743\n",
      "   7.1501884  19.31222    -5.3911705  13.386565   -4.1513205  -6.7627335\n",
      "   9.180627   36.154415    1.0509033 -21.00766    13.02405    10.922565\n",
      "  15.779665    2.2348008   3.9211915   4.0769587   2.7114089  13.191089\n",
      "   0.9950682  16.831108   25.424585    8.6317    -39.029823    2.277463\n",
      "  18.465534  -10.555899   -3.5416026  13.19945     2.770177 ]\n",
      "The accuracy of this model is61.016949152542374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of this model is30.85869264527205\n",
      "found best new margin\n",
      "Split: 4\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  2.8846517   10.756632    17.99359     28.387741    15.894896\n",
      "  -9.32296     -5.107439   -17.969978     1.895218     3.773797\n",
      "  32.977654    -5.5125346   27.755266    -6.1250367  -20.880125\n",
      "  20.796103    21.14366     17.257313    15.449631    28.94651\n",
      "  13.333422     0.2956965    0.59703434 -37.090626     6.7640452\n",
      "   2.2937732    8.187986    18.268597    -0.99448025   1.2282732\n",
      "  10.274497     7.7566066  -11.456727     1.340229     0.95797944\n",
      "  21.273487     3.1075082   36.482452   -21.111416     9.583497\n",
      "  10.847342   -13.77639     -2.4415214   -0.47412294  -4.3920236\n",
      " -22.668108    19.189234    18.923464   -46.771816     6.1500635\n",
      "  26.545374    16.200344   -43.780434   -12.533001   -18.287632\n",
      "  -0.7046343   15.759409    21.70708     27.302013  ]\n",
      "The accuracy of this model is71.1864406779661\n",
      "The rmse of this model is38.49804669559259\n",
      "found new best classify\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -6.812851  -18.234928   -5.6840963  24.528297  -14.791647   16.73218\n",
      "  -3.2584865  12.921974    2.2197905  16.642006   14.855667   26.600048\n",
      "   6.8495355   8.8055725  -3.402348   -4.9078546  -3.9328375   4.9245424\n",
      " -12.514183   10.985659    4.8294597   6.9788485   2.9119995  34.681744\n",
      "  24.947153    2.2624414  29.001194   12.444425   11.3918705 -20.723587\n",
      "  14.434365   22.687428   12.112321   -4.6480813  21.239384   10.390415\n",
      "  17.162436    1.3033428  -5.061241    6.775756  -10.360685   24.685566\n",
      " -25.724192   46.80408    20.416664   24.498714   11.698507   15.607437\n",
      "  25.979017    0.7957052   6.730408  -14.767423   16.90489   -15.951498\n",
      "  25.897835   19.270462   23.965843   -1.3393973  -6.683384 ]\n",
      "The accuracy of this model is72.88135593220339\n",
      "The rmse of this model is31.886989815368498\n",
      "found new best classify\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  4.2422295   6.045571   18.86452    -4.8309245   6.349068   -8.384319\n",
      "   4.7208085  10.882137   -2.5310035  33.19598     4.6666927  -9.684718\n",
      "  14.017967   31.972218  -14.743705   -6.972444   12.0919695 -29.371595\n",
      "  -5.307842    7.6006794  12.620378  -15.642353   51.857277   32.98972\n",
      "  -9.273917    7.9552927 -12.739905  -30.014236   41.638626    3.38134\n",
      "  12.89049     7.397335    8.065159   -8.399765   38.491806   -1.8749027\n",
      "  14.416346   12.660065    9.126107  -33.614647    8.536108   35.57548\n",
      "   7.5267386  21.186197   23.042887    7.468418   18.939808   -4.398913\n",
      "  18.077637   47.971962   46.093334   21.832819    2.4105282   3.5113173\n",
      "  -7.748292   26.328548   11.457633  -19.348007    9.856533 ]\n",
      "The accuracy of this model is69.49152542372882\n",
      "The rmse of this model is33.14661437946208\n",
      "Split: 7\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-16.146229    12.807809   -19.054592     0.64004385 -12.04411\n",
      "  18.795042    18.440931    12.47375    -14.76242     12.068268\n",
      "  -4.058438     0.7115315   -6.4008517    9.814343     2.6077497\n",
      "  -6.7274847  -21.18953      6.989531    -6.792478   -14.523888\n",
      "  18.249283     8.532947    22.75842     16.365217    -6.4673247\n",
      "   2.519791   -24.275639    21.69656     22.354946   -24.059046\n",
      "  10.7681675  -24.375067    17.419975    31.952734    -1.6290145\n",
      " -15.238448   -17.527027   -11.211885    19.646437     2.3205948\n",
      "  21.105461     9.989442    36.73228     -9.064586   -19.889458\n",
      " -14.13822    -17.514145    30.446209    18.630396    12.572779\n",
      "  17.54524      4.9908714   -5.2340384   21.197468    19.271349\n",
      " -23.347963    19.251852     9.849607    24.898478  ]\n",
      "The accuracy of this model is66.10169491525424\n",
      "The rmse of this model is32.67855647927645\n",
      "Split: 8\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 16.632965  -16.533813    9.085291   25.722685  -24.235521   13.252964\n",
      "   6.0840254  -3.10437    28.923233   -2.8557343  24.490135  -18.96864\n",
      "  15.456043  -17.343695   32.15458    28.488998   16.998886   18.546267\n",
      "  10.598609   -1.6490257   7.691105   -8.227098   31.035206   -4.6512375\n",
      "  -1.5121119 -13.121002  -11.425457    5.2241154   7.5756783 -18.531166\n",
      "  20.194082   30.116724   -2.3105798   5.341346    3.0120018 -18.310604\n",
      "   3.0654044  -7.036816    3.9029586   1.8123294  -6.877809   -3.8492022\n",
      "  -8.71936    -2.73981    -7.0088525  -3.2317467  -1.1199272   8.225032\n",
      "   7.4779935  10.848807   29.158884    1.0039392 -12.122187   -3.779436\n",
      "  34.200367   -6.3198752  19.919653  -27.167473   10.6451025]\n",
      "The accuracy of this model is64.40677966101694\n",
      "The rmse of this model is35.37611489743691\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  6.153315    31.028652    20.066393    -0.2080121   24.295258\n",
      "  -1.8840375    4.225718     3.2286053   -1.6234365   25.183775\n",
      "   0.12669054   8.390349     2.356162     1.1172535    6.872805\n",
      "  18.087862   -12.055885   -11.753396    30.229631    -0.08008385\n",
      "  -2.7716138  -10.811396    14.63728    -28.950838     2.8091493\n",
      "   7.261476    27.400671    28.078222    25.880669     8.456975\n",
      " -25.668076    -8.054128   -12.856517     5.47122     18.015652\n",
      "  19.86155     11.289002    28.543787    -6.971628    -3.6785111\n",
      "  -3.4843495  -12.221436    29.887632    -1.0910115  -19.768082\n",
      "  10.58082      7.3661213   -2.8533008   14.749623    -5.6894054\n",
      "  -0.03340989   3.7045577   -5.1860647   17.420551    11.4489565\n",
      "  15.673705    17.49995      9.875126  ]\n",
      "The accuracy of this model is60.3448275862069\n",
      "The rmse of this model is33.66707662519015\n",
      "Split: 10\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 32.424995   -12.482338    -0.275549    10.817186   -19.015036\n",
      "  11.4171295   11.646276     7.7419467   -2.1540468    8.715\n",
      "  19.417791    16.23802     26.049948    37.91431     16.25531\n",
      "   0.8997097  -19.098888    -7.3167686   28.041588   -12.3396\n",
      "  23.01927      2.9658027    0.16790631  14.41434     34.536003\n",
      "  13.688899     1.7978702   20.85016     13.136545    14.047314\n",
      " -11.116254   -16.583439     7.039982    18.416828    15.896705\n",
      "  -5.718016     1.8111368  -10.998019     5.256619    10.995225\n",
      "  20.654667   -37.571156    27.794767    -7.242402    28.16273\n",
      "  10.877447    19.743004    13.191571    -0.72323215  28.081776\n",
      "   5.1790786   -2.9939349  -14.936072    -9.333177    -8.423538\n",
      " -16.983622    22.590605     7.509898  ]\n",
      "The accuracy of this model is60.3448275862069\n",
      "The rmse of this model is39.54289073169179\n",
      "Best win percentage split = 72.88135593220339\n",
      "Best margin rmse = 30.85869264527205\n",
      "Training Testing Accuracy: 64.61% (4.77%)\n",
      "Training Testing Margins: 34.42% (2.61%)\n",
      "Thresh=0.0000006078, n=604, Accuracy: 69.03%\n",
      "Thresh=0.0000007280, n=603, Accuracy: 69.19%\n",
      "Thresh=0.0000009196, n=602, Accuracy: 70.21%\n",
      "Thresh=0.0000009311, n=601, Accuracy: 70.21%\n",
      "Thresh=0.0000010087, n=600, Accuracy: 68.52%\n",
      "Thresh=0.0000018373, n=599, Accuracy: 67.83%\n",
      "Thresh=0.0000020615, n=598, Accuracy: 68.18%\n",
      "Thresh=0.0000021764, n=597, Accuracy: 67.66%\n",
      "Thresh=0.0000026372, n=596, Accuracy: 68.17%\n",
      "Thresh=0.0000028618, n=595, Accuracy: 66.31%\n",
      "Thresh=0.0000029274, n=594, Accuracy: 67.84%\n",
      "Thresh=0.0000030031, n=593, Accuracy: 68.00%\n",
      "Thresh=0.0000032359, n=592, Accuracy: 68.86%\n",
      "Thresh=0.0000033441, n=591, Accuracy: 68.87%\n",
      "Thresh=0.0000035041, n=590, Accuracy: 69.87%\n",
      "Thresh=0.0000038408, n=589, Accuracy: 70.04%\n",
      "Thresh=0.0000041210, n=588, Accuracy: 69.02%\n",
      "Thresh=0.0000046364, n=587, Accuracy: 68.51%\n",
      "Thresh=0.0000048308, n=586, Accuracy: 69.54%\n",
      "Thresh=0.0000049276, n=585, Accuracy: 69.88%\n",
      "Thresh=0.0000057533, n=584, Accuracy: 70.40%\n",
      "Thresh=0.0000059889, n=583, Accuracy: 69.89%\n",
      "Thresh=0.0000067380, n=582, Accuracy: 69.55%\n",
      "Thresh=0.0000070312, n=581, Accuracy: 68.52%\n",
      "Thresh=0.0000072572, n=580, Accuracy: 69.02%\n",
      "Thresh=0.0000081807, n=579, Accuracy: 69.02%\n",
      "Thresh=0.0000082190, n=578, Accuracy: 68.85%\n",
      "Thresh=0.0000086060, n=577, Accuracy: 68.85%\n",
      "Thresh=0.0000087344, n=576, Accuracy: 68.17%\n",
      "Thresh=0.0000088330, n=575, Accuracy: 67.83%\n",
      "Thresh=0.0000090449, n=574, Accuracy: 68.34%\n",
      "Thresh=0.0000094873, n=573, Accuracy: 69.20%\n",
      "Thresh=0.0000105218, n=572, Accuracy: 69.37%\n",
      "Thresh=0.0000113821, n=571, Accuracy: 69.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0000122902, n=570, Accuracy: 70.20%\n",
      "Thresh=0.0000153038, n=569, Accuracy: 69.18%\n",
      "Thresh=0.0000159102, n=568, Accuracy: 68.84%\n",
      "Thresh=0.0000167301, n=567, Accuracy: 69.52%\n",
      "Thresh=0.0000175904, n=566, Accuracy: 69.18%\n",
      "Thresh=0.0000182456, n=565, Accuracy: 67.65%\n",
      "Thresh=0.0000191867, n=564, Accuracy: 67.81%\n",
      "Thresh=0.0000220648, n=563, Accuracy: 69.70%\n",
      "Thresh=0.0000225534, n=562, Accuracy: 70.21%\n",
      "Thresh=0.0000229844, n=561, Accuracy: 70.72%\n",
      "Thresh=0.0000244731, n=560, Accuracy: 69.35%\n",
      "Thresh=0.0000245497, n=559, Accuracy: 69.69%\n",
      "Thresh=0.0000263812, n=558, Accuracy: 69.86%\n",
      "Thresh=0.0000291094, n=557, Accuracy: 70.55%\n",
      "Thresh=0.0000322935, n=556, Accuracy: 70.56%\n",
      "Thresh=0.0000324238, n=555, Accuracy: 70.05%\n",
      "Thresh=0.0000340197, n=554, Accuracy: 70.22%\n",
      "Thresh=0.0000355103, n=553, Accuracy: 70.05%\n",
      "Thresh=0.0000355735, n=552, Accuracy: 69.87%\n",
      "Thresh=0.0000445674, n=551, Accuracy: 68.34%\n",
      "Thresh=0.0000452677, n=550, Accuracy: 69.36%\n",
      "Thresh=0.0000458740, n=549, Accuracy: 68.85%\n",
      "Thresh=0.0000459210, n=548, Accuracy: 66.28%\n",
      "Thresh=0.0000511187, n=547, Accuracy: 67.49%\n",
      "Thresh=0.0000519502, n=546, Accuracy: 66.79%\n",
      "Thresh=0.0000699017, n=545, Accuracy: 67.30%\n",
      "Thresh=0.0000796562, n=544, Accuracy: 68.15%\n",
      "Thresh=0.0000901953, n=543, Accuracy: 68.83%\n",
      "Thresh=0.0000926217, n=542, Accuracy: 69.87%\n",
      "Thresh=0.0000978213, n=541, Accuracy: 70.38%\n",
      "Thresh=0.0001067128, n=540, Accuracy: 69.02%\n",
      "Thresh=0.0001118742, n=539, Accuracy: 69.19%\n",
      "Thresh=0.0001119210, n=538, Accuracy: 68.85%\n",
      "Thresh=0.0001132094, n=537, Accuracy: 66.97%\n",
      "Thresh=0.0001137813, n=536, Accuracy: 65.79%\n",
      "Thresh=0.0001280323, n=535, Accuracy: 67.65%\n",
      "Thresh=0.0001337919, n=534, Accuracy: 68.50%\n",
      "Thresh=0.0001354275, n=533, Accuracy: 68.67%\n",
      "Thresh=0.0001487139, n=532, Accuracy: 68.33%\n",
      "Thresh=0.0001679797, n=531, Accuracy: 68.33%\n",
      "Thresh=0.0001732327, n=530, Accuracy: 69.20%\n",
      "Thresh=0.0001758251, n=529, Accuracy: 68.16%\n",
      "Thresh=0.0001774959, n=528, Accuracy: 68.16%\n",
      "Thresh=0.0001829107, n=527, Accuracy: 66.46%\n",
      "Thresh=0.0001855345, n=526, Accuracy: 66.97%\n",
      "Thresh=0.0001972286, n=525, Accuracy: 68.68%\n",
      "Thresh=0.0001975039, n=524, Accuracy: 69.37%\n",
      "Thresh=0.0001980333, n=523, Accuracy: 70.05%\n",
      "Thresh=0.0002008997, n=522, Accuracy: 68.52%\n",
      "Thresh=0.0002083420, n=521, Accuracy: 70.05%\n",
      "Thresh=0.0002083784, n=520, Accuracy: 68.68%\n",
      "Thresh=0.0002130744, n=519, Accuracy: 67.83%\n",
      "Thresh=0.0002133287, n=518, Accuracy: 69.54%\n",
      "Thresh=0.0002133758, n=517, Accuracy: 69.54%\n",
      "Thresh=0.0002176896, n=516, Accuracy: 69.70%\n",
      "Thresh=0.0002184923, n=515, Accuracy: 70.03%\n",
      "Thresh=0.0002197764, n=514, Accuracy: 69.52%\n",
      "Thresh=0.0002258805, n=513, Accuracy: 69.70%\n",
      "Thresh=0.0002368989, n=512, Accuracy: 70.37%\n",
      "Thresh=0.0002405262, n=511, Accuracy: 69.87%\n",
      "Thresh=0.0002441133, n=510, Accuracy: 70.38%\n",
      "Thresh=0.0002456922, n=509, Accuracy: 70.22%\n",
      "Thresh=0.0002457236, n=508, Accuracy: 68.68%\n",
      "Thresh=0.0002472174, n=507, Accuracy: 68.85%\n",
      "Thresh=0.0002498636, n=506, Accuracy: 68.85%\n",
      "Thresh=0.0002508689, n=505, Accuracy: 68.68%\n",
      "Thresh=0.0002514590, n=504, Accuracy: 69.19%\n",
      "Thresh=0.0002535080, n=503, Accuracy: 69.02%\n",
      "Thresh=0.0002594299, n=502, Accuracy: 69.19%\n",
      "Thresh=0.0002623027, n=501, Accuracy: 68.68%\n",
      "Thresh=0.0002699896, n=500, Accuracy: 68.50%\n",
      "Thresh=0.0002708700, n=499, Accuracy: 69.01%\n",
      "Thresh=0.0002838445, n=498, Accuracy: 69.35%\n",
      "Thresh=0.0002861366, n=497, Accuracy: 69.35%\n",
      "Thresh=0.0002874540, n=496, Accuracy: 68.84%\n",
      "Thresh=0.0002891745, n=495, Accuracy: 70.89%\n",
      "Thresh=0.0002922657, n=494, Accuracy: 69.17%\n",
      "Thresh=0.0002924936, n=493, Accuracy: 69.51%\n",
      "Thresh=0.0002993535, n=492, Accuracy: 69.85%\n",
      "Thresh=0.0003068921, n=491, Accuracy: 68.16%\n",
      "Thresh=0.0003088474, n=490, Accuracy: 69.19%\n",
      "Thresh=0.0003088520, n=489, Accuracy: 70.55%\n",
      "Thresh=0.0003165231, n=488, Accuracy: 69.53%\n",
      "Thresh=0.0003202114, n=487, Accuracy: 69.87%\n",
      "Thresh=0.0003218453, n=486, Accuracy: 68.85%\n",
      "Thresh=0.0003221670, n=485, Accuracy: 68.35%\n",
      "Thresh=0.0003265214, n=484, Accuracy: 68.68%\n",
      "Thresh=0.0003338034, n=483, Accuracy: 68.85%\n",
      "Thresh=0.0003372557, n=482, Accuracy: 69.70%\n",
      "Thresh=0.0003413588, n=481, Accuracy: 69.88%\n",
      "Thresh=0.0003448708, n=480, Accuracy: 70.55%\n",
      "Thresh=0.0003462973, n=479, Accuracy: 70.04%\n",
      "Thresh=0.0003471190, n=478, Accuracy: 70.39%\n",
      "Thresh=0.0003525074, n=477, Accuracy: 70.05%\n",
      "Thresh=0.0003539273, n=476, Accuracy: 70.73%\n",
      "Thresh=0.0003578276, n=475, Accuracy: 70.04%\n",
      "Thresh=0.0003608942, n=474, Accuracy: 69.69%\n",
      "Thresh=0.0003633460, n=473, Accuracy: 70.90%\n",
      "Thresh=0.0003682213, n=472, Accuracy: 70.73%\n",
      "Thresh=0.0003770853, n=471, Accuracy: 70.05%\n",
      "Thresh=0.0003797611, n=470, Accuracy: 69.20%\n",
      "Thresh=0.0003831449, n=469, Accuracy: 70.40%\n",
      "Thresh=0.0003881060, n=468, Accuracy: 69.55%\n",
      "Thresh=0.0003954609, n=467, Accuracy: 70.39%\n",
      "Thresh=0.0003964859, n=466, Accuracy: 70.91%\n",
      "Thresh=0.0004064450, n=465, Accuracy: 69.89%\n",
      "Thresh=0.0004128348, n=464, Accuracy: 68.87%\n",
      "Thresh=0.0004163813, n=463, Accuracy: 68.36%\n",
      "Thresh=0.0004171824, n=462, Accuracy: 69.04%\n",
      "Thresh=0.0004223237, n=461, Accuracy: 70.06%\n",
      "Thresh=0.0004254953, n=460, Accuracy: 69.38%\n",
      "Thresh=0.0004265731, n=459, Accuracy: 69.88%\n",
      "Thresh=0.0004282485, n=458, Accuracy: 71.40%\n",
      "Thresh=0.0004316244, n=457, Accuracy: 70.38%\n",
      "Thresh=0.0004345181, n=456, Accuracy: 70.72%\n",
      "Thresh=0.0004386523, n=455, Accuracy: 68.52%\n",
      "Thresh=0.0004417644, n=454, Accuracy: 68.86%\n",
      "Thresh=0.0004489523, n=453, Accuracy: 68.86%\n",
      "Thresh=0.0004489745, n=452, Accuracy: 69.37%\n",
      "Thresh=0.0004516622, n=451, Accuracy: 69.71%\n",
      "Thresh=0.0004538833, n=450, Accuracy: 70.04%\n",
      "Thresh=0.0004566639, n=449, Accuracy: 69.19%\n",
      "Thresh=0.0004595777, n=448, Accuracy: 70.72%\n",
      "Thresh=0.0004601581, n=447, Accuracy: 71.57%\n",
      "Thresh=0.0004637906, n=446, Accuracy: 71.57%\n",
      "Thresh=0.0004643470, n=445, Accuracy: 71.23%\n",
      "Thresh=0.0004661765, n=444, Accuracy: 70.37%\n",
      "Thresh=0.0004663227, n=443, Accuracy: 70.56%\n",
      "Thresh=0.0004665475, n=442, Accuracy: 68.18%\n",
      "Thresh=0.0004808276, n=441, Accuracy: 67.83%\n",
      "Thresh=0.0004810221, n=440, Accuracy: 68.17%\n",
      "Thresh=0.0004844054, n=439, Accuracy: 70.05%\n",
      "Thresh=0.0004899175, n=438, Accuracy: 70.89%\n",
      "Thresh=0.0004940215, n=437, Accuracy: 69.87%\n",
      "Thresh=0.0004979153, n=436, Accuracy: 69.36%\n",
      "Thresh=0.0005012376, n=435, Accuracy: 68.85%\n",
      "Thresh=0.0005024477, n=434, Accuracy: 69.21%\n",
      "Thresh=0.0005048501, n=433, Accuracy: 68.69%\n",
      "Thresh=0.0005050666, n=432, Accuracy: 71.24%\n",
      "Thresh=0.0005078937, n=431, Accuracy: 67.83%\n",
      "Thresh=0.0005081099, n=430, Accuracy: 68.85%\n",
      "Thresh=0.0005123182, n=429, Accuracy: 70.56%\n",
      "Thresh=0.0005164496, n=428, Accuracy: 69.35%\n",
      "Thresh=0.0005182700, n=427, Accuracy: 70.90%\n",
      "Thresh=0.0005193411, n=426, Accuracy: 69.03%\n",
      "Thresh=0.0005195136, n=425, Accuracy: 69.19%\n",
      "Thresh=0.0005253544, n=424, Accuracy: 69.02%\n",
      "Thresh=0.0005259121, n=423, Accuracy: 69.18%\n",
      "Thresh=0.0005309585, n=422, Accuracy: 69.52%\n",
      "Thresh=0.0005330930, n=421, Accuracy: 70.37%\n",
      "Thresh=0.0005341236, n=420, Accuracy: 70.21%\n",
      "Thresh=0.0005351976, n=419, Accuracy: 70.21%\n",
      "Thresh=0.0005468435, n=418, Accuracy: 70.55%\n",
      "Thresh=0.0005493586, n=417, Accuracy: 69.18%\n",
      "Thresh=0.0005559725, n=416, Accuracy: 68.16%\n",
      "Thresh=0.0005564556, n=415, Accuracy: 68.16%\n",
      "Thresh=0.0005638336, n=414, Accuracy: 68.16%\n",
      "Thresh=0.0005645239, n=413, Accuracy: 67.48%\n",
      "Thresh=0.0005684863, n=412, Accuracy: 68.51%\n",
      "Thresh=0.0005689536, n=411, Accuracy: 69.20%\n",
      "Thresh=0.0005732701, n=410, Accuracy: 69.87%\n",
      "Thresh=0.0005748027, n=409, Accuracy: 69.02%\n",
      "Thresh=0.0005748288, n=408, Accuracy: 68.68%\n",
      "Thresh=0.0005753201, n=407, Accuracy: 68.17%\n",
      "Thresh=0.0005756326, n=406, Accuracy: 68.85%\n",
      "Thresh=0.0005828271, n=405, Accuracy: 68.86%\n",
      "Thresh=0.0005842155, n=404, Accuracy: 68.86%\n",
      "Thresh=0.0005842411, n=403, Accuracy: 69.20%\n",
      "Thresh=0.0005885746, n=402, Accuracy: 68.86%\n",
      "Thresh=0.0005888457, n=401, Accuracy: 69.03%\n",
      "Thresh=0.0005963091, n=400, Accuracy: 69.88%\n",
      "Thresh=0.0005995087, n=399, Accuracy: 70.05%\n",
      "Thresh=0.0006013628, n=398, Accuracy: 70.38%\n",
      "Thresh=0.0006028669, n=397, Accuracy: 70.38%\n",
      "Thresh=0.0006063774, n=396, Accuracy: 68.68%\n",
      "Thresh=0.0006149152, n=395, Accuracy: 69.04%\n",
      "Thresh=0.0006164387, n=394, Accuracy: 69.70%\n",
      "Thresh=0.0006205975, n=393, Accuracy: 70.39%\n",
      "Thresh=0.0006217449, n=392, Accuracy: 71.40%\n",
      "Thresh=0.0006254248, n=391, Accuracy: 71.40%\n",
      "Thresh=0.0006283418, n=390, Accuracy: 70.72%\n",
      "Thresh=0.0006322493, n=389, Accuracy: 68.86%\n",
      "Thresh=0.0006327407, n=388, Accuracy: 69.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0006359518, n=387, Accuracy: 68.85%\n",
      "Thresh=0.0006423722, n=386, Accuracy: 71.90%\n",
      "Thresh=0.0006427477, n=385, Accuracy: 67.48%\n",
      "Thresh=0.0006442482, n=384, Accuracy: 69.88%\n",
      "Thresh=0.0006488445, n=383, Accuracy: 69.20%\n",
      "Thresh=0.0006512736, n=382, Accuracy: 69.70%\n",
      "Thresh=0.0006513127, n=381, Accuracy: 72.09%\n",
      "Thresh=0.0006538983, n=380, Accuracy: 71.06%\n",
      "Thresh=0.0006575318, n=379, Accuracy: 71.23%\n",
      "Thresh=0.0006578436, n=378, Accuracy: 69.35%\n",
      "Thresh=0.0006579703, n=377, Accuracy: 70.72%\n",
      "Thresh=0.0006586189, n=376, Accuracy: 69.70%\n",
      "Thresh=0.0006603203, n=375, Accuracy: 69.54%\n",
      "Thresh=0.0006614752, n=374, Accuracy: 70.21%\n",
      "Thresh=0.0006646108, n=373, Accuracy: 69.70%\n",
      "Thresh=0.0006656751, n=372, Accuracy: 70.55%\n",
      "Thresh=0.0006693286, n=371, Accuracy: 69.53%\n",
      "Thresh=0.0006896743, n=370, Accuracy: 70.39%\n",
      "Thresh=0.0006911983, n=369, Accuracy: 69.55%\n",
      "Thresh=0.0006930775, n=368, Accuracy: 69.54%\n",
      "Thresh=0.0006933886, n=367, Accuracy: 70.21%\n",
      "Thresh=0.0006989043, n=366, Accuracy: 70.55%\n",
      "Thresh=0.0007152594, n=365, Accuracy: 69.54%\n",
      "Thresh=0.0007154653, n=364, Accuracy: 69.54%\n",
      "Thresh=0.0007236653, n=363, Accuracy: 69.87%\n",
      "Thresh=0.0007328186, n=362, Accuracy: 67.48%\n",
      "Thresh=0.0007331867, n=361, Accuracy: 68.84%\n",
      "Thresh=0.0007349546, n=360, Accuracy: 68.33%\n",
      "Thresh=0.0007352534, n=359, Accuracy: 69.19%\n",
      "Thresh=0.0007387183, n=358, Accuracy: 69.87%\n",
      "Thresh=0.0007396958, n=357, Accuracy: 69.87%\n",
      "Thresh=0.0007444585, n=356, Accuracy: 70.39%\n",
      "Thresh=0.0007528541, n=355, Accuracy: 70.04%\n",
      "Thresh=0.0007554556, n=354, Accuracy: 68.67%\n",
      "Thresh=0.0007598319, n=353, Accuracy: 69.01%\n",
      "Thresh=0.0007656542, n=352, Accuracy: 69.01%\n",
      "Thresh=0.0007734824, n=351, Accuracy: 69.36%\n",
      "Thresh=0.0007769209, n=350, Accuracy: 70.72%\n",
      "Thresh=0.0007772383, n=349, Accuracy: 69.88%\n",
      "Thresh=0.0007775119, n=348, Accuracy: 69.37%\n",
      "Thresh=0.0007783369, n=347, Accuracy: 69.20%\n",
      "Thresh=0.0007794391, n=346, Accuracy: 68.69%\n",
      "Thresh=0.0007914684, n=345, Accuracy: 67.67%\n",
      "Thresh=0.0007941065, n=344, Accuracy: 69.03%\n",
      "Thresh=0.0008012849, n=343, Accuracy: 70.04%\n",
      "Thresh=0.0008033027, n=342, Accuracy: 68.85%\n",
      "Thresh=0.0008194453, n=341, Accuracy: 69.03%\n",
      "Thresh=0.0008222330, n=340, Accuracy: 69.02%\n",
      "Thresh=0.0008225242, n=339, Accuracy: 69.70%\n",
      "Thresh=0.0008310719, n=338, Accuracy: 68.68%\n",
      "Thresh=0.0008417885, n=337, Accuracy: 69.37%\n",
      "Thresh=0.0008565355, n=336, Accuracy: 67.67%\n",
      "Thresh=0.0008568447, n=335, Accuracy: 68.52%\n",
      "Thresh=0.0008622789, n=334, Accuracy: 68.69%\n",
      "Thresh=0.0008648565, n=333, Accuracy: 70.04%\n",
      "Thresh=0.0008654512, n=332, Accuracy: 69.19%\n",
      "Thresh=0.0008680067, n=331, Accuracy: 69.88%\n",
      "Thresh=0.0008729280, n=330, Accuracy: 69.37%\n",
      "Thresh=0.0008785376, n=329, Accuracy: 69.88%\n",
      "Thresh=0.0008835164, n=328, Accuracy: 69.04%\n",
      "Thresh=0.0008837738, n=327, Accuracy: 68.69%\n",
      "Thresh=0.0008863119, n=326, Accuracy: 68.18%\n",
      "Thresh=0.0008883635, n=325, Accuracy: 69.04%\n",
      "Thresh=0.0008883874, n=324, Accuracy: 69.37%\n",
      "Thresh=0.0008923122, n=323, Accuracy: 70.22%\n",
      "Thresh=0.0008972120, n=322, Accuracy: 68.34%\n",
      "Thresh=0.0009010315, n=321, Accuracy: 72.09%\n",
      "Thresh=0.0009056751, n=320, Accuracy: 70.40%\n",
      "Thresh=0.0009110374, n=319, Accuracy: 69.37%\n",
      "Thresh=0.0009168912, n=318, Accuracy: 69.04%\n",
      "Thresh=0.0009312117, n=317, Accuracy: 69.37%\n",
      "Thresh=0.0009333974, n=316, Accuracy: 70.57%\n",
      "Thresh=0.0009334433, n=315, Accuracy: 70.73%\n",
      "Thresh=0.0009380723, n=314, Accuracy: 69.70%\n",
      "Thresh=0.0009485341, n=313, Accuracy: 69.54%\n",
      "Thresh=0.0009486756, n=312, Accuracy: 70.06%\n",
      "Thresh=0.0009491969, n=311, Accuracy: 70.56%\n",
      "Thresh=0.0009493941, n=310, Accuracy: 69.88%\n",
      "Thresh=0.0009507270, n=309, Accuracy: 69.86%\n",
      "Thresh=0.0009587602, n=308, Accuracy: 71.93%\n",
      "Thresh=0.0009623529, n=307, Accuracy: 70.89%\n",
      "Thresh=0.0009660401, n=306, Accuracy: 70.72%\n",
      "Thresh=0.0009675841, n=305, Accuracy: 70.90%\n",
      "Thresh=0.0009729055, n=304, Accuracy: 70.90%\n",
      "Thresh=0.0009787038, n=303, Accuracy: 70.73%\n",
      "Thresh=0.0009838209, n=302, Accuracy: 68.69%\n",
      "Thresh=0.0009916943, n=301, Accuracy: 69.54%\n",
      "Thresh=0.0010003755, n=300, Accuracy: 70.71%\n",
      "Thresh=0.0010034004, n=299, Accuracy: 70.55%\n",
      "Thresh=0.0010070221, n=298, Accuracy: 72.08%\n",
      "Thresh=0.0010118338, n=297, Accuracy: 69.70%\n",
      "Thresh=0.0010165237, n=296, Accuracy: 68.69%\n",
      "Thresh=0.0010172708, n=295, Accuracy: 69.04%\n",
      "Thresh=0.0010236055, n=294, Accuracy: 68.86%\n",
      "Thresh=0.0010344284, n=293, Accuracy: 70.40%\n",
      "Thresh=0.0010358937, n=292, Accuracy: 69.53%\n",
      "Thresh=0.0010551192, n=291, Accuracy: 69.54%\n",
      "Thresh=0.0010592637, n=290, Accuracy: 69.03%\n",
      "Thresh=0.0010630455, n=289, Accuracy: 69.02%\n",
      "Thresh=0.0010668922, n=288, Accuracy: 69.70%\n",
      "Thresh=0.0010748879, n=287, Accuracy: 69.37%\n",
      "Thresh=0.0010842473, n=286, Accuracy: 69.54%\n",
      "Thresh=0.0010869415, n=285, Accuracy: 69.21%\n",
      "Thresh=0.0010910314, n=284, Accuracy: 68.53%\n",
      "Thresh=0.0010966702, n=283, Accuracy: 68.35%\n",
      "Thresh=0.0010993145, n=282, Accuracy: 68.01%\n",
      "Thresh=0.0011024742, n=281, Accuracy: 71.23%\n",
      "Thresh=0.0011100788, n=280, Accuracy: 69.53%\n",
      "Thresh=0.0011144794, n=279, Accuracy: 69.88%\n",
      "Thresh=0.0011165012, n=278, Accuracy: 69.21%\n",
      "Thresh=0.0011249998, n=277, Accuracy: 69.89%\n",
      "Thresh=0.0011278141, n=276, Accuracy: 70.57%\n",
      "Thresh=0.0011287275, n=275, Accuracy: 70.72%\n",
      "Thresh=0.0011332496, n=274, Accuracy: 70.39%\n",
      "Thresh=0.0011485801, n=273, Accuracy: 67.33%\n",
      "Thresh=0.0011486870, n=272, Accuracy: 69.89%\n",
      "Thresh=0.0011588845, n=271, Accuracy: 69.37%\n",
      "Thresh=0.0011776277, n=270, Accuracy: 68.35%\n",
      "Thresh=0.0011818520, n=269, Accuracy: 68.52%\n",
      "Thresh=0.0011851726, n=268, Accuracy: 69.05%\n",
      "Thresh=0.0011930218, n=267, Accuracy: 68.19%\n",
      "Thresh=0.0011938507, n=266, Accuracy: 70.23%\n",
      "Thresh=0.0011961496, n=265, Accuracy: 69.20%\n",
      "Thresh=0.0012061490, n=264, Accuracy: 69.20%\n",
      "Thresh=0.0012079225, n=263, Accuracy: 70.57%\n",
      "Thresh=0.0012112702, n=262, Accuracy: 67.84%\n",
      "Thresh=0.0012149746, n=261, Accuracy: 69.03%\n",
      "Thresh=0.0012206763, n=260, Accuracy: 68.36%\n",
      "Thresh=0.0012238806, n=259, Accuracy: 68.69%\n",
      "Thresh=0.0012245525, n=258, Accuracy: 71.41%\n",
      "Thresh=0.0012268291, n=257, Accuracy: 70.56%\n",
      "Thresh=0.0012287514, n=256, Accuracy: 70.57%\n",
      "Thresh=0.0012289960, n=255, Accuracy: 69.19%\n",
      "Thresh=0.0012316910, n=254, Accuracy: 68.35%\n",
      "Thresh=0.0012393300, n=253, Accuracy: 69.73%\n",
      "Thresh=0.0012406796, n=252, Accuracy: 68.70%\n",
      "Thresh=0.0012408227, n=251, Accuracy: 69.71%\n",
      "Thresh=0.0012427765, n=250, Accuracy: 69.72%\n",
      "Thresh=0.0012537559, n=249, Accuracy: 69.37%\n",
      "Thresh=0.0012613807, n=248, Accuracy: 70.57%\n",
      "Thresh=0.0012750303, n=247, Accuracy: 69.55%\n",
      "Thresh=0.0012855961, n=246, Accuracy: 68.87%\n",
      "Thresh=0.0012894394, n=245, Accuracy: 70.05%\n",
      "Thresh=0.0012928448, n=244, Accuracy: 69.72%\n",
      "Thresh=0.0012945791, n=243, Accuracy: 70.41%\n",
      "Thresh=0.0013027919, n=242, Accuracy: 69.89%\n",
      "Thresh=0.0013069813, n=241, Accuracy: 70.39%\n",
      "Thresh=0.0013098991, n=240, Accuracy: 71.07%\n",
      "Thresh=0.0013134074, n=239, Accuracy: 69.19%\n",
      "Thresh=0.0013450973, n=238, Accuracy: 69.72%\n",
      "Thresh=0.0013490181, n=237, Accuracy: 67.33%\n",
      "Thresh=0.0013540079, n=236, Accuracy: 70.41%\n",
      "Thresh=0.0013634539, n=235, Accuracy: 70.58%\n",
      "Thresh=0.0013728819, n=234, Accuracy: 70.75%\n",
      "Thresh=0.0013732682, n=233, Accuracy: 71.76%\n",
      "Thresh=0.0013846434, n=232, Accuracy: 71.59%\n",
      "Thresh=0.0013883474, n=231, Accuracy: 71.08%\n",
      "Thresh=0.0013924367, n=230, Accuracy: 71.25%\n",
      "Thresh=0.0014036710, n=229, Accuracy: 69.71%\n",
      "Thresh=0.0014106280, n=228, Accuracy: 69.21%\n",
      "Thresh=0.0014107053, n=227, Accuracy: 69.88%\n",
      "Thresh=0.0014140136, n=226, Accuracy: 70.21%\n",
      "Thresh=0.0014204428, n=225, Accuracy: 68.17%\n",
      "Thresh=0.0014448666, n=224, Accuracy: 68.51%\n",
      "Thresh=0.0014563270, n=223, Accuracy: 69.36%\n",
      "Thresh=0.0014724934, n=222, Accuracy: 68.86%\n",
      "Thresh=0.0014804153, n=221, Accuracy: 69.37%\n",
      "Thresh=0.0014818616, n=220, Accuracy: 68.69%\n",
      "Thresh=0.0014909748, n=219, Accuracy: 68.86%\n",
      "Thresh=0.0014986610, n=218, Accuracy: 69.37%\n",
      "Thresh=0.0015066592, n=217, Accuracy: 70.22%\n",
      "Thresh=0.0015110121, n=216, Accuracy: 70.56%\n",
      "Thresh=0.0015146026, n=215, Accuracy: 68.69%\n",
      "Thresh=0.0015167487, n=214, Accuracy: 68.19%\n",
      "Thresh=0.0015214154, n=213, Accuracy: 68.52%\n",
      "Thresh=0.0015751743, n=212, Accuracy: 68.69%\n",
      "Thresh=0.0015805637, n=211, Accuracy: 68.35%\n",
      "Thresh=0.0016022823, n=210, Accuracy: 68.53%\n",
      "Thresh=0.0016024773, n=209, Accuracy: 68.87%\n",
      "Thresh=0.0016169228, n=208, Accuracy: 69.20%\n",
      "Thresh=0.0016197539, n=207, Accuracy: 69.20%\n",
      "Thresh=0.0016236507, n=206, Accuracy: 67.68%\n",
      "Thresh=0.0016303211, n=205, Accuracy: 68.52%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0016444154, n=204, Accuracy: 67.49%\n",
      "Thresh=0.0016535152, n=203, Accuracy: 70.57%\n",
      "Thresh=0.0016722891, n=202, Accuracy: 69.56%\n",
      "Thresh=0.0016738160, n=201, Accuracy: 70.41%\n",
      "Thresh=0.0016742466, n=200, Accuracy: 69.72%\n",
      "Thresh=0.0016860629, n=199, Accuracy: 68.01%\n",
      "Thresh=0.0016918106, n=198, Accuracy: 69.70%\n",
      "Thresh=0.0016960497, n=197, Accuracy: 69.37%\n",
      "Thresh=0.0017097073, n=196, Accuracy: 68.68%\n",
      "Thresh=0.0017191495, n=195, Accuracy: 69.20%\n",
      "Thresh=0.0017258594, n=194, Accuracy: 69.21%\n",
      "Thresh=0.0017269442, n=193, Accuracy: 68.70%\n",
      "Thresh=0.0017413073, n=192, Accuracy: 68.53%\n",
      "Thresh=0.0017419036, n=191, Accuracy: 69.38%\n",
      "Thresh=0.0017480828, n=190, Accuracy: 69.56%\n",
      "Thresh=0.0017565220, n=189, Accuracy: 68.19%\n",
      "Thresh=0.0017661782, n=188, Accuracy: 68.52%\n",
      "Thresh=0.0017699153, n=187, Accuracy: 69.03%\n",
      "Thresh=0.0018145752, n=186, Accuracy: 69.54%\n",
      "Thresh=0.0018181264, n=185, Accuracy: 69.03%\n",
      "Thresh=0.0018189566, n=184, Accuracy: 68.51%\n",
      "Thresh=0.0018231960, n=183, Accuracy: 69.88%\n",
      "Thresh=0.0018420254, n=182, Accuracy: 67.66%\n",
      "Thresh=0.0018542643, n=181, Accuracy: 68.68%\n",
      "Thresh=0.0018818340, n=180, Accuracy: 69.87%\n",
      "Thresh=0.0019139617, n=179, Accuracy: 68.00%\n",
      "Thresh=0.0019196930, n=178, Accuracy: 68.86%\n",
      "Thresh=0.0019274493, n=177, Accuracy: 67.67%\n",
      "Thresh=0.0019481709, n=176, Accuracy: 68.01%\n",
      "Thresh=0.0019624096, n=175, Accuracy: 68.00%\n",
      "Thresh=0.0019629949, n=174, Accuracy: 69.20%\n",
      "Thresh=0.0019641584, n=173, Accuracy: 66.65%\n",
      "Thresh=0.0019831890, n=172, Accuracy: 69.37%\n",
      "Thresh=0.0019872931, n=171, Accuracy: 69.37%\n",
      "Thresh=0.0020165895, n=170, Accuracy: 69.20%\n",
      "Thresh=0.0020319137, n=169, Accuracy: 68.19%\n",
      "Thresh=0.0020553991, n=168, Accuracy: 70.05%\n",
      "Thresh=0.0020684313, n=167, Accuracy: 66.65%\n",
      "Thresh=0.0020775711, n=166, Accuracy: 67.17%\n",
      "Thresh=0.0020821413, n=165, Accuracy: 66.65%\n",
      "Thresh=0.0020983953, n=164, Accuracy: 68.52%\n",
      "Thresh=0.0021043171, n=163, Accuracy: 67.15%\n",
      "Thresh=0.0021045106, n=162, Accuracy: 68.53%\n",
      "Thresh=0.0021073967, n=161, Accuracy: 69.19%\n",
      "Thresh=0.0021299100, n=160, Accuracy: 68.52%\n",
      "Thresh=0.0021398759, n=159, Accuracy: 69.21%\n",
      "Thresh=0.0021446918, n=158, Accuracy: 68.36%\n",
      "Thresh=0.0021588097, n=157, Accuracy: 70.38%\n",
      "Thresh=0.0021635354, n=156, Accuracy: 68.52%\n",
      "Thresh=0.0021715423, n=155, Accuracy: 70.05%\n",
      "Thresh=0.0021719655, n=154, Accuracy: 68.51%\n",
      "Thresh=0.0021758305, n=153, Accuracy: 71.40%\n",
      "Thresh=0.0022222989, n=152, Accuracy: 70.04%\n",
      "Thresh=0.0022358939, n=151, Accuracy: 70.22%\n",
      "Thresh=0.0022397672, n=150, Accuracy: 70.05%\n",
      "Thresh=0.0022448634, n=149, Accuracy: 70.03%\n",
      "Thresh=0.0022558738, n=148, Accuracy: 71.91%\n",
      "Thresh=0.0022617928, n=147, Accuracy: 69.02%\n",
      "Thresh=0.0023077345, n=146, Accuracy: 71.41%\n",
      "Thresh=0.0023113475, n=145, Accuracy: 70.54%\n",
      "Thresh=0.0023139776, n=144, Accuracy: 70.72%\n",
      "Thresh=0.0023166873, n=143, Accuracy: 69.71%\n",
      "Thresh=0.0023235832, n=142, Accuracy: 70.04%\n",
      "Thresh=0.0023277563, n=141, Accuracy: 70.89%\n",
      "Thresh=0.0023420127, n=140, Accuracy: 71.57%\n",
      "Thresh=0.0023454358, n=139, Accuracy: 71.90%\n",
      "Thresh=0.0023460148, n=138, Accuracy: 70.71%\n",
      "Thresh=0.0023645868, n=137, Accuracy: 70.36%\n",
      "Thresh=0.0024212375, n=136, Accuracy: 70.21%\n",
      "Thresh=0.0024248036, n=135, Accuracy: 70.04%\n",
      "Thresh=0.0024269626, n=134, Accuracy: 69.03%\n",
      "Thresh=0.0024370325, n=133, Accuracy: 70.37%\n",
      "Thresh=0.0024405764, n=132, Accuracy: 71.22%\n",
      "Thresh=0.0024424745, n=131, Accuracy: 72.08%\n",
      "Thresh=0.0024576776, n=130, Accuracy: 68.34%\n",
      "Thresh=0.0024599235, n=129, Accuracy: 69.86%\n",
      "Thresh=0.0024661359, n=128, Accuracy: 71.22%\n",
      "Thresh=0.0024957333, n=127, Accuracy: 71.40%\n",
      "Thresh=0.0024978206, n=126, Accuracy: 69.69%\n",
      "Thresh=0.0025182469, n=125, Accuracy: 69.85%\n",
      "Thresh=0.0025378442, n=124, Accuracy: 69.00%\n",
      "Thresh=0.0025416107, n=123, Accuracy: 71.58%\n",
      "Thresh=0.0025649867, n=122, Accuracy: 71.41%\n",
      "Thresh=0.0025740918, n=121, Accuracy: 71.74%\n",
      "Thresh=0.0025842895, n=120, Accuracy: 69.03%\n",
      "Thresh=0.0026634207, n=119, Accuracy: 69.87%\n",
      "Thresh=0.0026656508, n=118, Accuracy: 69.02%\n",
      "Thresh=0.0026781936, n=117, Accuracy: 67.99%\n",
      "Thresh=0.0027258797, n=116, Accuracy: 69.17%\n",
      "Thresh=0.0027267381, n=115, Accuracy: 69.35%\n",
      "Thresh=0.0027677030, n=114, Accuracy: 70.05%\n",
      "Thresh=0.0027894971, n=113, Accuracy: 69.87%\n",
      "Thresh=0.0027949254, n=112, Accuracy: 69.19%\n",
      "Thresh=0.0028274863, n=111, Accuracy: 70.21%\n",
      "Thresh=0.0028661974, n=110, Accuracy: 67.64%\n",
      "Thresh=0.0028882576, n=109, Accuracy: 68.68%\n",
      "Thresh=0.0028951834, n=108, Accuracy: 68.68%\n",
      "Thresh=0.0029024465, n=107, Accuracy: 70.21%\n",
      "Thresh=0.0029137330, n=106, Accuracy: 66.46%\n",
      "Thresh=0.0029286363, n=105, Accuracy: 67.48%\n",
      "Thresh=0.0029357101, n=104, Accuracy: 68.15%\n",
      "Thresh=0.0029373358, n=103, Accuracy: 68.00%\n",
      "Thresh=0.0029428459, n=102, Accuracy: 67.48%\n",
      "Thresh=0.0029691625, n=101, Accuracy: 67.14%\n",
      "Thresh=0.0029731304, n=100, Accuracy: 67.64%\n",
      "Thresh=0.0029886756, n=99, Accuracy: 68.15%\n",
      "Thresh=0.0030230600, n=98, Accuracy: 69.03%\n",
      "Thresh=0.0030250712, n=97, Accuracy: 69.02%\n",
      "Thresh=0.0030277553, n=96, Accuracy: 68.16%\n",
      "Thresh=0.0030494707, n=95, Accuracy: 68.68%\n",
      "Thresh=0.0030624957, n=94, Accuracy: 68.85%\n",
      "Thresh=0.0030707456, n=93, Accuracy: 67.67%\n",
      "Thresh=0.0031024532, n=92, Accuracy: 68.01%\n",
      "Thresh=0.0031169818, n=91, Accuracy: 68.67%\n",
      "Thresh=0.0031173059, n=90, Accuracy: 67.49%\n",
      "Thresh=0.0031395005, n=89, Accuracy: 69.69%\n",
      "Thresh=0.0031434626, n=88, Accuracy: 69.54%\n",
      "Thresh=0.0031629130, n=87, Accuracy: 69.87%\n",
      "Thresh=0.0032106496, n=86, Accuracy: 70.21%\n",
      "Thresh=0.0032204038, n=85, Accuracy: 68.68%\n",
      "Thresh=0.0033216586, n=84, Accuracy: 70.21%\n",
      "Thresh=0.0033337686, n=83, Accuracy: 69.03%\n",
      "Thresh=0.0033643756, n=82, Accuracy: 69.37%\n",
      "Thresh=0.0033658314, n=81, Accuracy: 70.39%\n",
      "Thresh=0.0034272450, n=80, Accuracy: 69.35%\n",
      "Thresh=0.0034920403, n=79, Accuracy: 69.54%\n",
      "Thresh=0.0035964139, n=78, Accuracy: 70.73%\n",
      "Thresh=0.0036169593, n=77, Accuracy: 68.86%\n",
      "Thresh=0.0036456115, n=76, Accuracy: 70.04%\n",
      "Thresh=0.0036456992, n=75, Accuracy: 68.85%\n",
      "Thresh=0.0036826355, n=74, Accuracy: 67.83%\n",
      "Thresh=0.0036953257, n=73, Accuracy: 69.03%\n",
      "Thresh=0.0037442809, n=72, Accuracy: 70.73%\n",
      "Thresh=0.0037684804, n=71, Accuracy: 70.37%\n",
      "Thresh=0.0037688522, n=70, Accuracy: 70.53%\n",
      "Thresh=0.0037955826, n=69, Accuracy: 60.02%\n",
      "Thresh=0.0039446363, n=68, Accuracy: 59.69%\n",
      "Thresh=0.0040207086, n=67, Accuracy: 59.68%\n",
      "Thresh=0.0040823538, n=66, Accuracy: 59.84%\n",
      "Thresh=0.0040874188, n=65, Accuracy: 60.69%\n",
      "Thresh=0.0040903697, n=64, Accuracy: 60.87%\n",
      "Thresh=0.0041118655, n=63, Accuracy: 61.39%\n",
      "Thresh=0.0042101536, n=62, Accuracy: 61.87%\n",
      "Thresh=0.0042271004, n=61, Accuracy: 63.93%\n",
      "Thresh=0.0042280774, n=60, Accuracy: 63.07%\n",
      "Thresh=0.0042934506, n=59, Accuracy: 63.08%\n",
      "Thresh=0.0043070400, n=58, Accuracy: 61.90%\n",
      "Thresh=0.0044058571, n=57, Accuracy: 62.24%\n",
      "Thresh=0.0044381781, n=56, Accuracy: 58.33%\n",
      "Thresh=0.0045178686, n=55, Accuracy: 57.65%\n",
      "Thresh=0.0045214402, n=54, Accuracy: 59.70%\n",
      "Thresh=0.0045750840, n=53, Accuracy: 60.73%\n",
      "Thresh=0.0047211512, n=52, Accuracy: 59.18%\n",
      "Thresh=0.0047538555, n=51, Accuracy: 61.22%\n",
      "Thresh=0.0048586116, n=50, Accuracy: 59.86%\n",
      "Thresh=0.0048834970, n=49, Accuracy: 60.89%\n",
      "Thresh=0.0048861876, n=48, Accuracy: 59.34%\n",
      "Thresh=0.0048923939, n=47, Accuracy: 61.74%\n",
      "Thresh=0.0048953518, n=46, Accuracy: 59.02%\n",
      "Thresh=0.0049253046, n=45, Accuracy: 59.20%\n",
      "Thresh=0.0049722907, n=44, Accuracy: 58.00%\n",
      "Thresh=0.0050047631, n=43, Accuracy: 62.24%\n",
      "Thresh=0.0051263352, n=42, Accuracy: 58.16%\n",
      "Thresh=0.0051489952, n=41, Accuracy: 58.85%\n",
      "Thresh=0.0051798788, n=40, Accuracy: 57.15%\n",
      "Thresh=0.0052550719, n=39, Accuracy: 58.54%\n",
      "Thresh=0.0052820374, n=38, Accuracy: 61.06%\n",
      "Thresh=0.0053424616, n=37, Accuracy: 58.34%\n",
      "Thresh=0.0053706579, n=36, Accuracy: 58.51%\n",
      "Thresh=0.0054461048, n=35, Accuracy: 59.51%\n",
      "Thresh=0.0054920511, n=34, Accuracy: 59.70%\n",
      "Thresh=0.0055169496, n=33, Accuracy: 60.71%\n",
      "Thresh=0.0055378363, n=32, Accuracy: 56.29%\n",
      "Thresh=0.0055408897, n=31, Accuracy: 56.81%\n",
      "Thresh=0.0055831894, n=30, Accuracy: 59.00%\n",
      "Thresh=0.0056432411, n=29, Accuracy: 58.16%\n",
      "Thresh=0.0057117371, n=28, Accuracy: 59.18%\n",
      "Thresh=0.0057727550, n=27, Accuracy: 59.87%\n",
      "Thresh=0.0060049463, n=26, Accuracy: 58.49%\n",
      "Thresh=0.0060134865, n=25, Accuracy: 59.87%\n",
      "Thresh=0.0061806794, n=24, Accuracy: 58.35%\n",
      "Thresh=0.0063835359, n=23, Accuracy: 57.31%\n",
      "Thresh=0.0065215323, n=22, Accuracy: 58.67%\n",
      "Thresh=0.0065377620, n=21, Accuracy: 59.84%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.0066866032, n=20, Accuracy: 60.86%\n",
      "Thresh=0.0066897124, n=19, Accuracy: 59.87%\n",
      "Thresh=0.0067067989, n=18, Accuracy: 58.33%\n",
      "Thresh=0.0068323212, n=17, Accuracy: 59.18%\n",
      "Thresh=0.0068447581, n=16, Accuracy: 58.99%\n",
      "Thresh=0.0071106353, n=15, Accuracy: 58.66%\n",
      "Thresh=0.0074904514, n=14, Accuracy: 58.99%\n",
      "Thresh=0.0075233728, n=13, Accuracy: 56.29%\n",
      "Thresh=0.0075640241, n=12, Accuracy: 56.27%\n",
      "Thresh=0.0076065841, n=11, Accuracy: 55.76%\n",
      "Thresh=0.0083431993, n=10, Accuracy: 55.28%\n",
      "Thresh=0.0085240314, n=9, Accuracy: 50.16%\n",
      "Thresh=0.0089149270, n=8, Accuracy: 51.51%\n",
      "Thresh=0.0089462595, n=7, Accuracy: 52.51%\n",
      "Thresh=0.0089846030, n=6, Accuracy: 53.90%\n",
      "Thresh=0.0096393032, n=5, Accuracy: 55.95%\n",
      "Thresh=0.0097859204, n=4, Accuracy: 48.62%\n",
      "Thresh=0.0098994244, n=3, Accuracy: 52.71%\n",
      "Thresh=0.0099588390, n=2, Accuracy: 53.39%\n",
      "Thresh=0.0120902099, n=1, Accuracy: 49.83%\n",
      "max accuracy is: 72.09234365867914for threshold: 0.0006513127\n",
      "SelectFromModel(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                        colsample_bylevel=0.8668929135927905,\n",
      "                                        colsample_bynode=1,\n",
      "                                        colsample_bytree=0.997063840297573,\n",
      "                                        gamma=3.04900088285793e-05, gpu_id=-1,\n",
      "                                        importance_type='gain',\n",
      "                                        interaction_constraints='',\n",
      "                                        learning_rate=0.12302808880337321,\n",
      "                                        max_delta_step=16, max_depth=49,\n",
      "                                        min_child_weight=2, missing=nan,\n",
      "                                        mono...\n",
      "                                        n_estimators=143, n_jobs=0,\n",
      "                                        num_parallel_tree=1,\n",
      "                                        objective='binary:logistic',\n",
      "                                        random_state=27022013,\n",
      "                                        reg_alpha=4.8738467809287005e-08,\n",
      "                                        reg_lambda=0.00036924338123727884,\n",
      "                                        scale_pos_weight=0.49510084682452793,\n",
      "                                        subsample=0.9800482649057883,\n",
      "                                        tree_method='exact',\n",
      "                                        validate_parameters=1, verbosity=None),\n",
      "                max_features=None, norm_order=1, prefit=True,\n",
      "                threshold=0.0006513127)\n",
      "X_train shape: (470, 381)\n",
      "X_test shape: (118, 381)\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   22.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   19.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.725531914893617\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   12.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.725531914893617\n",
      "        0       1     2     3    4      5     6      7      8     9    ...  \\\n",
      "0    153.18  220.73  17.0   1.0  0.0   96.0 -15.0  238.0  118.0  12.0  ...   \n",
      "1    271.70  111.92  10.0   2.0  0.0   85.0 -25.0  209.0   81.0   9.0  ...   \n",
      "2    165.38  221.03  12.0   2.0  1.0   69.0   2.0  208.0   73.0   9.0  ...   \n",
      "3    243.72  222.30   8.0   3.0  0.0   47.0  30.0  229.0   98.0  10.0  ...   \n",
      "4    225.93  202.16  15.0   1.0  0.0  118.0 -62.0  237.0  145.0   8.0  ...   \n",
      "..      ...     ...   ...   ...  ...    ...   ...    ...    ...   ...  ...   \n",
      "583  282.15  288.68   1.0  18.0  0.0   57.0   1.0  223.0   98.0   8.0  ...   \n",
      "584  251.19  230.00   8.0  12.0  0.0   74.0  -6.0  224.0  106.0   9.0  ...   \n",
      "585  285.06  226.11   2.0  17.0  0.0   90.0  -4.0  205.0   89.0  13.0  ...   \n",
      "586  999.00  201.61  15.0   9.0  0.0  132.0 -35.0  227.0   87.0  14.0  ...   \n",
      "587  999.00  264.81   7.0  13.0  0.0   58.0  -1.0  223.0   89.0   8.0  ...   \n",
      "\n",
      "      371   372   373  374    375   376   377  378  379  380  \n",
      "0    1.87   5.0   9.0  3.0  136.0  72.3   9.0  0.0  1.0  0.0  \n",
      "1    2.18  13.0   7.0  6.0  162.0  67.6   8.0  0.0  0.0  0.0  \n",
      "2    2.18   9.0   7.0  5.0  150.0  71.3  19.0  0.0  0.0  0.0  \n",
      "3    1.46   4.0   2.0  5.0  135.0  76.2   8.0  0.0  0.0  1.0  \n",
      "4    1.43  10.0   8.0  3.0  162.0  71.5  17.0  0.0  0.0  0.0  \n",
      "..    ...   ...   ...  ...    ...   ...   ...  ...  ...  ...  \n",
      "583  1.57   3.0  10.0  4.0   96.0  77.1   6.0  0.0  0.0  0.0  \n",
      "584  1.20   9.0   8.0  1.0  138.0  75.7  13.0  0.0  1.0  0.0  \n",
      "585  1.21  10.0   6.0  7.0  149.0  70.1  11.0  0.0  0.0  0.0  \n",
      "586  1.63   4.0   8.0  5.0  173.0  62.5   6.0  0.0  0.0  0.0  \n",
      "587  1.15   6.0   9.0  8.0  134.0  74.6  12.0  0.0  1.0  0.0  \n",
      "\n",
      "[588 rows x 381 columns]\n",
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -0.21987736  20.250814   -19.073978    -0.919021    13.837525\n",
      "  35.68171     18.04242     -3.1485515   -7.2493677    7.021889\n",
      "  -5.7917767   14.896067    -2.5937061   14.604222    28.657246\n",
      " -12.939452    16.445583    -5.802227    25.397085    18.223167\n",
      "  20.556377   -14.210878    -1.8626618   -6.0442977   16.029823\n",
      " -29.039207    -9.354258     8.597378   -25.83505    -20.778858\n",
      "  12.729288    14.169562    20.19467      6.026655   -28.135572\n",
      "  11.253288    35.556095    40.3074      32.307922   -27.703648\n",
      " -17.398647   -19.013338    26.929255   -21.040787    15.61627\n",
      "  -8.804467    -2.565005    -3.0488746   14.23246      5.4308558\n",
      "   9.514693    19.083302    42.527164    16.133121   -16.81689\n",
      "  -5.041564    20.569706     2.2595706   41.31718   ]\n",
      "The accuracy of this model is55.932203389830505\n",
      "The rmse of this model is34.13846453826125\n",
      "found new best classify\n",
      "found best new margin\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  5.725937     8.25313     -7.10013      8.671521    24.459404\n",
      " -10.17421    -10.106241    14.312805    -4.474455    -8.181011\n",
      "  -9.915964    12.882906     5.896421   -14.858349    13.365591\n",
      "  -1.4823058   14.649452   -23.112425    -1.2580119    2.5311294\n",
      " -17.070377     3.2119925    8.223803    26.815475    22.956648\n",
      "  21.431332     9.51892     20.72569      3.0928297   25.75275\n",
      " -24.656605     8.251276    37.944317    47.678596   -10.87561\n",
      "   2.5429113    4.6013703   14.986763    19.929684     8.521501\n",
      "  33.582226    20.599062     6.3694186   29.474083    10.95358\n",
      "   2.0554004   13.963576    12.097475    16.398407     0.8684002\n",
      " -10.134967    -0.25273484  23.531065     1.5383445   21.82167\n",
      "  15.639459    -5.5379543   -4.7314787    9.333968  ]\n",
      "The accuracy of this model is67.79661016949152\n",
      "The rmse of this model is34.45531534805608\n",
      "found new best classify\n",
      "Split: 3\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -9.321343   30.270184    1.0539532   8.259073   10.152626    4.03022\n",
      "  28.494009   -3.4252892  -7.8551655  -9.331161   -9.699861   26.891146\n",
      "  13.11736    25.095352  -12.8031435 -27.827158   -7.389784   -5.2954307\n",
      " -10.109796  -13.776615  -25.785208   17.632385   31.541803    8.773183\n",
      " -11.530463   28.12512   -22.193926  -10.249711   37.703335   12.303743\n",
      "   7.1501884  19.31222    -5.3911705  13.386565   -4.1513205  -6.7627335\n",
      "   9.180627   36.154415    1.0509033 -21.00766    13.02405    10.922565\n",
      "  15.779665    2.2348008   3.9211915   4.0769587   2.7114089  13.191089\n",
      "   0.9950682  16.831108   25.424585    8.6317    -39.029823    2.277463\n",
      "  18.465534  -10.555899   -3.5416026  13.19945     2.770177 ]\n",
      "The accuracy of this model is67.79661016949152\n",
      "The rmse of this model is30.85869264527205\n",
      "found best new margin\n",
      "Split: 4\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  2.8846517   10.756632    17.99359     28.387741    15.894896\n",
      "  -9.32296     -5.107439   -17.969978     1.895218     3.773797\n",
      "  32.977654    -5.5125346   27.755266    -6.1250367  -20.880125\n",
      "  20.796103    21.14366     17.257313    15.449631    28.94651\n",
      "  13.333422     0.2956965    0.59703434 -37.090626     6.7640452\n",
      "   2.2937732    8.187986    18.268597    -0.99448025   1.2282732\n",
      "  10.274497     7.7566066  -11.456727     1.340229     0.95797944\n",
      "  21.273487     3.1075082   36.482452   -21.111416     9.583497\n",
      "  10.847342   -13.77639     -2.4415214   -0.47412294  -4.3920236\n",
      " -22.668108    19.189234    18.923464   -46.771816     6.1500635\n",
      "  26.545374    16.200344   -43.780434   -12.533001   -18.287632\n",
      "  -0.7046343   15.759409    21.70708     27.302013  ]\n",
      "The accuracy of this model is79.66101694915254\n",
      "The rmse of this model is38.49804669559259\n",
      "found new best classify\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ -6.812851  -18.234928   -5.6840963  24.528297  -14.791647   16.73218\n",
      "  -3.2584865  12.921974    2.2197905  16.642006   14.855667   26.600048\n",
      "   6.8495355   8.8055725  -3.402348   -4.9078546  -3.9328375   4.9245424\n",
      " -12.514183   10.985659    4.8294597   6.9788485   2.9119995  34.681744\n",
      "  24.947153    2.2624414  29.001194   12.444425   11.3918705 -20.723587\n",
      "  14.434365   22.687428   12.112321   -4.6480813  21.239384   10.390415\n",
      "  17.162436    1.3033428  -5.061241    6.775756  -10.360685   24.685566\n",
      " -25.724192   46.80408    20.416664   24.498714   11.698507   15.607437\n",
      "  25.979017    0.7957052   6.730408  -14.767423   16.90489   -15.951498\n",
      "  25.897835   19.270462   23.965843   -1.3393973  -6.683384 ]\n",
      "The accuracy of this model is71.1864406779661\n",
      "The rmse of this model is31.886989815368498\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  4.2422295   6.045571   18.86452    -4.8309245   6.349068   -8.384319\n",
      "   4.7208085  10.882137   -2.5310035  33.19598     4.6666927  -9.684718\n",
      "  14.017967   31.972218  -14.743705   -6.972444   12.0919695 -29.371595\n",
      "  -5.307842    7.6006794  12.620378  -15.642353   51.857277   32.98972\n",
      "  -9.273917    7.9552927 -12.739905  -30.014236   41.638626    3.38134\n",
      "  12.89049     7.397335    8.065159   -8.399765   38.491806   -1.8749027\n",
      "  14.416346   12.660065    9.126107  -33.614647    8.536108   35.57548\n",
      "   7.5267386  21.186197   23.042887    7.468418   18.939808   -4.398913\n",
      "  18.077637   47.971962   46.093334   21.832819    2.4105282   3.5113173\n",
      "  -7.748292   26.328548   11.457633  -19.348007    9.856533 ]\n",
      "The accuracy of this model is72.88135593220339\n",
      "The rmse of this model is33.14661437946208\n",
      "Split: 7\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[-16.146229    12.807809   -19.054592     0.64004385 -12.04411\n",
      "  18.795042    18.440931    12.47375    -14.76242     12.068268\n",
      "  -4.058438     0.7115315   -6.4008517    9.814343     2.6077497\n",
      "  -6.7274847  -21.18953      6.989531    -6.792478   -14.523888\n",
      "  18.249283     8.532947    22.75842     16.365217    -6.4673247\n",
      "   2.519791   -24.275639    21.69656     22.354946   -24.059046\n",
      "  10.7681675  -24.375067    17.419975    31.952734    -1.6290145\n",
      " -15.238448   -17.527027   -11.211885    19.646437     2.3205948\n",
      "  21.105461     9.989442    36.73228     -9.064586   -19.889458\n",
      " -14.13822    -17.514145    30.446209    18.630396    12.572779\n",
      "  17.54524      4.9908714   -5.2340384   21.197468    19.271349\n",
      " -23.347963    19.251852     9.849607    24.898478  ]\n",
      "The accuracy of this model is74.57627118644068\n",
      "The rmse of this model is32.67855647927645\n",
      "Split: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 16.632965  -16.533813    9.085291   25.722685  -24.235521   13.252964\n",
      "   6.0840254  -3.10437    28.923233   -2.8557343  24.490135  -18.96864\n",
      "  15.456043  -17.343695   32.15458    28.488998   16.998886   18.546267\n",
      "  10.598609   -1.6490257   7.691105   -8.227098   31.035206   -4.6512375\n",
      "  -1.5121119 -13.121002  -11.425457    5.2241154   7.5756783 -18.531166\n",
      "  20.194082   30.116724   -2.3105798   5.341346    3.0120018 -18.310604\n",
      "   3.0654044  -7.036816    3.9029586   1.8123294  -6.877809   -3.8492022\n",
      "  -8.71936    -2.73981    -7.0088525  -3.2317467  -1.1199272   8.225032\n",
      "   7.4779935  10.848807   29.158884    1.0039392 -12.122187   -3.779436\n",
      "  34.200367   -6.3198752  19.919653  -27.167473   10.6451025]\n",
      "The accuracy of this model is67.79661016949152\n",
      "The rmse of this model is35.37611489743691\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[  6.153315    31.028652    20.066393    -0.2080121   24.295258\n",
      "  -1.8840375    4.225718     3.2286053   -1.6234365   25.183775\n",
      "   0.12669054   8.390349     2.356162     1.1172535    6.872805\n",
      "  18.087862   -12.055885   -11.753396    30.229631    -0.08008385\n",
      "  -2.7716138  -10.811396    14.63728    -28.950838     2.8091493\n",
      "   7.261476    27.400671    28.078222    25.880669     8.456975\n",
      " -25.668076    -8.054128   -12.856517     5.47122     18.015652\n",
      "  19.86155     11.289002    28.543787    -6.971628    -3.6785111\n",
      "  -3.4843495  -12.221436    29.887632    -1.0910115  -19.768082\n",
      "  10.58082      7.3661213   -2.8533008   14.749623    -5.6894054\n",
      "  -0.03340989   3.7045577   -5.1860647   17.420551    11.4489565\n",
      "  15.673705    17.49995      9.875126  ]\n",
      "The accuracy of this model is72.41379310344827\n",
      "The rmse of this model is33.66707662519015\n",
      "Split: 10\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "[ 32.424995   -12.482338    -0.275549    10.817186   -19.015036\n",
      "  11.4171295   11.646276     7.7419467   -2.1540468    8.715\n",
      "  19.417791    16.23802     26.049948    37.91431     16.25531\n",
      "   0.8997097  -19.098888    -7.3167686   28.041588   -12.3396\n",
      "  23.01927      2.9658027    0.16790631  14.41434     34.536003\n",
      "  13.688899     1.7978702   20.85016     13.136545    14.047314\n",
      " -11.116254   -16.583439     7.039982    18.416828    15.896705\n",
      "  -5.718016     1.8111368  -10.998019     5.256619    10.995225\n",
      "  20.654667   -37.571156    27.794767    -7.242402    28.16273\n",
      "  10.877447    19.743004    13.191571    -0.72323215  28.081776\n",
      "   5.1790786   -2.9939349  -14.936072    -9.333177    -8.423538\n",
      " -16.983622    22.590605     7.509898  ]\n",
      "The accuracy of this model is58.620689655172406\n",
      "The rmse of this model is39.54289073169179\n",
      "Best win percentage split = 79.66101694915254\n",
      "Best margin rmse = 30.85869264527205\n",
      "Training Testing Accuracy: 68.87% (6.77%)\n",
      "Training Testing Margins: 34.42% (2.61%)\n"
     ]
    }
   ],
   "source": [
    "#as one big script to go through n_games\n",
    "n_games = [2,3,10]\n",
    "#n_games = [4,5,6]\n",
    "for n in n_games:\n",
    "    run_all_models(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best of 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_test(n_games,ohe):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "    #manual update cbf automating this part as this is just a rough check to see how well best of 3 does\n",
    "    x_data = x_data.tail(1988)\n",
    "    \n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, ohe, 1, cv)\n",
    "    \n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_models(n):\n",
    "    #clf = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    clf = pickle.load(open(\"Models/best_xgb_clas_FS_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    ohe = pickle.load(open(\"Models/ohe_\"+str(n)+\"_no_2021_games.dat\", \"rb\"))\n",
    "    fs_filename = 'Models/fs_criteria_'+str(n)+'.dat'\n",
    "    selector = pickle.load(open(fs_filename, \"rb\"))\n",
    "    return clf, ohe, selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no202010_games.csv')\n",
    "\n",
    "model_2, ohe, selector = load_test_models(2)\n",
    "x_2 = prep_data_test(2,ohe)\n",
    "#x_2 = selector.transform(x_2)\n",
    "#x_2 = pd.DataFrame(x_2)\n",
    "\n",
    "model_3, ohe, selector = load_test_models(3)\n",
    "x_3 = prep_data_test(3, ohe)\n",
    "#x_3 = selector.transform(x_3)\n",
    "#x_3 = pd.DataFrame(x_3)\n",
    "\n",
    "#model_4, ohe, selector = load_test_models(4)\n",
    "#x_4 = prep_data_test(4, ohe)\n",
    "#x_4 = selector.transform(x_4)\n",
    "#x_4 = pd.DataFrame(x_4)\n",
    "\n",
    "#model_5, ohe, selector = load_test_models(5)\n",
    "#x_5 = prep_data_test(5, ohe)\n",
    "#x_5 = selector.transform(x_5)\n",
    "#x_5 = pd.DataFrame(x_5)\n",
    "\n",
    "#model_6, ohe, selector = load_test_models(6)\n",
    "#x_6 = prep_data_test(6, ohe)\n",
    "#x_6 = selector.transform(x_6)\n",
    "#x_6 = pd.DataFrame(x_6)\n",
    "\n",
    "model_10, ohe, selector = load_test_models(10)\n",
    "x_10 = prep_data_test(10, ohe)\n",
    "#x_10 = selector.transform(x_10)\n",
    "#x_10 = pd.DataFrame(x_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          1.0       1.0       1.0  1.000000\n",
      "2          0.0       1.0       1.0  0.666667\n",
      "3          1.0       0.0       1.0  0.666667\n",
      "4          1.0       1.0       1.0  1.000000\n",
      "..         ...       ...       ...       ...\n",
      "194        0.0       0.0       0.0  0.000000\n",
      "195        1.0       1.0       1.0  1.000000\n",
      "196        1.0       0.0       0.0  0.333333\n",
      "197        0.0       0.0       0.0  0.000000\n",
      "198        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0]\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "The accuracy of this model is64.321608040201\n",
      "Split: 2\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       0.0       0.0  0.000000\n",
      "1          0.0       0.0       1.0  0.333333\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       1.0       1.0  0.666667\n",
      "4          1.0       1.0       0.0  0.666667\n",
      "..         ...       ...       ...       ...\n",
      "194        0.0       0.0       0.0  0.000000\n",
      "195        0.0       0.0       0.0  0.000000\n",
      "196        1.0       0.0       0.0  0.333333\n",
      "197        1.0       0.0       0.0  0.333333\n",
      "198        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0]\n",
      "[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "The accuracy of this model is69.34673366834171\n",
      "Split: 3\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          0.0       1.0       0.0  0.333333\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          1.0       1.0       1.0  1.000000\n",
      "..         ...       ...       ...       ...\n",
      "194        1.0       0.0       1.0  0.666667\n",
      "195        1.0       1.0       1.0  1.000000\n",
      "196        0.0       0.0       0.0  0.000000\n",
      "197        0.0       0.0       0.0  0.000000\n",
      "198        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0]\n",
      "[1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "The accuracy of this model is70.35175879396985\n",
      "Split: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          1.0       1.0       1.0  1.000000\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "194        1.0       1.0       1.0  1.000000\n",
      "195        0.0       0.0       0.0  0.000000\n",
      "196        0.0       0.0       0.0  0.000000\n",
      "197        1.0       1.0       0.0  0.666667\n",
      "198        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "The accuracy of this model is68.84422110552764\n",
      "Split: 5\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          0.0       1.0       0.0  0.333333\n",
      "2          1.0       0.0       1.0  0.666667\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "194        1.0       0.0       0.0  0.333333\n",
      "195        0.0       0.0       0.0  0.000000\n",
      "196        0.0       0.0       0.0  0.000000\n",
      "197        1.0       1.0       1.0  1.000000\n",
      "198        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0]\n",
      "[1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "The accuracy of this model is66.83417085427136\n",
      "Split: 6\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       0.0       0.0  0.000000\n",
      "1          0.0       1.0       1.0  0.666667\n",
      "2          1.0       1.0       1.0  1.000000\n",
      "3          1.0       1.0       1.0  1.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "194        0.0       0.0       0.0  0.000000\n",
      "195        0.0       1.0       1.0  0.666667\n",
      "196        0.0       0.0       1.0  0.333333\n",
      "197        1.0       0.0       0.0  0.333333\n",
      "198        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0]\n",
      "[0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "The accuracy of this model is72.8643216080402\n",
      "Split: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       0.0       0.0  0.000000\n",
      "1          1.0       1.0       0.0  0.666667\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "194        0.0       0.0       0.0  0.000000\n",
      "195        1.0       1.0       1.0  1.000000\n",
      "196        0.0       0.0       0.0  0.000000\n",
      "197        0.0       0.0       0.0  0.000000\n",
      "198        0.0       0.0       0.0  0.000000\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "The accuracy of this model is62.8140703517588\n",
      "Split: 8\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       0.0       0.0  0.000000\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          1.0       1.0       1.0  1.000000\n",
      "4          0.0       0.0       0.0  0.000000\n",
      "..         ...       ...       ...       ...\n",
      "194        0.0       0.0       0.0  0.000000\n",
      "195        1.0       1.0       1.0  1.000000\n",
      "196        0.0       0.0       0.0  0.000000\n",
      "197        1.0       1.0       1.0  1.000000\n",
      "198        1.0       0.0       0.0  0.333333\n",
      "\n",
      "[199 rows x 4 columns]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333]\n",
      "[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "The accuracy of this model is66.33165829145729\n",
      "Split: 9\n",
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          0.0       1.0       0.0  0.333333\n",
      "1          1.0       1.0       1.0  1.000000\n",
      "2          1.0       1.0       1.0  1.000000\n",
      "3          0.0       1.0       1.0  0.666667\n",
      "4          1.0       1.0       1.0  1.000000\n",
      "..         ...       ...       ...       ...\n",
      "193        1.0       0.0       0.0  0.333333\n",
      "194        1.0       0.0       0.0  0.333333\n",
      "195        0.0       0.0       0.0  0.000000\n",
      "196        1.0       0.0       1.0  0.666667\n",
      "197        1.0       0.0       1.0  0.666667\n",
      "\n",
      "[198 rows x 4 columns]\n",
      "[0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666]\n",
      "[0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "The accuracy of this model is63.63636363636363\n",
      "Split: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables for auroc curve done. Processing fold accuracy + checking best model\n",
      "     y_pred_10  y_pred_2  y_pred_3   average\n",
      "0          1.0       1.0       1.0  1.000000\n",
      "1          0.0       0.0       0.0  0.000000\n",
      "2          0.0       0.0       0.0  0.000000\n",
      "3          0.0       0.0       0.0  0.000000\n",
      "4          0.0       0.0       1.0  0.333333\n",
      "..         ...       ...       ...       ...\n",
      "193        0.0       0.0       0.0  0.000000\n",
      "194        0.0       0.0       0.0  0.000000\n",
      "195        1.0       0.0       1.0  0.666667\n",
      "196        1.0       0.0       0.0  0.333333\n",
      "197        1.0       0.0       1.0  0.666667\n",
      "\n",
      "[198 rows x 4 columns]\n",
      "[1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666]\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]\n",
      "The accuracy of this model is70.70707070707071\n",
      "Best win percentage split = 0\n",
      "Training Testing Accuracy: 67.61% (3.18%)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "count = 0\n",
    "high_w = 0\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "y = y_label\n",
    "for train,test in cv.split(x_2,y):\n",
    "    count = count + 1\n",
    "    print(\"Split: \" + str(count))\n",
    "    prediction = model_2.fit(x_2.loc[train],y.loc[train]).predict_proba(x_2.loc[test])\n",
    "    prediction = model_3.fit(x_3.loc[train],y.loc[train]).predict_proba(x_3.loc[test])\n",
    "    #prediction = model_4.fit(x_4.loc[train],y.loc[train]).predict_proba(x_4.loc[test])\n",
    "    #prediction = model_5.fit(x_5.loc[train],y.loc[train]).predict_proba(x_5.loc[test])\n",
    "    #prediction = model_6.fit(x_6.loc[train],y.loc[train]).predict_proba(x_6.loc[test])\n",
    "    prediction = model_10.fit(x_10.loc[train],y.loc[train]).predict_proba(x_10.loc[test])\n",
    "    print(\"variables for auroc curve done. Processing fold accuracy + checking best model\")\n",
    "    d = {'y_pred_10':model_10.predict(x_10.loc[test]),\n",
    "         'y_pred_2':model_2.predict(x_2.loc[test]), 'y_pred_3':model_3.predict(x_3.loc[test])}\n",
    "    pred_df = pd.DataFrame(data=d)\n",
    "    summary_ave_data = pred_df.copy()\n",
    "    summary_ave_data['average'] = summary_ave_data.mean(numeric_only=True, axis=1)\n",
    "    print(summary_ave_data)\n",
    "    y_pred = summary_ave_data[\"average\"].tolist()\n",
    "    print(y_pred)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    print(predictions)\n",
    "    #sees how accurate the model was when testing the test set\n",
    "    accuracy = accuracy_score(y.loc[test], predictions)\n",
    "    pcent = accuracy * 100.0\n",
    "    print(\"The accuracy of this model is\" + str(pcent))\n",
    "    results.append(pcent)\n",
    "print(\"Best win percentage split = \" +str(high_w))\n",
    "print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced Multicollinearity Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "n_games = 2\n",
    "model = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "thresholds = sort(model.feature_importances_)\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find multicollinearaity and then reduce it\n",
    "\n",
    "#def feature_select(x_data, clf):\n",
    "n_games = 2\n",
    "h = get_headers(n_games)\n",
    "h = clean_headers(h)\n",
    "cv = generate_categorical_headers(h)\n",
    "\n",
    "#to get names of teams from index\n",
    "g = gad()\n",
    "teams = g.createTeamDict()\n",
    "\n",
    "#load Data\n",
    "x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "#make empty OHE object\n",
    "na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#one hot encode data with new one hot encoder, saves ohe for later use\n",
    "x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "#filename = 'Models/ohe_'+str(n_games)+'_no_2021_games_fs.dat'\n",
    "#pickle.dump(ohe, open(filename, \"wb\"))\n",
    "#reset headers\n",
    "feature_names = x_data.columns\n",
    "\n",
    "#loads the ylabel matrix,\n",
    "y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "#loads margin as the y_label\n",
    "margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "print(margin_label.shape)\n",
    "print(y_label.shape)\n",
    "print(x_data.shape)\n",
    "\n",
    "#regex solution which is apparently necessary??\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "model = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "margin_model = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"rb\"))\n",
    "\n",
    "# margin_label = abs(margin_label)\n",
    "print(margin_label)\n",
    "best_xgb_clas, best_xgb_reg = eval_xgb_games_margins(x_data, y_label, model, x_data, margin_label, margin_model)\n",
    "\n",
    "best_threshold = threshold_search(x_data, y_label, best_xgb_clas)\n",
    "selection = SelectFromModel(best_xgb_clas, threshold=best_threshold, prefit=True)\n",
    "print(selection)\n",
    "selection_x_data = selection.transform(x_data)\n",
    "selection_x_data = pd.DataFrame(selection_x_data)\n",
    "\n",
    "fs_filename = 'Models/fs_criteria_'+str(n_games)+'.dat'\n",
    "pickle.dump(selection, open(fs_filename, \"wb\"))\n",
    "\n",
    "fs_model = param_search(selection_x_data, y_label, 0)\n",
    "\n",
    "best_xgb_fs_clas, best_xgb_reg = eval_xgb_games_margins(selection_x_data, y_label, fs_model, x_data, margin_label, margin_model)\n",
    "\n",
    "pickle.dump(best_xgb_fs_clas, open(\"Models/best_xgb_clas_FS_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))\n",
    "    #return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_threshold_cv(x, y, m):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = 27022013)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "    mean_acc = (np.mean(results))\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(x_data, y_label, best_xgb_clas):\n",
    "    thresholds = sort(best_xgb_clas.feature_importances_)\n",
    "    threshold_array = []\n",
    "    threshold_accuracies = []\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(best_xgb_clas, threshold=thresh, prefit=True)\n",
    "        selection_x_data = selection.transform(x_data)\n",
    "        selection_x_data = pd.DataFrame(selection_x_data)\n",
    "        if(thresh > 0 ):\n",
    "            threshold_array.append(thresh)\n",
    "            selection_model = XGBClassifier()\n",
    "            acc = eval_threshold_cv(selection_x_data, y_label, selection_model)\n",
    "            threshold_accuracies.append(acc)\n",
    "            print(\"Thresh=%.10f, n=%d, Accuracy: %.2f%%\" % (thresh, selection_x_data.shape[1], acc))\n",
    "    i = 0\n",
    "    max_acc = 0\n",
    "    max_i = 0\n",
    "    max_thresh = 0\n",
    "    for x in threshold_array:\n",
    "        current_acc = threshold_accuracies[i]\n",
    "        if(current_acc > max_acc):\n",
    "            max_acc = current_acc\n",
    "            max_thresh = x\n",
    "            max_i = i\n",
    "        i = i + 1\n",
    "    print(\"max accuracy is: \" + str(max_acc) + \"for threshold: \" + str(max_thresh))\n",
    "    return max_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_2_thresh = \n",
    "n_3_thresh =\n",
    "n_10_thresh = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this a method param later\n",
    "#n_games = 5\n",
    "def run_all_models(n_games):\n",
    "    #load headers and then subsequently categorical headers\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "    filename = 'Models/ohe_'+str(n_games)+'_no_2021_games_fs.dat'\n",
    "    pickle.dump(ohe, open(filename, \"wb\"))\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "    \n",
    "    #DO STUFF Here\n",
    "    x_data = reduce_MC(x_data)\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #loads margin as the y_label\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    print(margin_label.shape)\n",
    "    print(y_label.shape)\n",
    "    print(x_data.shape)\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    #optimise XGBoost model\n",
    "\n",
    "    #for predicting win\n",
    "    model = param_search(x_data, y_label, 0)\n",
    "    #for predicting margin\n",
    "    #margin_label = abs(margin_label)\n",
    "    margin_model = clf = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "\n",
    "   # margin_label = abs(margin_label)\n",
    "    print(margin_label)\n",
    "    best_xgb_clas, best_xgb_reg = eval_xgb_games_margins(x_data, y_label, model, margin_label, margin_model)\n",
    "\n",
    "    #save\n",
    "    pickle.dump(best_xgb_clas, open(\"Models/best_xgb_clas_no2020_\"+str(n_games)+\"_games_fs.dat\", \"wb\"))\n",
    "    #pickle.dump(best_xgb_reg, open(\"Models/best_xgb_reg_no2020_\"+str(n_games)+\"_games.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data Testing Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_R_TeamDict():\n",
    "    teams = {\n",
    "    \"1\" : \"Adelaide Crows\",\n",
    "    \"2\" : \"Brisbane Lions\",\n",
    "    \"3\" : \"Carlton\",\n",
    "    \"4\" : \"Collingwood\",\n",
    "    \"5\" : \"Essendon\",\n",
    "    \"6\" : \"Fremantle\",\n",
    "    \"7\" : \"Geelong Cats\",\n",
    "    \"8\" : \"Gold Coast Suns\",\n",
    "    \"9\" : \"GWS Giants\",\n",
    "    \"10\": \"Hawthorn\",\n",
    "    \"11\": \"Melbourne\",\n",
    "    \"12\": \"North Melbourne\",\n",
    "    \"13\": \"Port Adelaide\",\n",
    "    \"14\": \"Richmond\",\n",
    "    \"15\": \"St Kilda\",\n",
    "    \"16\": \"Sydney Swans\",\n",
    "    \"17\": \"West Coast Eagles\",\n",
    "    \"18\": \"Western Bulldogs\"\n",
    "    }\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_int = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pavs = pd.read_csv(\"R_Code/all_team_pavs.csv\")\n",
    "team_pavs = pavs.loc[(pavs[\"Team_ID\"]==team_int)]\n",
    "team_pavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sum_pav(year, rnd, team_int):\n",
    "    #do calc\n",
    "    g = gad()\n",
    "    team_dict = g.createTeamDict()\n",
    "    r_dict = create_R_TeamDict()\n",
    "    current_team = (team_dict[str(team_int)])\n",
    "    df = pd.read_csv(\"Data/\"+current_team+'_clean_stats.csv')\n",
    "    current_r_team = (r_dict[str(team_int)])\n",
    "    lineups = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "    lineups = lineups[lineups.isin([current_r_team]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([year]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([rnd]).any(axis=1)]\n",
    "    lineups['team'] = team_int\n",
    "    if(rnd < 11):\n",
    "        lineups['year'] = (year-1)\n",
    "    lineups.columns = ['year', 'teamname', 'roundNumber', 'firstname', 'surname', 'team']\n",
    "    cols = ['team', 'year', 'firstname', 'surname']\n",
    "    lineups = lineups[cols]\n",
    "    all_pavs = pd.read_csv(\"R_Code/all_player_PAVs.csv\")\n",
    "    \n",
    "    lineups.firstname = lineups.firstname.str.split(' ').str[0]\n",
    "    all_pavs.firstname = all_pavs.firstname.str.replace(' ','')\n",
    "    \n",
    "    lineups = lineups.merge(all_pavs, how='inner', on=['team', 'year', 'firstname', 'surname'])\n",
    "    if(lineups.shape[0] > 0):\n",
    "        pav = lineups['PAV_total'].sum()\n",
    "    else:\n",
    "        pav = 999\n",
    "    print(pav)\n",
    "    pav_array = [year, rnd, team_int, pav]\n",
    "    return pav_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pav_array = []\n",
    "for team_id in range(1,19):\n",
    "    for year in range(2022, 2023):\n",
    "        for rnd in range(1,5):\n",
    "            print(str(team_id) + '_' + str(year)+'_'+str(rnd))\n",
    "            pa = calc_sum_pav(year, rnd, team_id)\n",
    "            if(pa[3] == 999):\n",
    "                continue\n",
    "            pav_array.append(pa)\n",
    "pav_df = pd.DataFrame(pav_array, columns=['Year', 'Round', 'Team_ID', 'Player_PAV_Total'])\n",
    "all_pav_df = pd.read_csv('R_Code/all_team_pavs.csv')\n",
    "all_pav_df = pd.concat([all_pav_df, pav_df], ignore_index=True)\n",
    "print(pav_df)\n",
    "print(all_pav_df)\n",
    "all_pav_df.to_csv(\"R_Code/all_team_pavs.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Based Dataset Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get assemble_df code from the clean_dataset csv\n",
    "#do the usual stuff appended at the front eg. venue, ladder, round, H_team_id, A_team_id\n",
    "#pick averageable statistics and get n_game average for home and away\n",
    "#function to workout from clean_dataset home_team wins against away team in last 5\n",
    "    #5-home_team_wins to get away team wins against oppo\n",
    "    #append to new X_data\n",
    "#save to new assemble_df.csv\n",
    "\n",
    "match_id = 10576\n",
    "team_id = 9\n",
    "oppo_id = 6\n",
    "g = gad()\n",
    "teams = g.createTeamDict()\n",
    "n_games = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_form(ct, ot, match_id):\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "    current_team = (teams[str(ct)])\n",
    "    team_string = current_team+\"_clean_stats.csv\"\n",
    "    df = pd.read_csv(\"Data/\"+team_string)\n",
    "    idx = df.index[df['Match_ID'] == match_id]\n",
    "    my_idx = idx[0]\n",
    "    df = df.loc[0:my_idx-1,:]\n",
    "    prev_games = df.loc[(df['Team_against_ID']==ot)]\n",
    "    #return last 5 games against each other and 8th column is whether the ct won against ot\n",
    "    l = 5\n",
    "    if(prev_games.shape[0] < 5):\n",
    "        l = prev_games.shape[0]\n",
    "    if(l==0):\n",
    "        wins = 0\n",
    "    else:\n",
    "        prev_games = prev_games.iloc[-l: , 8]\n",
    "        wins = prev_games.sum()\n",
    "    return wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prev_games(match_id, team_id, teams, n_games, oppo_id):\n",
    "    margin = None\n",
    "    ma = None\n",
    "    y_label = None\n",
    "    trend_cg = []\n",
    "    current_team = (teams[str(team_id)])\n",
    "    print(current_team)\n",
    "    print(match_id)\n",
    "    team_string = current_team+\"_clean_stats.csv\"\n",
    "    df = pd.read_csv(\"Data/\"+team_string)\n",
    "    #drops ladder stats\n",
    "    #finds where in the dataframe the current match is\n",
    "    idx = df.index[df['Match_ID'] == match_id]\n",
    "    #print(idx)\n",
    "    my_idx = idx[0]\n",
    "    #splits dataframe into game data and end of round ladder data\n",
    "    l_df = df.iloc[:,-5:]\n",
    "    t_df = df.iloc[: , :-5]\n",
    "    current_year = t_df.loc[my_idx][1]\n",
    "    if(current_year == 2020.0):\n",
    "        print('game in 2020')\n",
    "        margin = 8888\n",
    "    else:\n",
    "        #turns the WWWLL form column into # of W\n",
    "        n_form = []\n",
    "        for x in l_df['form']:\n",
    "            if(len(x)<n_games):\n",
    "                y=float(x.count(\"W\"))\n",
    "                n_form.append(y)\n",
    "            else:\n",
    "                x=x[-n_games:]\n",
    "                y=float(x.count(\"W\"))\n",
    "                n_form.append(y)\n",
    "        l_df['form'] = n_form\n",
    "        #checks to make sure there is enough games to go through\n",
    "        if(my_idx < (n_games)):\n",
    "            print('Num of Prev Games Exceeds previous games')\n",
    "            margin = 9999\n",
    "        else:\n",
    "            #start match array with the ladder values from end of previous round (as this would be current for predicting round)\n",
    "            ma = l_df.loc[my_idx-1].values\n",
    "            #finds both labels for models\n",
    "            y_label = t_df.loc[my_idx][\"H/A Win?\"]\n",
    "            margin = t_df.loc[my_idx][\"Margin\"]\n",
    "            #start from the previous game to current game\n",
    "            #i is to know how many games included\n",
    "            i = 1\n",
    "            #j finds the previous game and allows for 2020 exclusion\n",
    "            j = 1\n",
    "            while i <= n_games:\n",
    "                year = t_df.loc[my_idx-j][1]\n",
    "                if(year == 2020.0):\n",
    "                    j = j + 1\n",
    "                    continue\n",
    "                cg = t_df.loc[my_idx-j][2:].values\n",
    "                trend_cg.append(cg)\n",
    "                i = i + 1\n",
    "                j = j + 1\n",
    "            my_df = pd.DataFrame(trend_cg, columns = t_df.columns[2:])\n",
    "            my_df = my_df.iloc[:,3:-1]\n",
    "            cg = my_df.mean(axis=0)\n",
    "            ma = [*ma, *cg]\n",
    "            h_form = find_form(team_id, oppo_id, match_id)\n",
    "            o_form = find_form(oppo_id, team_id, match_id)\n",
    "            form_diff = h_form-o_form\n",
    "            ma.append(form_diff)\n",
    "    return ma, y_label, margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "home_array, y_label, margin = create_prev_games(5720, team_id, teams, 3, oppo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(home_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Round', 'Home_Team', 'Away_Team', 'Venue']\n",
    "example_file = pd.read_csv('Data/Fremantle_clean_stats.csv')\n",
    "cl_h = example_file.columns\n",
    "cl_h = cl_h[5:-6]\n",
    "ladder_header = ['Ladder Pos_H', 'Form_H', 'Season Wins_H', 'Season Loss_H', 'Season Draw_H']\n",
    "headers = [*headers, *ladder_header]\n",
    "for x in cl_h:\n",
    "    if 'Match_ID' in x or 'Year' in x:\n",
    "        continue\n",
    "    x = 'H_'+ x + ' avg'\n",
    "    headers.append(x)\n",
    "headers.append(\"H_Recent_Matchup_Diff\")\n",
    "ladder_header = ['Ladder Pos_A', 'Form_A', 'Season Wins_A', 'Season Loss_A', 'Season Draw_A']\n",
    "headers = [*headers, *ladder_header]\n",
    "for x in cl_h:\n",
    "    if 'Match_ID' in x or 'Year' in x:\n",
    "        continue\n",
    "    x = 'A_'+ x + ' avg'\n",
    "    headers.append(x)\n",
    "headers.append(\"A_Recent_Matchup_Diff\")\n",
    "len(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Specific Models\n",
    "## Averaged about 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_specific_dataset(n_games, tn):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "    #load in x_data and y_label for n = 1 (quicker)\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #finds team index\n",
    "    team_idx = x_data.index[(x_data['Home_Team']==tn) | (x_data['Away_Team']==tn)]\n",
    "    team_x_data = x_data.iloc[team_idx]\n",
    "    team_y_data = y_label.iloc[team_idx]\n",
    "    team_x_data.reset_index(drop=True, inplace=True)\n",
    "    team_y_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #quick shape check\n",
    "    print(team_x_data.shape)\n",
    "    print(team_y_data.shape)\n",
    "    l = team_x_data.shape[0]\n",
    "\n",
    "    #loop for new y_array\n",
    "    i = 0\n",
    "    new_team_y = []\n",
    "    while i < l:\n",
    "        x = team_x_data.iloc[i]\n",
    "        y = team_y_data.iloc[i]\n",
    "        #if our team for current model is the home team\n",
    "        if(x[\"Home_Team\"] == tn):\n",
    "            #and the home team has won\n",
    "            if(y[\"H/A Win?\"] == 0):\n",
    "                #set win val to 1\n",
    "                w_val = 1\n",
    "            #else they're the home team but the away team won\n",
    "            else:\n",
    "                #set win val to 0\n",
    "                w_val = 0\n",
    "        #else they're the away team\n",
    "        else:\n",
    "            #if the home team won, that means they lost\n",
    "            if(y[\"H/A Win?\"] == 0):\n",
    "                w_val = 0\n",
    "            #else they're the away team and they won\n",
    "            else:\n",
    "                w_val = 1\n",
    "        i = i + 1\n",
    "        new_team_y.append(w_val)\n",
    "    ny = pd.DataFrame(new_team_y, columns=['Team Won?'])\n",
    "    return team_x_data, ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_team_specific_dataset(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_team_xgb_games(x, y, m, n_games, tn):\n",
    "    results = []\n",
    "    error = []\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        #comment out fit steps for random forest i guess lol\n",
    "        prediction = m.fit(x.loc[train],y.loc[train]).predict_proba(x.loc[test])\n",
    "        y_pred = m.predict(x.loc[test])\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y.loc[test], predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "        #change the best model to equal current model\n",
    "        if(pcent > high_w):\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "    print(\"Training Testing Accuracy for n_games=\"+str(n_games)+\" team=\"+str(tn)+\" : %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_w, np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_team_models(n_games, tn):\n",
    "    #load headers and then subsequently categorical headers\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data, y_label = get_team_specific_dataset(n_games, tn)\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "    filename = 'Models/Team_OHE/ohe_'+str(n_games)+\"_team_specific_\"+str(tn)+'_no_2020_games.dat'\n",
    "    pickle.dump(ohe, open(filename, \"wb\"))\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "\n",
    "    #optimise XGBoost model\n",
    "    #print(x_data)\n",
    "    #for predicting win\n",
    "    model = param_search(x_data, y_label, 0)\n",
    "    best_xgb_clas, model_av = eval_team_xgb_games(x_data, y_label, model, n_games, tn)\n",
    "\n",
    "    #save\n",
    "    pickle.dump(best_xgb_clas, open(\"Models/Team_Models/best_xgb_clas_no2020_\"+str(n_games)+\"_team_specific_\"+str(tn)+'_.dat', \"wb\"))\n",
    "    return model_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for n in range(1,11):\n",
    "    averages = []\n",
    "    for tn in range(1,19):\n",
    "        a = run_team_models(n, tn)\n",
    "        averages.append(a)\n",
    "    print(\"Accuracy for Team Models for n_games= \"+str(n)+\" : %.2f%% (%.2f%%)\" % (np.mean(averages), np.std(averages)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import re\n",
    "from numpy import arange\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(n_games):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #loads margin as the y_label\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    print(margin_label.shape)\n",
    "    print(y_label.shape)\n",
    "    print(x_data.shape)\n",
    "\n",
    "    #regex solution which is apparently necessary??\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "    return x_data, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_NC(x_data, y_label):\n",
    "# define model\n",
    "    print(\"optimising hyperparameters\")\n",
    "    model = NearestCentroid()\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # define grid\n",
    "    grid = dict()\n",
    "    grid['shrink_threshold'] = arange(0, 1.01, 0.01)\n",
    "    grid['metric'] = ['euclidean', 'manhattan']\n",
    "    # define search\n",
    "    search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # perform the search\n",
    "    results = search.fit(x_data, y_label.values.ravel())\n",
    "    # summarize\n",
    "    print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "    print('Config: %s' % results.best_params_)\n",
    "    return results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_NC(x, y, m):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    results = []\n",
    "    print(x)\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    for train,test in cv.split(x,y):\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        x_train = x.loc[train]\n",
    "        y_train = y.loc[train].values.ravel()\n",
    "        x_test = x.loc[test]\n",
    "        y_test = y.loc[test]\n",
    "        m.fit(x_train,y_train)\n",
    "        y_pred = m.predict(x_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "        if(pcent > high_w):\n",
    "            print(\"found new best classify\")\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "    print(\"Best win percentage split = \" +str(high_w))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_all_NC(n):\n",
    "    x_data, y_label = load_data(n)\n",
    "    best_params = params_NC(x_data, y_label)\n",
    "    model = NearestCentroid(**best_params)\n",
    "    best_NC_clas = eval_NC(x_data, y_label, model)\n",
    "    pickle.dump(best_NC_clas, open(\"Models/best_NC_clas_no2020\"+str(n_games)+'_games.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games = [1,2,3,4,5,6,7,10]\n",
    "for n in n_games:\n",
    "    run_all_NC(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_BNB(x_data, y_label):\n",
    "# define model\n",
    "    print(\"optimising hyperparameters\")\n",
    "    model = BernoulliNB()\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # define grid\n",
    "    grid = dict()\n",
    "    grid['alpha'] = arange(0.01, 1.01, 0.01)\n",
    "    # define search\n",
    "    search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=1, verbose=1)\n",
    "    # perform the search\n",
    "    results = search.fit(x_data, y_label.values.ravel())\n",
    "    # summarize\n",
    "    print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "    print('Config: %s' % results.best_params_)\n",
    "    return results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_BNB(x, y, m):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    results = []\n",
    "    print(x)\n",
    "    count = 0\n",
    "    best_w = m\n",
    "    high_w = 0\n",
    "    for train,test in cv.split(x,y):\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        x_train = x.loc[train]\n",
    "        y_train = y.loc[train].values.ravel()\n",
    "        x_test = x.loc[test]\n",
    "        y_test = y.loc[test]\n",
    "        m.fit(x_train,y_train)\n",
    "        y_pred = m.predict(x_test)\n",
    "        predictions = [round(value) for value in y_pred]\n",
    "        #sees how accurate the model was when testing the test set\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        pcent = accuracy * 100.0\n",
    "        results.append(pcent)\n",
    "        if(pcent > high_w):\n",
    "            print(\"found new best classify\")\n",
    "            best_w = m\n",
    "            high_w = pcent\n",
    "    print(\"Best win percentage split = \" +str(high_w))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_BNB(n):\n",
    "    x_data, y_label = load_data(n)\n",
    "    best_params = params_BNB(x_data, y_label)\n",
    "    model = BernoulliNB(**best_params)\n",
    "    best_BNB_clas = eval_BNB(x_data, y_label, model)\n",
    "    pickle.dump(best_BNB_clas, open(\"Models/best_BNB_clas_no2020\"+str(n_games)+'_games.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_games = [1,2,3,4,5,6,7,10]\n",
    "for n in n_games:\n",
    "    run_all_BNB(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAZY PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lazy_predict(x, y, my):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    all_clf_models = []\n",
    "    all_reg_models = []\n",
    "    count = 0\n",
    "    for train,test in cv.split(x,y):\n",
    "       # print(len(train))\n",
    "        count = count + 1\n",
    "        print(\"Split: \" + str(count))\n",
    "        #classifier\n",
    "        X_train = x.loc[train]\n",
    "        X_test = x.loc[test]\n",
    "        y_train = y.loc[train]\n",
    "        y_test = y.loc[test]\n",
    "        my_train = my.loc[train]\n",
    "        my_test = my.loc[test]\n",
    "        clf = LazyClassifier(predictions=True)\n",
    "        reg = LazyRegressor(predictions=True)\n",
    "        if(count == 1):\n",
    "            all_clf_models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "          #  all_reg_models, reg_predictions = reg.fit(X_train, X_test, my_train, my_test)\n",
    "            all_clf_models.sort_index(inplace=True)\n",
    "           # all_reg_models.sort_index(inplace=True)\n",
    "            #print(all_models)\n",
    "        else:\n",
    "            new_clf_models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "           # new_reg_models, reg_predictions = reg.fit(X_train, X_test, my_train, my_test)\n",
    "            new_clf_models.sort_index(inplace=True)\n",
    "           # new_reg_models.sort_index(inplace=True)\n",
    "            #print(new_models)\n",
    "            all_clf_models = all_clf_models.add(new_clf_models)\n",
    "           # all_reg_models = all_reg_models.add(new_reg_models)\n",
    "    return all_clf_models#, all_reg_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_all_lp(n_games):\n",
    "    h = get_headers(n_games)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "\n",
    "    #to get names of teams from index\n",
    "    g = gad()\n",
    "    teams = g.createTeamDict()\n",
    "\n",
    "    #load Data\n",
    "    x_data = pd.read_csv('Data/assembled_stat_matrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #make empty OHE object\n",
    "    na_enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    #one hot encode data with new one hot encoder, saves ohe for later use\n",
    "    x_data, ohe = ohe_data(x_data, na_enc, 0, cv)\n",
    "\n",
    "    #reset headers\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    #loads the ylabel matrix,\n",
    "    y_label = pd.read_csv('Data/assembled_labelled_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "\n",
    "    #do margins in a second when this works\n",
    "    margin_label = pd.read_csv('Data/assembled_margin_ymatrix_no2020'+str(n_games)+'_games.csv')\n",
    "    margin_label = abs(margin_label)\n",
    "\n",
    "    clf_lp = eval_lazy_predict(x_data, y_label, margin_label)\n",
    "\n",
    "    clf_lp.sort_values(by='Accuracy', ascending=False, inplace=True)\n",
    "    #reg_lp.sort_values(by='RMSE', inplace=True)\n",
    "    pct_lp = clf_lp*10\n",
    "    print(pct_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#as one big script to go through n_games\n",
    "n_games = [1,2,3,4,5,6,7,10]\n",
    "for n in n_games:\n",
    "    run_all_lp(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learningggg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DNN_model(x_len):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(63, input_dim = x_len))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.03))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.02))\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('relu'))\n",
    "    #add output layer\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN_model(x_len):\n",
    "    #del model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=14,\n",
    "                     input_shape=(x_len, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters=16, kernel_size=10,\n",
    "                     input_shape=(32, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters=10, kernel_size=8,\n",
    "                     input_shape=(16, 1)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='linear'))\n",
    "    model.add(Dense(32, activation='linear'))\n",
    "    model.add(Dense(16, activation='linear'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = tf.keras.optimizers.Adamax(learning_rate=0.003)#, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
    "\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag = 0 (DNN)\n",
    "#flag = 1 (CNN)\n",
    "def eval_dl(x,y,k,flag):\n",
    "    cv = StratifiedKFold(n_splits=k,shuffle=True)\n",
    "    best_model = []\n",
    "    results = []\n",
    "    highest = 0\n",
    "    i = 1\n",
    "    for train,test in cv.split(x,y):\n",
    "        if(flag == 0):\n",
    "            model = build_DNN_model(x[train].shape[1])\n",
    "        if(flag == 1):\n",
    "            x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "            model = build_CNN_model(x[train].shape[1])\n",
    "        bs = ((x[train].shape[0])/20)\n",
    "        bs = round(bs)\n",
    "        history = model.fit(x[train], y[train], validation_data=(x[test], y[test]), epochs = 50, batch_size=bs)\n",
    "        _, accuracy = model.evaluate(x[test], y[test], batch_size=bs, verbose=0)\n",
    "        accuracy = accuracy * 100\n",
    "        print(\"accuracy for model \" + str(i) + \" is \" + str(accuracy))\n",
    "        if(accuracy > highest):\n",
    "            highest = accuracy\n",
    "            best_model = model\n",
    "        results.append(accuracy)\n",
    "        i = i + 1\n",
    "    print(\"highest accuracy is: \" + str(highest))\n",
    "    print(\"Training Testing Accuracy: %.2f%% (%.2f%%)\" % (np.mean(results), np.std(results)))\n",
    "    return best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
