{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78df18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import xgboost as xgb\n",
    "#import torch.nn as nn\n",
    "#import touch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randint\n",
    "from Gather_AFL_Data import gatherer as gad\n",
    "#from fdnn import feature_extractor as fex\n",
    "import skopt\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import re\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d702dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get headers\n",
    "#feed this into a bigger function which specifies the amount of games to go through \n",
    "def get_headers(n_games):\n",
    "    headers = ['Round', 'Home_Team', 'Away_Team', 'Venue', 'H_PAV_Sum', 'A_PAV_Sum']\n",
    "    example_file = pd.read_csv('Data/Fremantle_clean_stats.csv')\n",
    "    cl_h = example_file.columns\n",
    "    cl_h = cl_h[:-5]\n",
    "    ladder_header = ['Ladder Pos_H', 'Form_H', 'Season Wins_H', 'Season Loss_H', 'Season Draw_H']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    j = 1\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'H_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    j = 1\n",
    "    ladder_header = ['Ladder Pos_A', 'Form_A', 'Season Wins_A', 'Season Loss_A', 'Season Draw_A']\n",
    "    headers = [*headers, *ladder_header]\n",
    "    while j <= n_games:\n",
    "        for x in cl_h:\n",
    "            if 'Match_ID' in x or 'Year' in x:\n",
    "                continue\n",
    "            x = 'A_'+ x + ' n-' + str(j)\n",
    "            headers.append(x)\n",
    "        j = j + 1\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e83d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headers(h):\n",
    "    headers = []\n",
    "    for x in h:\n",
    "        if '<' in x or '>' in x:\n",
    "            x = x.replace('<',\"lt_\")\n",
    "            x = x.replace('>', \"gt_\")\n",
    "            #print(x)\n",
    "        headers.append(str(x))\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f930a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_categorical_headers(h):\n",
    "    cat_var = ['Round', 'Home_Team', 'Away_Team']\n",
    "    skip = 0\n",
    "    for x in h:\n",
    "        if 'Round' in x:\n",
    "            if (skip == 0):\n",
    "                skip = 1\n",
    "                continue\n",
    "            cat_var.append(x)\n",
    "            #print(x)\n",
    "        elif 'Team_against_ID' in x:\n",
    "            #print(x)\n",
    "            cat_var.append(x)\n",
    "        elif 'Venue' in x:\n",
    "            cat_var.append(x)\n",
    "    return cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0537bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode data and transform the X_data\n",
    "#first redo, find the categorial variables\n",
    "def ohe_data(x_data, enc, flag,cat_var):\n",
    "    #data has not been previously one hot encoded\n",
    "    if (flag == 0):\n",
    "        #get columns with categorical data and drop from main DF\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        #define and fit new OHE. Use it on our categorical data by transforming\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        ohe = ohe.fit(categorical_data)\n",
    "        categorical_data = ohe.transform(categorical_data)\n",
    "        #get feature names for better labelling\n",
    "        fn = ohe.get_feature_names(cat_var)\n",
    "        #make a dataframe with new OHE data and feature names\n",
    "            #would have been good to have coded it like this for my Masters project...\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        #ensure that it won't get cranky about any different indexes(shouldn't be any but just a good check)\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        #concatenate along column axis\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1)\n",
    "    else:\n",
    "        #same as above except used already fitted ohe\n",
    "        categorical_data = x_data[cat_var]\n",
    "        x_data = x_data.drop(cat_var, axis = 1)\n",
    "        categorical_data = enc.transform(categorical_data)\n",
    "        fn = enc.get_feature_names(cat_var)\n",
    "        categorical_data = pd.DataFrame(categorical_data)\n",
    "        categorical_data.columns = fn\n",
    "        x_data.reset_index(drop=True, inplace=True)\n",
    "        categorical_data.reset_index(drop=True, inplace=True)\n",
    "        x_data = pd.concat([x_data, categorical_data], axis = 1)\n",
    "        ohe = enc\n",
    "    return x_data, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790399f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(n):\n",
    "    clf = pickle.load(open(\"Models/best_xgb_clas_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    reg = pickle.load(open(\"Models/best_xgb_reg_no2020_\"+str(n)+\"_games.dat\", \"rb\"))\n",
    "    ohe = pickle.load(open(\"Models/ohe_\"+str(n)+\"_no_2021_games.dat\", \"rb\"))\n",
    "    return clf, reg, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5916b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prev_games(team_id, n_games, teams):\n",
    "    ma = None\n",
    "    current_team = (teams[str(team_id)])\n",
    "    team_string = current_team+\"_clean_stats.csv\"\n",
    "    df = pd.read_csv(\"Data/\"+team_string)\n",
    "    df = df.iloc[::-1]\n",
    "    df = df.head(n_games)\n",
    "    df = df.reset_index()\n",
    "    #print(df)\n",
    "    #drops ladder stats\n",
    "    #finds where in the dataframe the current match is\n",
    "    #splits dataframe into game data and end of round ladder data\n",
    "    l_df = df.iloc[:,-5:]\n",
    "    t_df = df.iloc[: , :-5]\n",
    "    #turns the WWWLL form column into # of W\n",
    "    n_form = []\n",
    "    for x in l_df['form']:\n",
    "        if(len(x)<n_games):\n",
    "            y=float(x.count(\"W\"))\n",
    "            n_form.append(y)\n",
    "        else:\n",
    "            x=x[-n_games:]\n",
    "            y=float(x.count(\"W\"))\n",
    "            n_form.append(y)\n",
    "    l_df['form'] = n_form\n",
    "\n",
    "    #checks to make sure there is enough games to go through\n",
    "    #start match array with the ladder values from end of previous round (as this would be current for predicting round)\n",
    "    ma = l_df.loc[0].values\n",
    "    #finds both labels for models\n",
    "    #start from the previous game to current game\n",
    "    #i is to know how many games included\n",
    "    i = 0\n",
    "    #j finds the previous game and allows for 2020 exclusion\n",
    "    while i < n_games:\n",
    "        cg = t_df.loc[i][3:].values\n",
    "        ma = [*ma, *cg]\n",
    "        i = i + 1\n",
    "    return ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1efe2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prev_games(home_id, away_id, round_num, venue, h_pav, a_pav, home_array, away_array):\n",
    "    current_example_array = [round_num, home_id, away_id, venue, h_pav, a_pav]\n",
    "    current_example_array.extend(home_array)\n",
    "    current_example_array.extend(away_array)\n",
    "    return current_example_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85cbc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(home_id, away_id, venue, round_num, h_pav, a_pav, n, teams):\n",
    "    \n",
    "    cea_df = []\n",
    "    home_array = create_prev_games(home_id, n, teams)\n",
    "    away_array = create_prev_games(away_id, n, teams)\n",
    "    cea = combine_prev_games(home_id, away_id, round_num, venue, h_pav, a_pav, home_array, away_array)\n",
    "    \n",
    "    cea_df.append(cea)\n",
    "    cea_df = pd.DataFrame(cea_df)\n",
    "    h = get_headers(n)\n",
    "    cea_df.columns = h\n",
    "    \n",
    "    clf, reg, ohe = load_models(n)\n",
    "    h = get_headers(n)\n",
    "    h = clean_headers(h)\n",
    "    cv = generate_categorical_headers(h)\n",
    "    x_data, ohe = ohe_data(cea_df, ohe, 1, cv)\n",
    "    #I don't think this does anything, but I'm too scared to move it\n",
    "    feature_names = x_data.columns\n",
    "\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    x_data.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in x_data.columns.values]\n",
    "    \n",
    "    \n",
    "    y = clf.predict(x_data)\n",
    "    yp = clf.predict_proba(x_data)\n",
    "    my = reg.predict(x_data)\n",
    "    my[0] = abs(my[0])\n",
    "    my[0] = round(my[0],0)\n",
    "    if(y < 0.5):\n",
    "        p = yp[:,0]*100\n",
    "        p = str(p)\n",
    "        #Could somehow make this print statement into a javascript thing for django?\n",
    "        print(teams[str(home_id)] + \"(HOME) is predicted to win with a \"+p[1:-1]+\"% chance by \" + str(my[0]) +\" points\")\n",
    "    elif(y > 0.5):\n",
    "        p = yp[:,1]*100\n",
    "        p = str(p)\n",
    "        print(teams[str(away_id)] + \"(AWAY) is predicted to win with a \"+p[1:-1]+\"% chance by \" + str(my[0]) +\" points\")\n",
    "    else:\n",
    "        print(\"DRAW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d712a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sum_pav(year, rnd, team_int):\n",
    "    #do calc\n",
    "    g = gad()\n",
    "    team_dict = g.createTeamDict()\n",
    "    r_dict = create_R_TeamDict()\n",
    "    current_team = (team_dict[str(team_int)])\n",
    "    df = pd.read_csv(\"Data/\"+current_team+'_clean_stats.csv')\n",
    "    current_r_team = (r_dict[str(team_int)])\n",
    "    lineups = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "    lineups = lineups[lineups.isin([current_r_team]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([year]).any(axis=1)]\n",
    "    lineups = lineups[lineups.isin([rnd]).any(axis=1)]\n",
    "    lineups['team'] = team_int\n",
    "    if(rnd < 11):\n",
    "        lineups['year'] = (year-1)\n",
    "    lineups.columns = ['year', 'teamname', 'roundNumber', 'firstname', 'surname', 'team']\n",
    "    cols = ['team', 'year', 'firstname', 'surname']\n",
    "    lineups = lineups[cols]\n",
    "    all_pavs = pd.read_csv(\"R_Code/all_player_PAVs.csv\")\n",
    "    \n",
    "    lineups.firstname = lineups.firstname.str.split(' ').str[0]\n",
    "    all_pavs.firstname = all_pavs.firstname.str.replace(' ','')\n",
    "    \n",
    "    lineups = lineups.merge(all_pavs, how='inner', on=['team', 'year', 'firstname', 'surname'])\n",
    "    if(lineups.shape[0] > 0):\n",
    "        pav = lineups['PAV_total'].sum()\n",
    "    else:\n",
    "        pav = 999\n",
    "    print(pav)\n",
    "    pav = round(pav,2)\n",
    "    print(pav)\n",
    "    pav_array = [year, rnd, team_int, pav]\n",
    "    return pav_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6030b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_venue_dict():\n",
    "    vDict = {\n",
    "        \"1\" : \"MCG\",\n",
    "        \"2\" : \"Marvel Stadium\",\n",
    "        \"3\" : \"Optus Stadium\",\n",
    "        \"4\" : \"Adelaide Oval\",\n",
    "        \"5\" : \"SCG\",\n",
    "        \"6\" : \"Gabba\",\n",
    "        \"7\" : \"Metricon Stadium\",\n",
    "        \"8\" : \"GIANTS Stadium\",\n",
    "        \"9\" : \"GMHBA Stadium\",\n",
    "        \"10\" : \"Manuka Oval\",\n",
    "        \"11\" : \"Blundstone Arena\",\n",
    "        \"12\" : \"University of Tasmania Stadium\",\n",
    "        \"13\" : \"TIO Stadium\",\n",
    "        \"14\" : \"Accor Stadium Australia\",\n",
    "        \"15\" : \"Mars Stadium\"\n",
    "        }\n",
    "    return vDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1283e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_R_TeamDict():\n",
    "    teams = {\n",
    "    \"1\" : \"Adelaide Crows\",\n",
    "    \"2\" : \"Brisbane Lions\",\n",
    "    \"3\" : \"Carlton\",\n",
    "    \"4\" : \"Collingwood\",\n",
    "    \"5\" : \"Essendon\",\n",
    "    \"6\" : \"Fremantle\",\n",
    "    \"7\" : \"Geelong Cats\",\n",
    "    \"8\" : \"Gold Coast Suns\",\n",
    "    \"9\" : \"GWS Giants\",\n",
    "    \"10\": \"Hawthorn\",\n",
    "    \"11\": \"Melbourne\",\n",
    "    \"12\": \"North Melbourne\",\n",
    "    \"13\": \"Port Adelaide\",\n",
    "    \"14\": \"Richmond\",\n",
    "    \"15\": \"St Kilda\",\n",
    "    \"16\": \"Sydney Swans\",\n",
    "    \"17\": \"West Coast Eagles\",\n",
    "    \"18\": \"Western Bulldogs\"\n",
    "    }\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ab28921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the PAV for a team in round and year\n",
    "def get_pav(season, round_num, team_id):\n",
    "    p_df = pd.read_csv('R_Code/all_team_pavs.csv')\n",
    "    test_pav = p_df.loc[(p_df['Year'] == season) & (p_df['Round'] == round_num) & (p_df['Team_ID'] == team_id)]\n",
    "    x = test_pav['Player_PAV_Total'].values[0]\n",
    "    y = test_pav['Player_PAV_Total'].values\n",
    "    print(y)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3abbaf",
   "metadata": {},
   "source": [
    "# Start Prediction Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be506aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter here until you automate\n",
    "round_num = 6\n",
    "season = 2022\n",
    "home_teams = [9,18,13,6,12,8,14,10,5]\n",
    "away_teams = [15,1,17,3,7,2,11,16,4]\n",
    "v_ids = [10,15,4,3,11,7,1,12,1]\n",
    "\n",
    "#incremental running due to teams being announced incrementally\n",
    "start_match = 0\n",
    "end_match = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0beea2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82435, 5)\n",
      "(82435, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/home/chris/Documents/Mitch/AFL_Data/AFL_Data/django_AFL_ML\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ℹ Fetching match ids\n",
      "✔ Fetching match ids ... done\n",
      "\n",
      "ℹ Fetching lineups for \"9 matches\".\n",
      "✔ Fetching lineups for \"9 matches\". ... done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82903, 5)\n",
      "209.0\n",
      "209.0\n",
      "207.0\n",
      "207.0\n",
      "233.83999999999997\n",
      "233.84\n",
      "170.08\n",
      "170.08\n",
      "242.21\n",
      "242.21\n",
      "171.10000000000002\n",
      "171.1\n",
      "203.74\n",
      "203.74\n",
      "182.20000000000002\n",
      "182.2\n",
      "174.85999999999999\n",
      "174.86\n",
      "256.08\n",
      "256.08\n",
      "182.6\n",
      "182.6\n",
      "264.37999999999994\n",
      "264.38\n",
      "205.16\n",
      "205.16\n",
      "267.35\n",
      "267.35\n",
      "169.29000000000002\n",
      "169.29\n",
      "234.54\n",
      "234.54\n",
      "225.10999999999996\n",
      "225.11\n",
      "200.87999999999997\n",
      "200.88\n",
      "    Year  Round  Team_ID  Player_PAV_Total\n",
      "0   2022      6        9            209.00\n",
      "1   2022      6       15            207.00\n",
      "2   2022      6       18            233.84\n",
      "3   2022      6        1            170.08\n",
      "4   2022      6       13            242.21\n",
      "5   2022      6       17            171.10\n",
      "6   2022      6        6            203.74\n",
      "7   2022      6        3            182.20\n",
      "8   2022      6       12            174.86\n",
      "9   2022      6        7            256.08\n",
      "10  2022      6        8            182.60\n",
      "11  2022      6        2            264.38\n",
      "12  2022      6       14            205.16\n",
      "13  2022      6       11            267.35\n",
      "14  2022      6       10            169.29\n",
      "15  2022      6       16            234.54\n",
      "16  2022      6        5            225.11\n",
      "17  2022      6        4            200.88\n",
      "(3724, 4)\n",
      "(3724, 4)\n",
      "(3742, 4)\n",
      "(3742, 4)\n",
      "Mitchell's Crackhead Model Tips \n",
      "\n",
      "[209.]\n",
      "[207.]\n",
      "GWS(HOME) is predicted to win with a 56.32255% chance by 7.0 points\n",
      "[233.84]\n",
      "[170.08]\n",
      "Western Bulldogs(HOME) is predicted to win with a 68.798805% chance by 9.0 points\n",
      "[242.21]\n",
      "[171.1]\n",
      "Port Adelaide(HOME) is predicted to win with a 66.10062% chance by 14.0 points\n",
      "[203.74]\n",
      "[182.2]\n",
      "Fremantle(HOME) is predicted to win with a 71.31022% chance by 14.0 points\n",
      "[174.86]\n",
      "[256.08]\n",
      "Geelong(AWAY) is predicted to win with a 80.47689% chance by 32.0 points\n",
      "[182.6]\n",
      "[264.38]\n",
      "Brisbane(AWAY) is predicted to win with a 83.54473% chance by 29.0 points\n",
      "[205.16]\n",
      "[267.35]\n",
      "Melbourne(AWAY) is predicted to win with a 75.532745% chance by 14.0 points\n",
      "[169.29]\n",
      "[234.54]\n",
      "Sydney(AWAY) is predicted to win with a 72.76243% chance by 29.0 points\n",
      "[225.11]\n",
      "[200.88]\n",
      "Collingwood(AWAY) is predicted to win with a 63.86729% chance by 2.0 points\n",
      "\n",
      "\n",
      "\n",
      "Rebeccas's Tips \n",
      "\n",
      "[209.]\n",
      "[207.]\n",
      "St Kilda(AWAY) is predicted to win with a 63.522804% chance by 8.0 points\n",
      "[233.84]\n",
      "[170.08]\n",
      "Western Bulldogs(HOME) is predicted to win with a 69.73232% chance by 26.0 points\n",
      "[242.21]\n",
      "[171.1]\n",
      "Port Adelaide(HOME) is predicted to win with a 65.796265% chance by 19.0 points\n",
      "[203.74]\n",
      "[182.2]\n",
      "Fremantle(HOME) is predicted to win with a 55.78502% chance by 10.0 points\n",
      "[174.86]\n",
      "[256.08]\n",
      "Geelong(AWAY) is predicted to win with a 79.430084% chance by 39.0 points\n",
      "[182.6]\n",
      "[264.38]\n",
      "Brisbane(AWAY) is predicted to win with a 79.02896% chance by 35.0 points\n",
      "[205.16]\n",
      "[267.35]\n",
      "Melbourne(AWAY) is predicted to win with a 78.51159% chance by 24.0 points\n",
      "[169.29]\n",
      "[234.54]\n",
      "Sydney(AWAY) is predicted to win with a 57.08313% chance by 2.0 points\n",
      "[225.11]\n",
      "[200.88]\n",
      "Collingwood(AWAY) is predicted to win with a 57.506603% chance by 4.0 points\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "##### RUN :) ######\n",
    "###################\n",
    "\n",
    "\n",
    "#load in dictionaries\n",
    "g = gad()\n",
    "teams = g.createTeamDict()\n",
    "vdict = create_venue_dict()\n",
    "\n",
    "#turn v_ids in venue names that are model\n",
    "venues = []\n",
    "for x in v_ids:\n",
    "    v = (vdict[str(x)])\n",
    "    venues.append(v)\n",
    "\n",
    "#check if the round and year data for lineups already exists and if so drop \n",
    "    #allows for multiple calls to update team lists as teams get announced\n",
    "df = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "print(df.shape)\n",
    "to_drop = df.index[(df['year'] == season) & (df['round.roundNumber'] == round_num) ]\n",
    "df = df.drop(to_drop)\n",
    "print(df.shape)\n",
    "df.to_csv(\"R_Code/all_lineups.csv\", header=True, index=False)\n",
    "    \n",
    "#update the all_lineups.csv\n",
    "subprocess.call([\"/usr/bin/Rscript\", \"R_Code/update_lineups.R\", str(season), str(round_num)])\n",
    "\n",
    "#check shape slightly reduces if lineup had previously existed\n",
    "df = pd.read_csv(\"R_Code/all_lineups.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "#uses the now updated all_lineups.csv to calculate PAVs for the specified games\n",
    "#updates the all_team_pavs file for easier access below and if retraining models\n",
    "#maybe chuck a cheeky remove duplicates and sort by year round in here for error checks\n",
    "pa = []\n",
    "for x in range(start_match, end_match):\n",
    "    home_pav_array = calc_sum_pav(season, round_num, home_teams[x])\n",
    "    pa.append(home_pav_array)\n",
    "    away_pav_array = calc_sum_pav(season, round_num, away_teams[x])\n",
    "    pa.append(away_pav_array)\n",
    "pav_df = pd.DataFrame(pa, columns=['Year', 'Round', 'Team_ID', 'Player_PAV_Total'])\n",
    "print(pav_df)\n",
    "\n",
    "#drop previous entries to all_team_pavs in the round and year\n",
    "all_pav_df = pd.read_csv('R_Code/all_team_pavs.csv')\n",
    "print(all_pav_df.shape)\n",
    "pav_to_drop = all_pav_df.index[(all_pav_df['Year'] == season) & (all_pav_df['Round'] == round_num) ]\n",
    "all_pav_df = all_pav_df.drop(pav_to_drop)\n",
    "print(all_pav_df.shape)\n",
    "\n",
    "all_pav_df = pd.concat([all_pav_df, pav_df], ignore_index=True)\n",
    "\n",
    "\n",
    "#remove duplicates and sort by year then round incase of multiple runnings or stupidity\n",
    "print(all_pav_df.shape)\n",
    "all_pav_df = all_pav_df.drop_duplicates()\n",
    "print(all_pav_df.shape)\n",
    "all_pav_df = all_pav_df.sort_values([\"Year\", \"Round\"], ascending = (True, True))\n",
    "all_pav_df.to_csv(\"R_Code/all_team_pavs.csv\", header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "#Run the predictions\n",
    "# n is which n_games model\n",
    "n = 2\n",
    "print(\"Mitchell's Crackhead Model Tips \\n\")\n",
    "\n",
    "i=start_match\n",
    "while i<end_match:\n",
    "    home_id = home_teams[i]\n",
    "    away_id = away_teams[i]\n",
    "    \n",
    "    home_pav = get_pav(season, round_num, home_id)\n",
    "    away_pav = get_pav(season, round_num, away_id)\n",
    "    \n",
    "    venue = venues[i]\n",
    "    predict(home_id, away_id, venue, round_num, home_pav, away_pav, n, teams)\n",
    "    i = i + 1\n",
    "    \n",
    "i = start_match\n",
    "n = 10\n",
    "print(\"\\n\\n\\nRebeccas's Tips \\n\")\n",
    "while i<end_match:\n",
    "    home_id = home_teams[i]\n",
    "    away_id = away_teams[i]\n",
    "    \n",
    "    home_pav = get_pav(season, round_num, home_id)\n",
    "    away_pav = get_pav(season, round_num, away_id)\n",
    "    \n",
    "    venue = venues[i]\n",
    "    predict(home_id, away_id, venue, round_num, home_pav, away_pav, n, teams)\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
